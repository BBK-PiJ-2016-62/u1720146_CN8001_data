id|question|person|oralEvidence
1|Q1|Chair|I welcome the panel here this morning. Can I ask you, for the record, to start by introducing yourselves? 
2|Q1|Sureyya Cansoy|Good morning. My name is Sureyya Cansoy. I am a director of tech for business and consumer programmes at techUK, the trade body for the technology industry. Thank you so much for the opportunity to talk to you this morning. 
3|Q1|Timo Hannay|Hello. I am Timo Hannay. I am managing director of Digital Science, a division of Macmillan Science and Education, the publishing company. We make software for researchers and scientists. 
4|Q1|Carl Miller|Good morning, everyone. I am Carl Miller, the research director for the Centre for the Analysis of Social Media—a bit of a tongue twister—at the think-tank Demos. 
5|Q2|Chair|A number of companies—I guess some of yours—make money from the use of social media data. There is nothing wrong with that; it is perfectly respectable. Will you tell us how the business models work—how you achieve that? 
6|Q2|Sureyya Cansoy|From our perspective, there are probably two broad ways that companies make money. One is that technology companies provide the software and tools necessary for big data analytics and social media analytics. They make the software and tools available to their customers through licensing, and they generate revenue through installing that software and training the staff in the customer organisations who will be using those tools. A smaller number of those tech companies also provide an end-to-end service delivery to customers. Instead of just providing the software and the tools, they actually provide the whole service to the customer. That is mainly how they make money. 
7|Q2|Sureyya Cansoy|In the broader context, companies using social media analytics ultimately make money out of gaining better insights into their customers, which increases their revenues and profitability. It is as simple as that. Some of the technology companies, in addition to providing software and tools for their customers, also use social media analytics to understand their customer base and the needs of their customers better so that they can tailor their products and services much better to their customers. 
8|Q3|Chair|The raw data itself is not the value; it is the data plus the analytical work done on the data. 
9|Q3|Sureyya Cansoy|Very much so. If we look at the amount of data out there, especially in the context of social media data, it is vast. You can argue that it only creates value once you analyse that data; you are able derive certain insights from the data that you can then apply to your business in order to become more efficient and effective, in order to create innovation and so on. Having said that, in order to do that analysis you need the data. It goes hand in hand, but analysis is an important element. 
10|Q3|Carl Miller|Social media platforms mainly regard themselves as advertising companies rather than data brokers. There are two models for the platforms. They either advertise— Facebook regards itself as an advertising company—or they sell data. Twitter stands out from all the companies as having a more data-centric view of how it is going to make value in the future, but it is not making that much value at the moment. If you look at the valuation of Twitter, it is 60 times what it currently turns over every year, which is enormous, and most of that is because of the future potential that they see in the data they create and can sell. 
11|Q3|Timo Hannay|May I comment on our business? We make a slightly unusual but hopefully interesting use of social media data. We have a range of young scientific software companies in which we have invested. We have a portfolio of second businesses in which we have invested. The most pertinent to the subject of this discussion is a company called Altmetric, which is a very young commercial organisation that was founded a couple of years ago. Its business is gathering social media data and other data to look at what attention is being paid to the scientific literature, the scientific papers. We are trying to enable a scientific discourse online. It works by gathering data from a range of sources, so it includes social media—Twitter, Facebook, Google Plus, Sina Weibo and so on—and also the several thousand blogs that post regularly about scientific papers and scientific subjects. We use that, together with data from mainstream media, from sources such as Government policy documents, to look at what attention is being paid to scientific papers and what impact they are having. 
12|Q3|Timo Hannay|We sell the business model to publishers; most of the top scientific publishers use our data in order to be able to point their readers and authors to what is being said about the content online. We sell data analytics to universities and other research organisations so that they can see what is being reported about their own and others’ research. We also sell data and analytics to funders who want to conduct similar kinds of analysis. We are not in the business of trying to market to people through social media, or those kinds of commercial pursuits; we are trying to facilitate scientific discourse online through the use of social media data. 
13|Q4|Chair|You will know from some of your scientific publications that, in some scientific disciplines, there is such a mass of data out there that finding reliable ways of analysing the data is quite hard. What is the risk of this analysis of big data becoming simply a big disappointment because it turns out, down the road, that you have got it wrong? How robust are your systems? 
14|Q4|Timo Hannay|It is fair to say that these are early days. As I said, Altmetric, the business in which we have invested that is relevant here, has only existed for a couple of years. The whole area of so-called altmetrics—the field in which people are applying these new kinds of measures, particularly data that you can gather online about the attention being paid to the impact of research publications and research activities—is a new field, so we are still learning about it. It is not just a matter of commercial development; it is a matter of research and development, as we try to understand these data. 
15|Q4|Timo Hannay|That said, it already has value. We already have 50 prominent, and in many cases large, scientific and technical publishers using our data and displaying it alongside their content. We know from surveys, and from more informal reader and author feedback, that people find this information useful. It is useful today, and it is generating revenue and commercial opportunities today, but it is still in its infancy, particularly in its use in research evaluation. You will be aware, I am sure, that research evaluation these days is conducted mainly through analysis of citations in the literature, which is valuable and will continue, but it takes a long time and measures only one kind of impact. What we are trying to do is to measure a much broader range of impacts, and to do so in real time online, through the analysis of these data. 
16|Q4|Timo Hannay|In terms of getting it wrong, the risks are much higher on the research evaluation side, so things are moving more slowly there. We need to be cautious. We need to understand how to interpret these data, and how they can inform decisions around funding, appointments, tenure and so forth. They undoubtedly can, but we need to be cautious, because those are important decisions. 
17|Q4|Timo Hannay|When it comes to helping people to engage in the online conversation around the literature, and helping them to discover papers that they might otherwise not have read but which are getting a lot of attention online, and drawing their attention to that fact, that has value today. That is indisputable. 
18|Q5|Chair|Moving on to public perceptions, a couple of papers ran the headline this morning, “GCHQ are snooping on your Facebook site”—shock, horror! How aware are the public of how data is being collected about them? 
19|Q5|Carl Miller|There really is the potential for a looming consumer crisis around the private sector use of social media data. Demos has done quite a lot of research into public attitudes in the UK, and a paper called “The Data Dialogue” was published a few years ago. It is fair to say that most people have some awareness of the fact that their social media data is being taken up, but it is impossible for them to have a specific awareness—I don’t, and I work in the field—because technology, and therefore what is possible, is moving forward so quickly, but there is a growing sense of unease everywhere. 
20|Q5|Carl Miller|Between 60% and 90% of people questioned about specific uses of social media data are uneasy about how it is currently happening. The reason that this is the case, we think, is that people are not given enough choice about the specific deals that they can strike with data controllers about how their data is used. At the moment, you either use Twitter or you do not; you either use Facebook or you do not; but underlying that is a real diversity of views among the public about what counts as intrusion, what value they think they should get from their data and how happy they are for people to use it. Probably 30% of people are non-sharers; they do not want their data to be used at all. You have 8% who we call enthusiastic sharers, who see no real problem in people using their data however they wish. Between, there are different shades of grey—pragmatists or value seekers, who are looking for value in exchange. At the moment, they do not see that value; they do not see that they are getting the right amount of value for the value they see in their data. 
21|Q5|Carl Miller|This is somewhere the Government can do a lot of good, helping to create a new consumer rights regime around data, with kitemarks and clearer terms of service. If we do not see a more consumer-friendly regime being implemented, we could see significant and systematic withdrawal of consent from people about social media use. We are already seeing social media sites lean towards becoming more and more private, with Facebook profiles becoming more and more closed. For me, as a researcher, that is incredibly concerning, because the value—the innovation—is in having the data public, in having it accessible and allowing people to innovate in finding uses for it. 
22|Q5|Carl Miller|Sureyya Cansoy: From the techUK perspective, the technology industry is very aware of the need to reassure the public about the privacy and security of their data. What Carl said is correct; there is some awareness among individuals of how their data may be used through social media, but perhaps not full awareness. I would like to mention a specific initiative that techUK is actively involved in, which we think will make a positive contribution to the debate. You may be aware of the Information Economy Council, a body that brings together Government, industry and academia to drive the information economy in the UK. It is co-chaired by the Government and the techUK president. One of the key initiatives that the Information Economy Council is looking at, in which techUK plays a priority role, is creating a set of data principles to address how we can reassure consumers in this new digital age without losing the opportunity to get the most out of technological innovations. 
23|Q6|Chair|Do you mean reassure, or do you mean demonstrate that there is a commercial advantage to them? 
24|Q6|Sureyya Cansoy|I think it is both. There is a reassuring element in it, but we are in the early days of putting it together. The work is led by the Connected Digital Economy Catapult, with strong support from techUK and others in the industry. It is very much an industry initiative, proactively saying that trust and confidence are important, and that we need to get that right. They are currently working on an initial set of principles, covering areas such as access, control, transparency and simplicity of message, which play into how aware consumers are of how their data is being used. We are currently consulting on those, and we think that they will be ready later this year, but it is important for us to show that the industry thinks it is an important issue to get right. The other important point to keep in mind is the balance between respecting people’s privacy and ensuring the security of their data, and making sure that we can take full advantage of technological innovation. 
25|Q6|Sureyya Cansoy|If I may, I will comment briefly on the point about the news this morning. We need to be clear about the interception of social media, which is what the news was about today, and the use of social media analytics, which in the large majority of cases is based on anonymised data, to come up with insights into general behaviours and patterns—what people want from products and services and so on. We need to be quite clear that they are two different things. We should not mix security laws with privacy considerations. Both need to be legislated for properly, and laws on them need to be complied with by companies, but we think they are separate issues and considerations. Security is absolutely essential for a free society and an open economy. However, it needs to be done in such a way that there is appropriate oversight and scrutiny around it. We think that is a matter for Parliament and the Government; the companies who are members of techUK always comply with the laws of the countries where they operate. 
26|Q6|Timo Hannay|I want to make a couple of points to add to what my co-panellists said. I completely agree with what Carl said earlier about the fact that users of social media need to be better informed, and I agree that even those of us who are closely involved in it sometimes do not understand all the implications of what is going on. Equally, we as users of that kind of data, and the companies that are gathering it, need to understand what user and consumer expectations are, and therefore what best practice is. I shall give a simple example. 
27|Q6|Timo Hannay|We take a datafeed from Twitter and use that to see what attention is being paid to the online scientific literature. If someone were to delete a tweet, Twitter’s system would immediately tell us and it would get deleted from our system as well. That seems to me to be consistent with what I would expect as a user of Twitter and, in that particular regard, it constitutes best practice. There is a useful role to be played in understanding what user and consumer expectations are, and in setting best practice standards on how we should handle the data. 
28|Q6|Timo Hannay|I reiterate briefly that it is very context-specific. When we talk about the use of social media data, often the case that we have in mind is using discussions I may have with my friends online to sell me something. That is very different from some uses, and I consider our use of it to be an example; people who are engaged in online discussions about scientific literature and scientific results want to engage in a global discussion, and we are trying to make that information more visible. There are what I would hopefully characterise as relatively uncontroversial uses of this kind of data and slightly more controversial uses, and we need to distinguish the two. 
29|Q6|Carl Miller|I have two quick points. The first is that there is a really baffling incoherence between people’s stated views when you do surveys and what they actually do. People say that they are concerned about supermarket loyalty cards, yet they sign up to them in their millions. It is the same with social media. People say that they are concerned about it, yet more and more people continue to sign up to these sites and use them. This is something not very well known about the detail of people’s everyday lives; we don’t know how concerned they are, outside the explicit polling type of setting. 
30|Q6|Carl Miller|Point two is that the most concerning part of the whole data uses industry is third-party data use. This is the bit where people say—again, pinch of salt—that they are most concerned not about the social media platforms using it but how it gets taken to those more mysterious and, to them, shadowy worlds, where people take their data and sell it, resell it and sell it again, packaging it up and selling it again. This is the bit that they know least about and the bit that they are most concerned about, because they cannot actually judge what the implications of this industry are for their privacy. 
31|Q6|Carl Miller|It is clear when you know that someone is reading your tweets and may be analysing them, but what about when a third-party sophisticated data broker using technology that you cannot understand is packaging your social media data with loads of other kinds of data about you, perhaps to create a detailed profile that will then be sold to advertisers or political parties? It is that third-party use where there is the least amount of public awareness and the highest amount of public concern. 
32|Q6|Timo Hannay|And none of us fully understands the implications of that—even the people who are experts. 
33|Q6|Carl Miller|We are struggling with it. 
34|Q6|Timo Hannay|We don’t know where it is going to lead. 
35|Q7|Chair|I have warned some of my colleagues about the things that they sometimes tweet. 
36|Q7|Stephen Metcalfe|I want to go back for a moment to the value question about all this data. Some wild figures are being thrown around. One is that the UK will benefit by £216 billion by 2017 and that it would support 58,000 jobs, but that is about £3.7 million per job. Is that a realistic figure, or is it lots of doubling up, with the same data going round and round? 
37|Q7|Sureyya Cansoy|I believe that that is from a CEBR study, the first study on big data in the UK and its economic value. It sounds realistic, because it is not only talking about it from our perspective. It not only talks about the data analytics tools of the technology industry and the revenues that they get from selling those tools and services to their customers; it also talks about how those tools then help the customers to achieve efficiencies in their businesses, and about achieving better innovation and creating new businesses. I have not looked at the numbers in detail, but when you think about the impact that big data analytics will have, it is not in one specific part of the industry but across the economy. With that in mind, it is quite possible. I think that number is cumulative; it is between 2012 and 2017, a four or five-year period, which is about £40 billion per annum, give or take. 
38|Q7|Timo Hannay|I cannot speak to those figures specifically; I can only speak anecdotally about our businesses and our opportunities. There are big opportunities. If we look in the area of scientific information and research evaluation, the established business is worth hundreds of millions of pounds worldwide in that one area. It is going to be revolutionised by the use of online data, including social media data but not limited to that. Through businesses like Altmetric, the UK is already taking a leading role. We are ahead of the curve compared with our competitors and colleagues on the other side of the Atlantic and elsewhere in Europe. 
39|Q7|Timo Hannay|There is a huge opportunity. The businesses that we run are early stage but growing rapidly, so we will have three times more staff at Altmetric at the end of the year than we had at the beginning, with about five times the revenue. It is from a low base, but it holds huge promise. It is important, and it is a source of huge economic value, quite apart from the fact that the usage that we are making of the data is itself trying to support scientific endeavour, which of course supports economic growth and other forms of social and intellectual progress. 
40|Q7|Carl Miller|The main value that we see in real-time social media analysis is in social research. For us, the growth of all this data in social media is the datafication of social life. It is the first time that all the things that happen everywhere in society have come together in a way that is inherently amenable to analysis and collection. 
41|Q7|Carl Miller|The commercial social research market is valued at about £3 billion to £7 billion a year, depending on how you value it. Real-time social media analysis, and even just social media analysis, has had strikingly little impact on this market up to now. Ten of the largest providers in that market account for about 6% of the total value. Social media research is a very small part of their business, so what we have seen is a growth underneath that, which is social media only—analytics companies, dashboards and so on. These have had a great impact on marketing and advertising in a few specific fields, but little wider impact throughout the whole of the business area of social research. That points to an important disjuncture, which is happening currently: social media is not having an even impact across either the private economy or across the whole of society. 
42|Q7|Carl Miller|At the moment, a few fields are completely redrawing their business models on the basis of the exposure of this data, but within civic society and especially within Government we have seen very little innovation indeed. There is so much more value that can be got from Government and the civil service using all of this incredibly valuable data, because of the many things that they do. Every Department has a stake in understanding what people think, and that is not currently happening. There is much more that the Government can do to support innovations in the public sector, helping to take the skills out of these concentrated little hubs of expertise and technological capability and moving them to companies, civic society, charities and people working for the social good, to allow them to get value out of this too. 
43|Q8|Stephen Metcalfe|Despite what the Government are saying about adopting big data as one of their A-grade technologies, you are saying that it is not happening. 
44|Q8|Carl Miller|It is not being used by the public sector. We have seen a visible increase in support for this within academia. In the “Eight Great Technologies” paper, I notice that social media is not mentioned as a distinct discipline. That is slightly worrying, because in my eyes it is a distinct discipline. It does not just come under the umbrella of big data; it is a new academic field and a new discipline within research, and, in my view, it should be a new profession in the civil service. It does not yet have that coherent body of expertise, so we are not seeing it emerge as a distinct and coherent community, a distinct and coherent set of skills or a body of technologies. At the moment, a sprinkling of practice is happening in disparate areas across the economy. 
45|Q9|Stephen Metcalfe|You do not share Mr Hannay’s optimism about Britain being well placed to make much of this. 
46|Q9|Carl Miller|I think that we are. My experience in the EU, where we certainly have a strong higher education sector and lively tech innovation hubs, is that we are considered leaders. But the UK can take a step forward to bring together all the expertise that happens into something more coherent and more disciplinary, more recognisable as social media science or a social media analytics discipline. That is what we are lacking, in my view. 
47|Q9|Timo Hannay|There is absolutely a skills gap. It is not limited to the public sector, which you are more expert on than I am. Today, we constantly have unfilled technical positions; we need people who can bridge the divide between computer programming, data analytics and, in our case, scientific research and research evaluation, and that is a challenge. Admittedly, we are in a particular scientific software niche, but the changes that we are talking about apply to scientific research generally. We need researchers who are more expert in data analytics and computer programming. It is changing every domain of society, so I completely agree with what Carl has been saying. There is a skills gap; we see it and feel it, and it is evident in other areas too. 
48|Q9|Stephen Metcalfe|I think we are going to come back to that. 
49|Q9|Sureyya Cansoy|I support that view. Talking to techUK member companies that provide these tools, the anecdotes that they tell us show that they believe the take-up of such tools is relatively strong in the private sector, particularly in sectors such as retail, retail banking and transport, but they think that take-up by the public sector is low. The UK Government have come up with a number of encouraging initiatives around open data and big data. However, I echo what Carl said; so far, in our view, they have not really used the full potential of social media analytics, or big data analytics broadly speaking, for the benefit of the public sector in delivering better services, and more effective and efficient services, to people. 
50|Q9|Sureyya Cansoy|I assume that we will come back to the skills question, but we also agree with the comments on the skills gap. I will leave it at that until we come back to it. 
51|Q10|Stephen Metcalfe|On the public sector issue, do you see any improvement? 
52|Q10|Carl Miller|There are courageous civil servants in most Departments who are trying to innovate in this area. They believe in evidence-based policymaking; they see all this new evidence and want to learn how to use it, but there is not the technology or skills within the civil service. I genuinely believe that they are not being supported in how to innovate by senior leadership in some Departments. In my view, the civil service has to react to this. There need to be defined experts. 
53|Q11|Stephen Metcalfe|I understand that. 
54|Q11|Timo Hannay|Could I comment briefly on the subject of Government? In some ways this is only tangentially related to social media, but we use Government information and we welcome open Government data. It is incredibly valuable, and a driver of innovation and progress, but Government can learn things from some of the social media companies in the way they release data. For example, we index Government policy documents from the NHS, the WHO, the IPCC and so forth, but it is a lot harder to deal with than our datafeed from Twitter. There are some things that the Government can learn from those kinds of organisations and the way they make data available to organisations like us. 
55|Q12|Stephen Metcalfe|I have one final question, Chair, because I am very conscious that time marches on. From what I gather, the one measure that would improve the UK’s prospects of making the most of this would be to get the public sector more engaged with using this technology. 
56|Q12|Sureyya Cansoy|Yes. 
57|Q13|Stephen Metcalfe|Does it make any difference to the fact that this data is being held by American-based companies as opposed to UK-based companies? Is that a barrier to us making the most of it? 
58|Q13|Sureyya Cansoy|I do not believe so. The social media world is very much a global one. The data can be obtained in a number of ways, but I guess that there are two common ones. One is using the analytic tools and software available to analyse publicly available data. Because some of the social media data is publicly available, it can be analysed anonymously and collectively to come up with insights about trends and so on, and not necessarily about individuals. Another way that it can be done is by purchasing anonymised datasets from the companies in question. Having spoken to our members, I think that they make a lot of use of openly and publicly available data, and to a degree they purchase some of the anonymised data, but I believe that the cost may be a barrier for some businesses. 
59|Q13|Timo Hannay|I don’t think there is a particular issue with whether the companies are American or British, or from anywhere else. For us, the issue is more around the degree of competition and choice. For us, as data consumers and users, the question is: can we access this data from a number of sources, do we have choices, and even more important for the consumer and users is do they have a choice? That, for me, is much more of an issue than the nationality of the business. 
60|Q13|Carl Miller|For researchers and academic tech innovators, there is an issue around collective bargaining, as they often do not have the budgets to allow them to acquire data in the way that private companies do. The Economic and Social Research Council was going to put out a particular call on social media that would allow that kind of stuff to happen—to allow the UK higher education community to come together collectively to bargain with the social media companies. Disappointingly, that has not come about yet; lots of universities would like a little more help in acquiring some of this data. 
61|Q14|Graham Stringer|Will the right to be forgotten affect the way that you do business? Will it affect your companies? 
62|Q14|Sureyya Cansoy|I shall respond from the tech industry perspective as briefly as I can. In terms of the whole debate around the right to be forgotten, there are two angles. There is the recent European Court of Justice Google ruling, requiring the search engine to remove links to certain data if requested by an individual. The second one is in the proposed EU data protection regulation, where I believe there is a new clause that deals with the right to be forgotten. 
63|Q14|Sureyya Cansoy|We understand that it is an issue for consumers, particularly in the social media context, where younger people may want to remove certain data as they get older or move into professional life and so on. However, I have been looking at the European Court of Justice ruling on Google, and we think that there are a number of practical challenges with it, and we do not think it is the right mechanism to deal with what it is trying to address. In the interests of time I shall not go into detail, but the fact that it only removes the search link to the data and not the data itself is a major drawback; and another is the fact that somebody needs to make a decision about whether the information is in the public interest and should be retained, or whether the link should be removed. There are a number of other challenges around, but in the interests of time those are some of the key ones. 
64|Q15|Graham Stringer|I may not understand the arguments, but I understand the issues involved. What I really want to know is whether it will affect your businesses at all. 
65|Q15|Timo Hannay|We do not see it as particularly affecting our business. We want to be able to abide by any reasonable requests that users may make to remove things. I gave the example earlier that if you delete a tweet it gets deleted from our system automatically. That is a simple example of the same sort of thing. However, removing all information from the internet is difficult, needless to say, so we have to be pragmatic about it. What we will see over inevitably a long period of time, I hope, is that attitudes to this kind of information—things that people may post that they regret later, for example—will be considered more normal, because most of us will have fallen victim to it at one time or another, so the right for it to be forgotten may ultimately be overtaken by the right for it to be forgiven. In practice, it is difficult to completely remove all information from a global online network. That is a pragmatic point. 
66|Q16|Graham Stringer|You talk regularly—it is the basis of your business—about having access to lots of social media data. Doesn’t that data belong to the websites themselves—to Twitter and Facebook? 
67|Q16|Timo Hannay|Yes, so we license it from them. 
68|Q16|Carl Miller|It still belongs to the user, technically, so it is the users’ data that they have licensed to social media platforms, essentially to be able to use how they want. Basically, we acquire it from them but it is still owned by them. 
69|Q16|Sureyya Cansoy|My understanding is that, in the majority of cases, the data provided are large sets of anonymised data. Once data is anonymised at that scale, it is no longer subject to data protection rules and constraints, because a person is not identifiable by the data. I believe that the Information Commissioner’s Office made a useful submission to your Committee, highlighting some of those issues. In terms of personal data, yes, of course it belongs to the individual; however, anonymised data provided at that scale is different from personal data. 
70|Q16|Timo Hannay|To be clear, the data that we and others access does include information about, for example, your Twitter ID. It is the same information that you would find on the public Twitter website, but it is available in a machine-readable format that we can use and analyse. We can therefore link to users’ Twitter accounts, for instance when users have commented on a particular research article. It is pseudonymous in the sense that you have no information other than their identity and their self-description on the system—you do not necessarily know who they are—but it is not completely anonymous in the sense that it is aggregated and you cannot tell one user from another. 
71|Q16|Carl Miller|I have one quick point about data availability. There is a massive inconsistency between platforms about what data is available. Twitter is the only social media platform that currently has its own “ology”—its own body of study about it—and that is because it has made its data much more available than nearly any other platform. Realistically, if you are looking at one of the services that bring in all the data that is conceivably available and make it accessible to people to use, 60% to 70% of the entire ecosystem will be Twitter. Facebook is much more difficult to acquire data from; there are many more privacy implications with it. It is not actually part of Facebook’s business model to make its data available in the same way. It is an advertising company fundamentally, not a data science company. 
72|Q16|Timo Hannay|Of course, we make use of the data under licence terms with those companies, so they will put certain restrictions on what we may and may not do with the data. Among other things, that will help them fulfil their obligations to their users under the terms of use on their website. 
73|Q16|Sureyya Cansoy|In addition to complying with the necessary laws and regulations, an increasing number of companies are concerned about ethics questions. It is not only “Can I actually do this under the law?”, but “Should I do this? Is it a fair treatment of the data?” Most companies involved in the analytics of such data are taking a much stronger stance on the ethics question as well as on compliance. 
74|Q16|Carl Miller|The industry has failed, as yet, to create a set of best practice guidelines. 
75|Q16|Sureyya Cansoy|We are hoping that some of the work that we are involved in through the data principles will address that, as I outlined earlier. 
76|Q17|Graham Stringer|You touched on this in your earlier answers, but do you have concerns that the data you are collecting has not had informed consent from the individuals concerned? 
77|Q17|Timo Hannay|I am somewhat concerned about that. As I say, the use to which we put the data would, I hope, be considered by most people as uncontroversial, but it would certainly give us greater comfort if there was as much transparency as possible in how the data were being used, and that people were aware of that. 
78|Q18|Graham Stringer|Do you think that that would come from the original contract with the website? 
79|Q18|Timo Hannay|Possibly, yes. I do not have a strong opinion about the mechanics of how it should happen, partly because there is such diversity of data sources and services that it differs according to which website or service we are talking about. It would inevitably have to involve them, because they are the ones with the relationship with the user. 
80|Q18|Carl Miller|There was a wonderful statistic that if you read all the terms and conditions on the internet you would spend a month every year on it. I would love to see a kitemarking regime, where an independent body could authenticate whether or not the terms and conditions were clear. That is a basic responsibility for a platform. For us to have confidence that informed consent has been given between the creator of the data and the platform, we need to know that the terms and conditions are clear enough for that person to understand what is happening. The big concern is that technology is moving so quickly that informed consent, in the sense of knowing all the things that it is possible to understand by that data, is changing so rapidly that I do not know how it can be publicly achieved. 
81|Q19|Chair|It also needs to be consistent with the law of the country where the person resides. 
82|Q19|Carl Miller|Right. It is incredibly tangled. Legal jurisdiction is meeting rapid technological change and globalised information architectures. It is a really tricky problem, and informed consent in those conditions is something that is far from being clearly secured. Having said that, with some platforms, like Twitter, it is so unapologetically open; the first line is something like, “If you tweet, you are asking Twitter to make your tweet as public as possible. You understand that your tweet can go around the world.” Clear statements like that are helpful in informing people’s reasonable expectation about what can happen and what is possible with their tweets. The other reason that Twitter has its own “ology” is that, ethically, it is clearly the most straightforward source of data to use. 
83|Q19|Mr Heath|I wonder whether anyone has ever met anybody who had read all the terms and conditions before clicking on “I agree.” 
84|Q19|Chair|Or who understood them. 
85|Q20|Mr Heath|They will not understand them if they have not read them. 
86|Q20|Mr Heath|I think you are suggesting, Mr Miller, that Twitter is open about the purposes that it sets out for itself. I wonder whether other companies gather information at an early stage with a view to retention and sharing, or whether that is a secondary consideration—that the information is there and they then see whether it is useful. Do you see the difference between the two? I just wonder whether companies get unnecessary information from their clients, with a view to seeing who it is going to be useful to. 
87|Q20|Carl Miller|We are certainly seeing a subtle pivot towards more data-centric business models. That is because every time someone innovates a new way of using Facebook posts or tweets or anything like that, they make that data more valuable. Social media began basically as an advertising industry; it began as a way of bringing people to a place where you could advertise to them in ways that were highly defined and specific. Now, most social media platforms are looking at ways of leveraging their data that would be much more valuable than that, to gather and sell. The big data mentality is that if you have data, you want as much as possible. The basic premise is that data is valuable. For lots of companies, it is not just a platform; they are gathering as much data as they can get hold of, because they know that it is going to be valuable in future. 
88|Q20|Timo Hannay|Certainly that is the incentive. The simple answer to your question is that I do not know. By definition, if they are not making that data visible—at least not yet—we do not know what data they are gathering. The concern is, first, that it is opaque and, secondly, that the incentive is to gather as much data as possible precisely for the reasons that you explained. 
89|Q21|Mr Heath|When they gather a lot of information, the concept of anonymity becomes a bit of a nonsense, doesn’t it, given the technology that we have for putting a number of disparate bits of data together? I was going to mention earlier the Information Commissioner’s view on anonymity; I just do not believe in anonymity. 
90|Q21|Sureyya Cansoy|We had some further discussions with our member companies better to understand this point. We think that, overall, anonymity strengthens the privacy of individuals, as they are no longer personally identifiable. Of course, there is the possibility that, by merging more than one dataset, you may be able to re-identify some of those individuals. We have seen some examples, which we cited in our submission to you. 
91|Q21|Sureyya Cansoy|Having had further discussions with technology companies who understand this really well, their take on it is: “What is the motivation behind merging those different datasets to re-identify people?” If the motivation is just to show that, academically, it is possible to do it, then, yes, it is possible; but evidence of it happening on the ground is very limited, which is supported by the Information Commissioner’s Office. However, a greater risk is if somebody is after personal data or identity for criminal purposes. According to our member companies, it would be much quicker and faster to use cyber-attacks and hacking to obtain the information than to combine different sets of anonymised data. That tells us that perhaps it is much more important to focus on the security of the datasets being held. That is the view that we got from our companies. 
92|Q22|Mr Heath|I am sorry, Mr Miller; I interrupted you earlier. 
93|Q22|Carl Miller|There are two quick points. The datasets that we gather, as Demos and CASM, are large and aggregated. I do not care about individuals; I care about broad social trends, so I am not trying to identify anyone. I care about how people react to a policy announcement or a speech and stuff like that. 
94|Q22|Carl Miller|De-anonymisation is a technology; there are ways in which you can attack anonymity, and they are being sketched out in the EU data protection regulations at the moment. It is always going to be a changing field; there will always be an arms race between anonymisation techniques and de-anonymisation techniques, to try to find the find the right strategies to anonymise when you need to that are both not too onerous on the company and also relatively impervious to it. There have been a few mini-scandals, where academic papers using so-called anonymised data were published, yet within hours people managed to work out who the people were. It is a constantly changing landscape. 
95|Q22|Timo Hannay|A rule of thumb is that you should assume that any data out there publicly, even if it has been anonymised, will potentially become de-anonymised. You never know what technologies or other information will become available. It is dangerous to assume that so-called anonymous data will remain anonymous, so I agree with the premise of your question. 
96|Q23|Mr Heath|Mr Miller, you mentioned EU legislation. We have the Data Protection Act. Is it fit for purpose? Does it get the balance right at the moment in terms of the burdens that it places on the industry and the protection of the individual? Will the proposed EU legislation pose difficulties or is it moving in the right direction? 
97|Q23|Sureyya Cansoy|I shall try to answer that from the techUK perspective. Having spoken to several technology companies, we believe that the UK data protection framework is broadly fit for purpose. Having said that, we need to consider the implications of the new digital age on laws that came into force before then. There are a few suggestions from member companies on how that can be addressed, for example, in terms of guidance rather than additional legislation, which we touched on in our submission to the Committee. 
98|Q23|Sureyya Cansoy|In terms of the proposed EU data protection regulation, we completely support the need to have a robust, flexible and fit-for-purpose data protection regime. I cannot stress enough how important this is for the technology industry. We need to assure the customers of our members of the privacy and security of their data. We also understand, as I said, that the new digital age means that rules that date back 20 or 25 years need to be looked at again. However, we think that the proposed EU data protection regulation is not the right mechanism. As it stands, we think that it would be very damaging to businesses across industry—the tech industry definitely, but also a number of others. We believe that it would hit jobs and growth. An estimate by Deloitte suggests that the EU could lose as many as 2.8 million jobs as a result. 
99|Q24|Mr Heath|Is that figure just plucked out of the air, or does it have some substance? 
100|Q24|Sureyya Cansoy|I do not know the basis of the calculation. We can look into it, but the gist of it is that it will affect companies significantly. It is very evident. We have been speaking to large and small companies, British and international, and anecdotally I can give you an example. 
101|Q24|Sureyya Cansoy|One successful small British cloud company, which started around three years ago, grew from two to about 50. Discussing the implications of data protection on their business, they told us that if the proposed EU data protection regulations had been on the table when they were setting up their business, they would have thought hard before taking the risk. It is possible that they might have decided not to go ahead, to the degree that they thought that it would be very burdensome for businesses. It is an area where we are doing a lot of work, so if you would like further details we would be happy to provide them. 
102|Q24|Sureyya Cansoy|One good thing is that the Ministry of Justice understands that the current draft is not what we need. We are working closely with them to make sure that whatever regime we end up with is one that works for individuals in protecting their privacy but also allows technology companies to innovate, as well as allowing other industries to operate within those premises. 
103|Q24|Timo Hannay|We do not find the current UK data protection framework problematic in any particular way. I am not familiar enough with the EU proposals to comment on them specifically, but I would say that for us the confidence and trust of the users who ultimately provide this information is paramount, while trying to avoid anything that is too heavy-handed and bureaucratic. The heavy hammer of legislation, although an important way to deal with this issue, is not the only way. I refer to some of the things that we discussed earlier on understanding user expectations, and identifying and encouraging best practice. Those things are just as important as legislation. 
104|Q24|Carl Miller|The major concern that I have with the regulation is that it is hard to see how that body of abstract legal provisions will play out technologically and in practice—how it would change the architecture of social media platforms, what new technologies would be required, what judgments it would be asking social media sites or data controllers to make. There is a lot of uncertainty, which is of course not what you want when you are trying to discuss a law. Broadly, I agree with the other two panellists that there is a simmering concern that it is going to be burdensome and hostile to growth. 
105|Q24|Carl Miller|It is important for a clearer public case to be made about the social good of big data and social media research—all the things that it can do for people, such as delivering better health, and more agile and responsive government. That requires it to be used in areas where it is not used at the moment, and for it to be used in areas that are concerned with delivering public goods. Inevitably, it is going to come down to people balancing individual privacy with other public goods that they think are important, but at the moment I don’t think people see the value of having their data being sucked up in huge quantities and crunched. Basically, they think that that is for private profit for large and sometimes quite opaque big data analytics firms, rather than for them. 
106|Q25|Pamela Nash|I want to look at the reliability of data, and how that impacts on how the data is used. We have had evidence of concerns about data being cherry-picked by researchers to suit their own ends and the results that they wish to have. Do you share that concern? Are tools available yet, or being developed, to help us to spot when it is happening and to tackle the problem? 
107|Q25|Carl Miller|There is the question of inadvertent and deliberate manipulation or challenges to reliability. The larger concern that I have is not the deliberate manipulation of data, but the fact that methods across the whole of the industry are young and weak and often cannot do the job. It is not just the fault of the Government that these methods are not being used within the public service; the methodologies that exist right now cannot usually satisfy the evidentiary requirements of public policy makers. 
108|Q25|Carl Miller|Yes, I have concerns. The first concern is that black box techniques are used. With technologies that can crunch and understand big data, there is very little clarity for many people, including users, about how they work and what they are actually doing. With most of the services out there, you can plug in some words on one side, you cannot really tell how the calculations happen, and you might get a graph coming out on the other side. Exposing those black box techniques so that everyone can understand how that analysis happens is important, and I think it is possible. Despite the arcane and often complex mathematics and technologies that are involved, it is possible for people to understand how big data analysis works. 
109|Q25|Carl Miller|In terms of deliberate manipulation, we are seeing a fair amount of automated production of content on social media, so it is likely that one in 10 Twitter accounts is fake. You can go out and buy Twitter followers if you want, and I have been tempted to do it many times. You can buy millions of Twitter followers to make yourself— 
110|Q26|Pamela Nash|I was going to ask about that, but it is different from cherry-picking the information that is available; we are talking about manipulating data that is online. 
111|Q26|Carl Miller|On the cherry-picking point, the difficulty is that, as a researcher, you cannot publish the datasets you have studied, because it is against the terms and conditions of the social media sites. In science, you obviously analyse a dataset and then make the dataset available so that people can see how you selected the data. We cannot do that. I have never encountered deliberate cherry-picking in research, but it is certainly possible and it is hard to verify. 
112|Q26|Carl Miller|You have automated data being created, and many states are stepping into this game now. We have seen a number of calls, made openly and issued by national Governments, for technology to allow analysts to behave, for example, as if they were 1,000 or 10,000 Twitter users. As we see Twitter and digital fora becoming more politically and socially significant, we are going to see increased interest in being able to manipulate the content. That said, there But there are corrective mechanisms. 
113|Q26|Carl Miller|There are three important layers where people are working on how to identify and correct this kind of stuff. You have technological responses; the same technology for national language processing, which is used to generate automatic data like language on social media, is also used to detect it. You then have methodological responses; a lot of researchers are now triangulating data, and this is something that they are increasingly going to do. If I want to present to the Committee social media research on attitudes, I will do so alongside conventional social research, as a way of trying to compare all these new and unfamiliar methods with the more mature, older, more conventional and trustworthy ones. 
114|Q26|Carl Miller|Then you have use. This is a really important one. Decision makers, whether in the private or public sector, are going to have to grow more familiar with the idea of using outcomes that are uncertain. A lot of the big data technologies that are being used are inherently probabilistic; they are predicated, for instance, on Bayesian mathematics, which basically gives you a result that has a confidence score attached to it. We are going to see an increasing epistemological shift, as it were, away from outcomes with evidence that is certain and clear, towards evidence that is shrouded and surrounded by a cloud of caveats and confidence scores. We are going to have to become more comfortable with uncertainty, as well. 
115|Q26|Timo Hannay|We, too, are more concerned about the gaming of systems than about the cherry-picking of data. Regarding cherry-picking, we try to gather data from as wide a range of sources as possible, and we try to detect every mention of scientific research that we possibly can, but we do not get everything. Sometimes our users and customers tell us about things that we have missed and we try to add them back in. We are trying to be as comprehensive as possible, and certainly not to cherry-pick in any way. 
116|Q26|Timo Hannay|When you are using this kind of information, and directing people to relevant material or research, particularly if you are using it in some kind of research evaluation, which will come in the future, there are concerns that people can game the system. If they think that by tweeting or writing on Facebook about their own research they will get more readers and that ultimately their funders and employers will see it, there is an incentive to try to game the system. 
117|Q26|Timo Hannay|We also have to bear in mind that current systems, particularly around citation analysis, are gamed already, so people self-cite; publications self-cite. The answer is to use a wide range of different sources and measures, and that is what we are developing. We do not just use social media; we use mainstream media and policy documents, and we are moving on to patents, for example, to look at the impact of research. Within social media, we do not use only one source; we use as many sources as we can get hold of, which reduces the chances of gaming. In addition, we use algorithms to detect gaming. If you keep tweeting about one particular journal, we surmise that you are probably the publisher or editor of that journal, and we will downgrade those tweets accordingly. 
118|Q27|Jim Dowd|I want to go back to what was said earlier about skills, but before doing so I want to look at the terms and conditions issue that arose earlier. I was leafing through my Sky television a couple of weeks ago, updating software of some kind or another, and I went on to the page headed “Terms and Conditions.” It helpfully said up front that it was 110 pages. That immediately deflected me from pursuing it any further. Okay, we live in inordinately litigious times, and, as you said, Chair, there are all kinds of jurisdictions where these things have to apply, but it occurred to me that although it is not a deliberate attempt to mislead, it does mislead, because effectively people do not engage with it at all. That gives the company—in this case Sky, but also Twitter and Facebook and the rest—the opportunity to do whatever they like with the consumer and the information they derive from them. Is that your feeling? 
119|Q27|Carl Miller|Some social media sites have taken some positive steps. If you go to Twitter’s terms of service, there is more of an effort to state them in plain English, but you are right: there has been little incentive for many platform providers to do anything other than issue 100-page documents, because everyone clicks “Yes.” That pressure, that incentive, has to come from outside the company. That is why, in addition to EU data protection regulation, which is very-rights based, a consumer protection regime is important. 
120|Q27|Carl Miller|It is not particularly clear what role the Government have to play in that, other than supporting it, but we certainly ought to have kitemark terms and conditions, where companies are incentivised to put in plain English in a few pages what the implications of people putting their data on those platforms really is. I do not see why it cannot be done. 
121|Q27|Timo Hannay|I completely agree. It is a huge issue. It is an issue for me as an individual in my personal capacity, as well as in my professional capacity. I agree with Carl; we should be identifying and rewarding best practice. That is the way to do it. 
122|Q27|Sureyya Cansoy|We agree with that. One of the key things that we are looking at as part of the data principles is the importance of simplicity and transparency, so that people understand what they are signing up to. We are completely behind that. 
123|Q28|Jim Dowd|Mr Hannay, you mentioned the skills gap and numerous vacancies in various regards; and, Mr Miller, you said that this data-mining, as it effectively is now, is developing in an almost random fashion, with no discipline and no strategy. The Government have come forward with the data capability strategy. I am not sure how familiar you are with it, but do any or all of you feel that it is of any value? 
124|Q28|Sureyya Cansoy|First, having the right skills is absolutely essential to maximise the benefits from social media analytics. There are some interesting numbers about how big that gap is. For example, one number from e-skills is that they expect big data job vacancies to grow by 23% annually by 2017, in three years’ time. 
125|Q29|Jim Dowd|What is the base for that? You say 23% growth, but what kind of numbers do you have? 
126|Q29|Sureyya Cansoy|We are talking about annual growth of the actual big data job vacancies available—how many big data jobs are advertised every year and the percentage growth. That is what it reflects. I can provide further information afterwards on the number. 
127|Q29|Sureyya Cansoy|Another number that we have seen suggests that 57% of recruiters dealing with big data vacancies say that it is difficult to find people for the jobs they are looking to hire for, and anecdotal evidence from techUK member technology companies that we have spoken to suggests that there are some talented and skilled people out there, but they seem to prefer to go to start-up companies and are not necessarily willing to work in established organisations or for Governments. With that in mind, it is quite clear that there is definitely an issue that needs to be addressed. 
128|Q29|Sureyya Cansoy|Another point is that the skills issue, in terms of digital skills in the UK, is broader than just data analytics or social media analytic skills, and it is a top priority for both techUK and the Information Economy Council. There are currently 1.1 million digital skills people in the UK economy; techUK and e-skills predict that we will need another half a million by 2020 if we are to maximise the benefit from the information economy. That is quite a substantial gap across the board. 
129|Q29|Sureyya Cansoy|In terms of the data capability strategy itself, it was produced by the Government jointly with the Information Economy Council, and the industry and academic institutions had the opportunity to contribute. We think that it addresses the right areas. It starts by asking what skills are needed by the industry, where are the gaps and where is action needed, and what needs to happen in schools, higher education, apprenticeships in terms of promoting the reputation of the industry and so on. It talks about industry, Government and skills bodies all having a role to play in getting it right. 
130|Q29|Sureyya Cansoy|We think that the raw actions are broadly right. With anything like this, the proof of the pudding will be in the implementation of those actions. One of the things that we would like to highlight is that the sector skills council for the technology industry in the UK should have an important role to play in making sure that some of those actions are implemented. There is also the importance of continuity beyond 2015, should there be a change in Government, for example, because this is not a short-term issue and actions should not be short term. 
131|Q29|Timo Hannay|I shall speak to our on-the-ground experience, which is necessarily anecdotal but hopefully informative. We certainly find that London is a great place to set up these kinds of businesses. A great pool of talent is attracted here. 
132|Q30|Jim Dowd|May I stop you on that very point? How much of it is indigenous or locally generated, and how much is attracted from abroad? 
133|Q30|Timo Hannay|The Digital Science office in London has about 70 or 80 members of staff, and we reckon that there are about 12 nationalities, and probably about 20 languages spoken. They come from far and wide, and that is incredibly important. The fact that London attracts people from around the world was very significant for us in setting up here. 
134|Q30|Timo Hannay|That said, demand outstrips supply, and we expect demand to go up because of some of the macro-trends that we have been discussing. We are based in King’s Cross. Google are building their new UK headquarters just down the road. They are going to be employing a lot of technical people; we hope that will attract people, but also that it will provide competition for the best staff. Altmetric, which I mentioned earlier, currently has 11 staff but seven vacancies, of which five are technical—essentially developer and data analytics-type roles. That gives you some indication of the difficulty that we are having in getting the high calibre of person that we are looking for. 
135|Q30|Carl Miller|Within data science there is a shortage, but that is understandable; there has been an explosion of this new discipline, and suddenly incentives have changed. We are seeing secondary schools with the new computing syllabus, and both undergraduate and postgraduate courses are changing—quite rapidly for the higher education sector—to meet these new demands. 
136|Q30|Carl Miller|The concern I have is that at the moment, in terms of skills, social media analysis is being treated like a branch of big data, or data science, but strictly speaking that is not true at all. In my view, social media analysis requires a hybrid skills set. This is both a social and a computational science. It requires people who understand both culture and people, and also all the new ways in which we can handle data that is unprecedentedly dynamic and large. At the moment, my concern is that if you simply see social media as part of the “eight great technologies”—if you simply see social media research as part of the UK data capability strategy—we are going to get very good at counting things from social media, but we are not going to know very well what we are counting. 
137|Q30|Carl Miller|Within the field of research, which is feeding all the economic activity that is going on, we are seeing the numbers game galloping ahead of the squishier, softer, slower social scientific work that happens underneath that, and that is going to be an important brake on growth. That is the reason why it is not being used more broadly across the economy. 
138|Q31|Jim Dowd|There is no real attempt to grow specialism itself; it is just an assumption that we will get talent from elsewhere, which can be adapted. 
139|Q31|Carl Miller|There is no consistent attempt or incentive to break down the disciplinary boundaries that currently stand in the way of getting the hybridised skills sets required to do the everyday job of getting insight from social media. It is not something that computer scientists can just sit down at a computer and build algorithms for. Social media is a new cultural space, and it plays by different linguistic rules. 
140|Q31|Carl Miller|To understand behaviour on social media—to do things like predicting what is going to happen in future, to model and to understand attitudes—is a new and distinct discipline, and it forces the meshing together of both social and computational sciences. My worry, and the reason it has not yet been applied beyond the advertising, marketing and retailing industries, is that if you are a policy maker you get a smorgasbord of metrics—raw metrics, numbers. You will get some numbers about how many people were positive or negative, and you will get some numbers about how many shares were happening, but in the social sciences the serving up of raw data is the beginning of the story, not the end. No social scientist would ever accept the presentation of data as an adequate description of what is going on. We have to throw these disciplines closer together. That is a challenge for the higher education sector above all, but I am concerned about this being treated basically as a small branch of data science. In my view, it is not that. 
141|Q31|Sureyya Cansoy|We think that different skills are needed in the technology industry, which produces the software and tools to enable the analytics, and perhaps different skills are needed in the organisations that use the software and tools to come to the sort of insights that they need for their business or organisation. I agree with Carl that we need a mix not only of technical skills but, depending on the business that you are in, perhaps a knowledge of the business that you operate in and the kind of insights you are trying to get with that analysis. 
142|Q31|Chair|Thank you very much for such a comprehensive set of answers. I am sure that there will be other things that you can feed in as the inquiry goes on. Thank you. 
143|Q32|Chair|Good morning, and thank you very much for coming. I think that all three of you were listening to at least part of the earlier exchanges, so you have the gist of our direction of travel. First, I ask you to introduce yourselves for the record. 
144|Q32|Professor Yates|I am a professor at Leeds University, and I work on the ESRC-funded consumer data centre. In a previous life I was at Dunnhumby, which you may or may not know is the company behind the Tesco club card. 
145|Q32|Dr McPherson|I am Ella McPherson. I am an ESRC fellow at the University of Cambridge in the department of sociology. 
146|Q32|Professor Preston|I am John Preston. I am professor of education at the University of East London. My area of specialism is disaster education and public response in disasters. 
147|Q33|Chair|We are talking this morning about social media, and one of the areas that we are particularly interested in is how Governments and governance could be improved by smart use of social media. Is it possible to see some gains? 
148|Q33|Professor Yates|First, there is a distinction that was not made by the first group between social media and big data, in the sense that social media, generally speaking, is unstructured—the photograph that you put on Facebook, the colours of your shirts and so forth—whereas most big data historically is structured datasets, such as till records, census records and so on. You have an opportunity to take the structured and the unstructured. 
149|Q33|Professor Yates|In a commercial sense, if you knew what colour shirts you liked, you could make a better promotional offer, based on your Facebook pictures. In the social science sense, you can do the same thing: attitudes. What are people’s attitudes to different kinds of food? Where do they go? How do they visit and what methods of transportation do they use? That will come out of social media, but it would not necessarily come out of structured datasets. If you put those two things together, you have a rich way of thinking about consumer behaviour, which goes well beyond business. 
150|Q33|Dr McPherson|Our perspective on this is that social media data is a complement to other sources of data that the Government are already using. We think that it should be used in addition to, not as a replacement for, other methods of inquiry such as interviews and surveys. 
151|Q33|Professor Preston|In terms of my research, which is on how social media could be used in a disaster or emergency, I would agree that it is not a panacea for Government, but you have to be careful in the ways you use it. It does not work, for example, in warning and informing the public of a crisis, where old media such as radio and television, are much more effective. It does not work in terms of helping people to organise themselves in terms of a large-scale event like the evacuation of a city; there we found that social media could disrupt the evacuation and cause congestion. Where it does work is in terms of helping policy makers in Government understand how a situation unfolds, to look at how populations are responding during a disaster or emergency and during the recovery, to put resources where they are best used. You have to be careful how you use social media in an emergency situation, but it is of use. 
152|Q34|Chair|Leaving aside disasters, those are interesting comments on how other situations unfold, evolve and develop. Are there examples, outside the ones that Professor Preston gave, where social media could be a useful tool in planning Government responses? 
153|Q34|Dr McPherson|One area where social media has proven to be very useful is in understanding what is happening in closed societies or countries under conflict. You were talking before about issues to do with data manipulation. That is always a problem, but in scenarios where previously it had been difficult to get information out of situations, social media is proving to be a way to access it and to get some idea of what is going on in those scenarios. 
154|Q34|Professor Yates|You could also use social media to understand how ideas flow through systems; people swap ideas, change ideas, improve ideas. As a way of gauging innovation in a system, you can look at what is happening and what people are saying. In theory, you could also use it to stimulate innovation if you were part of the process of communication itself. 
155|Q35|Chair|I ask this question as somebody who is over 65, who has a Twitter account and Facebook account and who is “LinkedIn.” Are there problems interpreting the data about some demographic groups within the population? 
156|Q35|Professor Preston|Certain demographics use social media a lot less, and even if people count themselves as social media users, we distinguish between heavy users of social media and those who might have put down only one or two tweets in their lives. It is not only an age thing; it is also socio-economic status and ethnicity in terms of the users of Twitter or other social media, so you have to be careful when you interpret the results. That is why it does not work very effectively as a method— 
157|Q36|Chair|Surely that is true of any data source. 
158|Q36|Professor Preston|Not necessarily. If you look at the cohort studies data, for example, that the Economic and Social Research Council fund, it is designed to be representative of the population. The millennium cohort study, for example, is designed in such a way as to be representative, whereas Twitter is based on users who want to tweet, or not. 
159|Q36|Dr McPherson|That means that it is important to understand who the user base is, and to have research into that. It is always important, as I said, to combine it with other sources of data. 
160|Q36|Professor Yates|It is blindingly obvious, but people use social media deliberately to share, and they choose what to share. That tends to be a younger person’s thing, but it also applies to the 65s. That is the difference with some of the more structured datasets, and it is where social media is completely different. People have taken the decision to share information about themselves, positively, with the rest of the world. 
161|Q37|Stephen Mosley|I am interested in whether the UK Government can use social media data and real-time analysis to react to threats and to things that are happening within the UK. Do you think that the Government are properly equipped to use social media information and real-time analysis to react to emergency events? 
162|Q37|Professor Preston|In our analysis, we looked at three cities in terms of local government: London, Birmingham and Carlisle. They each had different strategies in their use and interpretation of social media. Birmingham was very much ahead of the curve in using Twitter, Facebook and YouTube; London, being the seat of Government, was quite top-down; and Carlisle said that they did not want to use social media that much—it was very much face-to-face contact and radio communications that they wanted to use. It depends on the city’s orientation as much as anything. Birmingham has changed recently. The resilience team has changed, so it depends upon officials who have an interest in doing this for it to be a success. 
163|Q37|Professor Preston|Policy makers find that they lack the tools, or the confidence to use the tools, to do this in real time; for example, during an emergency. There are tools that enable you to analyse sentiment—how the population is feeling emotionally in a crisis—and that can be incredibly useful. Are people fearful? Are they anxious and what are they anxious about? In real time, policy makers would not really want to use that tool because they would be scared of the implications; they would be scared of making the wrong decision on the basis of social media data. 
164|Q38|Chair|Before we move on, may I test that a little further? Have you undertaken any research around communities close to COMAH sites that are used to emergency planning processes? 
165|Q38|Professor Preston|In a more recent project that I am doing on population response to infrastructure failure, populations close to COMAH sites are used to using social media and looking at social media in terms of what is going on, whereas populations that are not near COMAH sites are not as used to it. 
166|Q39|Chair|They are more aware of the likely effect. 
167|Q39|Professor Preston|They are more aware of the effect and of the alerting protocols. 
168|Q39|Dr McPherson|May I add something about its use in crisis or emergency situations? I am concerned about using social media to establish events—to establish what has gone on. The point that we made in our written submission was that using data sources requires verification. You need to do a technical verification of social media information that relies on particular technologies, and that requires knowledge and understanding of how social media data can be manipulated. It takes a human element, because at the end of the day establishing the truth is a subjective exercise. Moving from social media data telling you what is going on in an event to reacting in real time I don’t think is possible, because you need to put verification in the middle and that takes time. 
169|Q39|Professor Preston|There are two verification methods for social media in real time. One of them is to use the users themselves. In the Australian floods, people were using the hashtag “mythbusters.” “Mythbusters” is a television programme about busting myths, conspiracies and so on, and people were using the hashtag to say what was real and what was not. That became a trending hashtag, with people using it to ask whether the flood was really happening in an area. People actually made use of that hashtag. Another one is the use of real-world data, using social media in conjunction with CCTV data or other kinds of situation awareness that the emergency services might have. But I agree that it takes a while to establish what is true and what is not. One of the things that we fear in emergencies is that people, or even terrorists or subversive bodies, might set up slop-bucket accounts to tweet that something is happening when it is not occurring, in order to make the situation worse. 
170|Q40|Stephen Mosley|That was the area I wanted to move on to next. Is there any evidence, in the situation that you just highlighted, of third parties trying to encourage other people to do things? 
171|Q40|Professor Preston|One of the biggest examples is the Syrian Electronic Army, as they classify themselves. No one knows who they really are, but they tweeted that the White House had been destroyed and no one knew where Barack Obama was, which caused billions to be wiped off the stock market in the United States. People are using it for disruptive activities at the moment. 
172|Q40|Dr McPherson|There is an absolutely huge amount of evidence emerging about this in Syria, but in other cases as well. I was looking recently at a video of someone being shot by a water cannon. It was being circulated in Latin America, with the title “This is happening in Colombia,” but there was the same video in Mexico. The problem that this raises is that of verification. Even if they are ultimately disproven, it requires a lot of resources for groups to debunk them. It takes time, and it takes people away from other work that they could be doing, so it is quite disruptive. 
173|Q41|Stephen Mosley|Looking at the UK, have there been any cases of that? I am on social media quite a bit, and see these stories circulating. I guess there is no checking, so how do you debunk these myths? 
174|Q41|Professor Preston|Twitter can be self-correcting. In our project, we had an analysis of a plane crash in Cork in Ireland. Social media got there first, in terms of how many casualties there were, before other media. It tends to be self-correcting so, first, people were tweeting that there were 20 casualties, then someone said that there were no casualties, but both of those were debunked. They iterated to the right—unusually, before the old media got there and the BBC broadcast how many casualties there were. People act almost like scientists sometimes. It is not just rumours; people say, “Is this correct or not? I know someone who works at the airport.” 
175|Q41|Dr McPherson|There was some great research done by The Guardian in conjunction with the LSE about the rumours circulating during the London riots. They showed timelines of tweets supporting the rumour and then debunking it, and how that worked, so it is self-correcting. 
176|Q41|Dr McPherson|You asked how you might verify. This is an emerging area, and I have been looking at it in terms of human rights organisations as well as journalists, and guidelines have been in development in recent months. The fundamental approach that verification professionals take to this information is to assume that it is false and your job is to prove that it is true, and if you can’t prove that it’s true you do not use it. I remember some quote that it is less about the snazzy technology than it is about good old gumshoe detective work. You might try first to find the source—the person who posted it—and speak to them directly and ask them details about it, just as you would with any other bit of information. It then needs cross-referencing with other databases. Technology can help; for example, you can use satellite images to verify whether large-scale bombing has taken place. You can also look at weather databases and ask the person, “What is the sun doing right now where you are?” and cross-reference to see whether they are actually there, but it is a complicated process. 
177|Q41|Professor Preston|It is also important to remember that old media can be hacked. The emergency alert system in the United States has been hacked several times in the last few years, broadcasting erroneous messages at state level. It is not just new media that can be subverted. 
178|Q42|Stephen Mosley|Lastly, do you think that social media platforms should be obligated to share information with Governments when there are concerns about security issues? 
179|Q42|Professor Preston|In disasters and emergencies, they are willing to do so readily anyway. Most users have an idea that they are sharing data, and they would like it to be used for altruistic purposes. If there is a disaster or an emergency, people are willing to do so. With the Boston marathon bombing, for example, people were willing to share their data and images with the authorities. People are less willing to do so if they think that the security services are spying on them for other reasons. 
180|Q43|Stephen Mosley|Or if social media is being used to encourage that trouble. 
181|Q43|Professor Preston|Yes, absolutely. 
182|Q44|Jim Dowd|I want to look briefly at how real-time analysis can be used in non­emergency circumstances. First, I want to test what you said, Professor Preston, about Twitter being self-correcting. Surely it is not self-correcting at all. It undermines the authenticity and the believability of Twitter the more conflicting messages you get. If everybody is tweeting— unless they are doing it maliciously, as Stephen suggested—“I believe this to be true,” what are people going to do? I think that they will lose confidence in the whole system. 
183|Q44|Professor Preston|People do not behave like that. They look for corroboration. If you saw a tweet saying that there was a fire at King’s Cross station, people would say, “Well you’re saying this, but what evidence is there”? And then they would look for someone who had tweeted— 
184|Q45|Jim Dowd|In other words, they do not trust it. 
185|Q45|Professor Preston|Not necessarily initially; there might be a bit of overshooting, but eventually it comes to be corrected over a period of time. That happens more rapidly as social media progresses. 
186|Q45|Professor Yates|In effect, you could argue that they do trust it, because they are looking for sources of corroboration from the very same system, and they assume that the system will provide the correct answer, so generally speaking— 
187|Q46|Jim Dowd|Are you suggesting that that is a false assumption? 
188|Q46|Professor Yates|That is the way that people actually use it. 
189|Q46|Dr McPherson|My evidence has shown that it is not at the system level that trust is taking place; it is looking at every individual user and deciding whether or not to trust that user. You look at the information but you also look at the source, and you do not trust the information unless you trust the source. 
190|Q46|Professor Preston|As a small example of that, we did an exercise with the Olympic Delivery Authority when the Westfield shopping centre opened. We were looking at different kinds of data. Someone was tweeting that one of the gates was shut and you could not get in that way, and people were saying, “Maybe someone is trying to get in more quickly,” but once they had tweeted a photograph, there was some corroboration and people started to believe that the gate was actually shut. 
191|Q47|Jim Dowd|I accept that; over time, if the same message is repeated, it becomes the norm. 
192|Q47|Professor Preston|No information is correct at first shot. If we heard that there was an emergency in London or elsewhere, the broadcast media would probably get it wrong. 
193|Q48|Jim Dowd|A lot of social media users are the least likely to believe the Government or any public authority. 
194|Q48|Professor Preston|Maybe, yes. 
195|Q49|Jim Dowd|Can we go back to non-emergency uses of real-time analysis? Are there any circumstances where it will be of benefit, other than in emergencies? 
196|Q49|Professor Yates|It is not a real-time analysis of social media, but the US amber alert system on missing children is quite a good system. You can get real-time alerts sent to people’s phones through tweets or whatever, in whatever way people have signed up to the system, and they provide information to the highway patrol. It is a small slice of use, but it is a clever use and it is well accepted in the US. 
197|Q49|Professor Yates|It is a way of communicating as well. It is not just, “I’ve got a disaster. Let me understand the disaster,” but what you would like to communicate to people. To what extent are the Government prepared to open their communication channels to talk to people? I go back to the question of trust. I am not sure that we know each other, so I am not sure that I trust you, but maybe after an hour I might, because you have been saying sensible things that corroborate— 
198|Q50|Jim Dowd|But I am a Member of Parliament. 
199|Q50|Professor Yates|Sincere apologies. My general point is that we as human beings trust each other over time by understanding what is being said and the context for what is being said. In fact, social media provides you with lots of different personalities. On Twitter, for example, I am reasonably well regarded—believe it or not—for photography, but I am probably not well regarded on politics. People know the context of my personality in that social media, and that is how people use it. Government could do the same thing. What is the personality that you want to project, in certain circumstances and situations and in certain media, to communicate with the public at large? It is a positive opportunity rather than a negative one, if that makes sense. 
200|Q50|Professor Preston|Another example, away from disasters, is looking at flu or the spread of infections. You can use social media to work out where outbreaks are and when there will be a demand for antibiotics and so on, and use that to predict where the demand will be on GPs and pharmaceutical services. 
201|Q51|Jim Dowd|Can it be used to replace or supplement the traditional census? 
202|Q51|Professor Yates|You can supplement it but not replace it, for all the reasons that everybody has given so far. The census will provide a broad look at everything, in a structured and detailed way, and you cannot replace that with social media, as to a certain extent it self-selects. Social media can create user attitudes—even colours, if you like; different things that are not available in traditional census mechanisms—and it can be extremely valuable. It is one of the things that we will eventually do in the centre at Leeds. 
203|Q52|Jim Dowd|You are clear that it could not replace the census. 
204|Q52|Professor Yates|It could not replace it, no. 
205|Q53|Jim Dowd|The civil service has traditionally not been the most responsive or adaptive of institutions—for good reason, I hasten to add; I do not say this as a criticism. How amendable do you think it is? Do you have any evidence that they will be able to utilise this either at a national or local level? 
206|Q53|Professor Yates|Can I address that by stepping back? The biggest barrier to the use of big data and social media analytics in general is the understanding and management of what it is capable of. We have a skills shortage, and I would like to come back to that later, but we also have an understanding shortage, even in industry, about how you can use analytics and data to make different kinds of decisions. In that sense, the civil service is no different from industry at large. The system needs an education job at principal level, and on bringing in the right people to do that. It is an “experiment and see” mentality, perhaps, but it is the same problem that, frankly, you will find in most big companies. 
207|Q54|Pamela Nash|We had evidence from the University of Cambridge touching on some of the themes that you discussed with Mr Dowd, saying that real-time analysis is incompatible with verification. That is common sense, and we did not need to ask the University of Cambridge for that. Does that rule out its use by the Government for civil policy purposes? How do we get around that? 
208|Q54|Dr McPherson|It does not rule it out at all, but what needs to be in place is a rigorous verification system. There is a new publication called “Verification Handbook,” which speaks to a lot of experts in this area about the techniques that they use. First and foremost, it says that whatever verification system you are going to use should not be put in place when you have an emergency and want to use the information. It should be systematically thought out ahead of time. It is something on which participants can be trained. It has ethical aspects as well, which should be included in that training. I don’t think it rules it out; it just means that verification needs to occur, and that verification should be based on a plan. 
209|Q55|Pamela Nash|Can you tell us more about what you mean by that? These are situations where I imagine that it would not be easy to plan ahead unless, as in another inquiry we have done, you have good horizon scanners where you could use Twitter or other social media to analyse an unfolding situation. How do you plan ahead to use that information? 
210|Q55|Dr McPherson|There is a methodological level of planning, which is understanding how verification works, and it can be done with social media; but there is also how this sort of data would fit into existing Government bodies and their existing sources of data. You can imagine that the police have all kinds of sources of information, including on-the-ground contacts and networks. You would then get social media data, and try to verify it. You would plug it into your existing on-the-ground networks, with whom you can have quick telephone or face-to-face contact. These will be people that you trust in that community, and you can ask them to verify it for you. It is a system of triangulation that, at its basis, should be used for any source of information, but I want to highlight that it needs to occur in this situation because social media is particularly vulnerable to certain types of manipulation. 
211|Q55|Professor Yates|There is also a distinction between individual verification and mass verification. With mass verification, you have the same techniques as used with other data sources. You are looking at a vast quantity of information, and trying to figure out the truth from it. That is a bit different from identifying whether we said a certain thing ourselves at a certain time or a certain moment. 
212|Q55|Professor Yates|From a broader sense, social media can be extremely useful because it is very fast. You can look at the way that some companies use data. I am not sure if you are familiar with how Google do translation, but they favour quantity of data over accuracy, and that is how they get better results. They have literally digitised every document that has been translated and figured out the context. If I hold up a candle and say, “This is light,” does it mean that it is illuminating or that it is not heavy? It will depend on the context in which I hold up the candle. The software deals with that by crunching vast amounts of data to get to a very fast response, which is why we all get instant translation on our phones. The same kind of techniques can be applied to social media. 
213|Q55|Professor Preston|There are other uses outside verification. Whether the data is verifiable or not is one issue, but in an emergency situation people go through different stages. We found that at the first stage they use social media to seek information. They then go through an emotional stage and then an opinion-sharing stage. 
214|Q55|Professor Preston|If you know that as a policy maker, you can tailor your types of message to those different stages. Which stage are the public in at the moment? If they are seeking and sharing information, you want to put information out there, but if they are responding emotionally then you want to put something out about being concerned or being compassionate about the victims of the emergency. If they are sharing opinions, you want to deal with that side of things. 
215|Q55|Professor Preston|Another facet, away from verification, is that some people on our project came up with a tool to detect outliers on social media during an emergency. If people are saying things very different from anyone else, it might be interesting for you to pick up on it, even if it is not verifiable. They might have access to information that others do not, or they might be an outlying group with an interest in the crisis. 
216|Q55|Dr McPherson|What you said reminds me that whether or not it is true does not have a bearing on whether it has an effect. It does have a bearing, but it may not have a bearing on whether or not it has an effect because it depends on what other people who are looking on social media believe. Even if you eventually debunk some kind of rumour, if it is circulating and people are believing it and reacting to it, that is another area where the Government might be concerned about responding. 
217|Q56|Pamela Nash|In terms of the processes that you have described, Professor, and the nuances that you mentioned about the different stages of people using Twitter, are the UK Government doing that already? If not, how do we get ready to make full use of it? 
218|Q56|Professor Preston|In my conversations with civil servants, they are certainly interested in dealing with it, and emergency managers are interested too. 
219|Q56|Pamela Nash|That was a very political answer. 
220|Q56|Professor Preston|Yes. They are interested in doing it, but they do not feel that a tool is available that Government could necessarily trust. In terms of sentiment analysis or analysis of emotions during any sort of political situation, they would like a tool that is kitemarked—one that Government could trust—but it is not there at the moment, so that makes them wary of doing it, whereas at the local level, you see people experimenting with all sorts of different things in local authorities and local government. 
221|Q57|Pamela Nash|Is there any incentive for anyone to produce that tool? 
222|Q57|Professor Preston|There is a commercial imperative for someone to produce a verifiable tool that Government could use and trust. In the States, the Federal Emergency Management Agency is very big on engaging the private sector in producing these sorts of things, with Government contracts and so on. 
223|Q58|Mr Heath|Professor Preston, you mentioned observations in a flu epidemic, which reminded me that when I was a Minister at DEFRA we were dealing with Chalara fraxinea, ash dieback, and one of the things that we had then was an app and an ashtag hashtag, which we were rather proud of. 
224|Q58|Chair|How much did you pay for that? 
225|Q58|Mr Heath|I wonder whether there is greater scope for observational science, using citizens as observers, in collecting information about natural phenomena such as epidemics. If so, won’t we need better protocols for interpreting the information that comes in? Obviously it is partial and some of it is incorrect, but it nevertheless has some value. 
226|Q58|Professor Preston|There is great scope for doing that. In my example about Birmingham and how Birmingham Resilience organised things, they depended on people at a local level to say whether events were happening and to tweet and use hashtags and so on. There is huge scope for that. Although the data may have observational errors, most people are minded enough, in terms of helping the scientific effort, not to skew the data. I cannot think of any example of a scientific effort that has involved Twitter, like spotting bird species and so on, where people have deliberately skewed the data. 
227|Q59|Chair|Does that conform to the Google rule about collecting volume? Every now and then, the pinpoint data might be inaccurate but the general pattern is correct. For example, David’s constituency was badly affected by the recent floods, and an individual Twitter message might have been inaccurate, in the same way as an individual physical measurement might not have told the full picture, but the collective pattern does. 
228|Q59|professor Preston|That is right. You can get sampling errors. 
229|Q60|Mr Heath|I want to talk about the collection of personal information, and the disparity between the preparedness of the individual to give personal information to companies, whether they are social media sites or private or industrial, and their lack of preparedness to do the same for the Government. This may all be down to George Orwell, or there may be something else. 
230|Q60|Professor Yates|It goes back to what we said before. In social media, people make a conscious choice to share specific information for a specific purpose—some of it silly, maybe, but some of it for a useful purpose. They have already decided to give that, and they know that it is going to be used in some way, shape or form, by other people on the system or by the company itself. That is a bit different from being compelled by law to give information about your tax return, your expenses or whatever. There is a different sense for the human being about how you deal with that information. In one sense you are doing it freely, but in another sense you are being compelled. If you can get people to do these things freely, that would be incredibly helpful. There would then be no sense that they were being imposed upon. 
231|Q61|Mr Heath|Quite so. We freely give information to our doctor about our symptoms and our personal details, but there was marked reluctance by some for that information to be shared for purely benign research purposes in the NHS database. 
232|Q61|Professor Yates|I completely agree, but that is a failure of education. It goes back to the point of to what degree we are educating the population at large about the value of using data to take better decisions on behalf of all of us, in many different ways. We do not do that very much. Even in my business school, we teach analytics almost as a statistical activity, whereas we should be teaching it as a contextual activity about how to use the insight to get to a different place. Although it might be hard to convince the population that it is something they should truly understand, we have to start that process. Had we had that education in place, I contend that getting informed consent would have been a lot easier. 
233|Q62|Mr Heath|That is helpful. Thank you. 
234|Q62|Professor Preston|There are platforms available where people can share information for disasters. There is one called Ushahidi, where people are very willing to share their information, but it depends on the level of government you are talking about. People might be wary of sharing information with central Government, but if it is about helping in an emergency at city or local authority level, people might be very willing to share information. 
235|Q63|Mr Heath|We talked with the previous panel—I think you were all listening—about the application of our own data protection laws, but also the potential extension of the EU legislation. Are we going to inhibit our Government’s ability to use data effectively by perhaps increasing the protections available under data protection laws? 
236|Q63|Professor Yates|That is a difficult one. I have to state up front that I am more in favour of the US style of using data to innovate rather than some of the rights-based approaches, although obviously there is a balance between the two. 
237|Q63|Professor Yates|I was at a conference recently where a gentleman called Steven Finlay, in a new book, talked about rules on how to deal with personal data. He said that it depends on the data itself. How immutable is the data? Your DNA cannot be changed and it should be completely protected. To what extent does it benefit you as an individual or society at large? To what degree should we protect it? How will the data impact me as an individual? If it is going to impact me a great deal, I really should be protected. 
238|Q63|Professor Yates|There must be some sort of balancing act with the needs of the individual. Just to paint it as, “I must protect the individual’s information” is too broad; to what extent does the individual really need it to be protected, and can we protect it while also allowing companies and Governments to use the information in a sensible way for the benefit of people at large? I am not sure that any legislation deals with that. 
239|Q64|Mr Heath|That suggests that you think that personal information is in common ownership rather than the ownership of the person to whom it refers. 
240|Q64|Professor Yates|No, I tend to think of it as personal. I am sorry if I suggested otherwise. Your DNA is very much your own information. Can it be used by doctors to help you? Of course it can, so to what degree does it belong to the doctor or you? I am not really sure, frankly. 
241|Q64|Professor Preston|Doing research is a legal and ethical minefield, and data protection legislation is obviously a central part of that. Anything that could make innovation or academic research easier in this area would be welcome. 
242|Q65|Mr Heath|It would probably do the reverse. 
243|Q65|Professor Preston|That is right, yes. 
244|Q65|Professor Yates|I have an observation on that which might be helpful. I was thinking in preparation for this session that, in the legal world, there is the Creative Commons approach to you releasing your IP on the web, with certain restrictions on it. The idea of the kitemark was suggested, but I wonder whether, from an individual point of view, we could have some way of saying, “I am prepared to share this,” with some kind of licence, “but I am not prepared to share that,” with another kind of licence, so that the individual could positively take a decision about which data they want to share and in what context. That would be very helpful. 
245|Q66|Chair|We have talked about licensing regimes. Taking the simple example of the club card, the trouble is that if you want the points you have to sign up to the terms and conditions; if you want to be on Twitter, you have to sign up to the terms and conditions. Companies, under current legislation in this country and elsewhere, have all the aces. 
246|Q66|Professor Yates|They do, in a way. That is absolutely true. 
247|Q67|Stephen Metcalfe|Following on from that point, I want to look at users’ expectations of how their data will be used. We talked earlier about end-user licence agreements. To show how helpful they were, Jim told us that there were 110 pages. Are they designed to be as accessible as they appear, so that you can hide all sorts of stuff in them? Is there a way of making it easier for people to know the key issues that they are signing up to—the bit that you would not expect to be in there, as opposed to what you would expect? 
248|Q67|Professor Yates|I think that there is. It is almost like what are the bullet points of the agreements. I completely agree. If you take the example of a loyalty programme, whatever the terms and conditions and the detail, people are making a conscious exchange. They are allowing the company to use their information on what they have bought or the planes that they have flown on in return for something—some kind of discount, some kind of service improvement or whatever. That is why people sign up for those programmes. People understand the idea of exchanging their data for a benefit. If those simple things could be explained in those 110-page agreements—“What is the benefit of Twitter sharing my information?”, “Why would Facebook share my information?”—it would be helpful. 
249|Q67|Professor Preston|Socially, people treat social media a bit like they treat the pub. They feel that if they go into a pub and have a private conversation, it does not belong to the pub; it is their conversation. They interpret Twitter or Facebook in the same way—as a place to have a conversation. People need to know what they are signing up to, but because they are US companies, the advice would be exhaustive and legalistic, and their lawyers will have advised them that the terms and conditions should cover any situation that could potentially occur. 
250|Q67|Dr McPherson|Even if you know and understand the terms and conditions, there is a difference between the theory of what you are signing up to and the practice of how you use it. In my own Twitter use, for example, I think of my followers when I tweet; I am not thinking that it could be used to draw conclusions about other things, or that it might end up travelling the world or in a newspaper. I read an interesting piece recently that advocated considering Twitter users as what in journalistic ethics is referred to as “inexperienced sources,” who would not necessarily know what the personal implications are for them of their information going broadly public, and emphasising caution. 
251|Q67|Professor Yates|Another side to this is that when you log on to a website and you sign in with Facebook or Twitter, not everybody realises that you are allowing the other site that is using that login to access your Facebook or Twitter information. You get a thing that says “sharing your profile,” but that is through the API, so you can access profile information from Facebook or Twitter without paying Facebook or Twitter, just by saying, “I sign up for this.” It is not a barrier to understanding that individual. 
252|Q67|Professor Yates|Usually, there isn’t informed consent. If you sign up and share your Facebook profile and photographs or whatever, they then become part of the other person’s system. In the mobile context, that is called a token. That token is long lasting. It is there for a long time; it does not just disappear. 
253|Q68|Stephen Metcalfe|As is often the case, I suppose it is getting people to catch up with the speed at which the technology is developing and to get social attitudes to change. As politicians, we would want to put everything that we ever write, say or tweet in the context of how we would feel if it was on the front page of the local or national newspaper. If you do that, you protect yourself. With the pub analogy, if you are having a private conversation but someone is standing next to you and you are aware that they might be listening, you probably would not think that the pub is recording it for security purposes. 
254|Q68|Stephen Metcalfe|We have to help people understand how the world around them is changing, but do we need to do that on their behalf, from a Government point of view, to protect them—to create systems that avoid them making these mistakes, or do we need to educate people about the freedoms and choices that they have now? 
255|Q68|Professor Yates|Education, education, education. To me, that is the most important thing. You talked quite a bit about data scientists in the first session. Unfortunately, data science in most countries tends to get defined as a technical activity. As it was originally defined by IBM, it was a combination of analytics and artistry, so that you understand the business or social context of what you are doing. There is a great data science course in America at the Illinois Institute of Technology. We have one at the University of Bedfordshire, but even my institution does not have a course where we train all these people across the board on how to use analytics and insight to take public decisions. Education has to be the answer rather than legislation. 
256|Q69|Jim Dowd|Following on directly from that, you said earlier, Professor Yates, that you wanted to come back to skills and training in these matters. I asked the first group about this. It is a new science or discipline—whether it is science or guesswork, I am not quite sure. How are we adapting to it? How is the provision of courses for professionals in this area? 
257|Q69|Professor Yates|The data capability strategy that was mentioned before is a good document. It is robust and it points things in the right direction, although largely from a technical point of view; it does not necessarily address the social, business or contextual understanding that we also need. If you look at the data, you get the insight, but the visualisation and impact of the data is more important than the data itself. How do we train people in that? We do not have enough programmes that do that. We have some in the DTCs—the doctoral training centres; there are 21 in the UK. The White Rose in Yorkshire is doing a big data programme to address some of these issues. We need more of those programmes. That one is aimed at doctoral students, not at students in grammar school, high school or comprehensive school, so we probably need that kind of programme too. More education at different levels needs to be addressed. 
258|Q69|Professor Yates|Don’t get me wrong: this country is probably one of the leaders in some of this analytics work, largely because of what companies like Dunnhumby have done in the retail space. We know how to do the work; the shortage tends to be finding people who can put it into context, not for doing the analytics itself. That is where we need to focus. 
259|Q69|Professor Preston|In terms of skills, it is a very interdisciplinary area. The benefit of doing our project on social media in emergencies was that it brought people together. I am from education, and there were economists, physicists, mathematicians, computer scientists and people involved in language processing. 
260|Q69|Professor Preston|It is partly a reorganisation issue—how we get people from different disciplines to work on this complex interdisciplinary problem. It is not necessarily a matter of new resources; it is a matter of how you organise the resources that you already have. As my colleagues said, we already have great potential in the United Kingdom in terms of social and physical sciences. 
261|Q70|Jim Dowd|One of the broader problems that the Government have in highly technical and advanced areas—in the field of IT, for example—is that they cannot compete in attracting skilled labour into their service because it is so commercially valuable. Is this not likely to replicate itself in the case of data analysis and big data? It is of such enormous value out there that the Government could not possibly compete on labour rates and so on. 
262|Q70|Professor Preston|There is a possibility of strategic partnerships, working with universities and other innovators and with private sector innovators to make these kinds of products, or whatever you want to do. It is not necessarily a matter of the Government funding it all themselves. I don’t think that works. If you look at the Department of Homeland Security and FEMA, their approach is very much to have science centres in the universities to innovate in this area. That is one approach. 
263|Q71|Jim Dowd|I am not sure about the record of the Department of Homeland Security in building their new headquarters. There is not much faith in what they are up to. 
264|Q71|Professor Yates|The UK has a great reputation on open data; it is one of the world’s leaders, so the Government have a good reputation in this field. It is not a bad reputation; it is a question of building on it with the kind of partnerships that John is talking about. That would be helpful. 
265|Q72|Chair|Professor Preston, on your observation about the multidisciplinary nature of the skills needed, do the research councils get it now? Is there a joined-up approach within the research councils to help fund projects that fit into this category? 
266|Q72|Professor Preston|Yes. Our project was jointly funded by the Engineering and Physical Sciences Research Council and the Economic and Social Research Council. It brought together those two bits of expertise in one project. Those sorts of activities help. The research councils are getting it in terms of big data. 
267|Q72|Professor Yates|The project that we had was funded by the ESRC. We would not have been awarded a bid unless we had put a multidisciplinary bid together inside our own institution. It was almost forcing us to think in an interdisciplinary way, which was a good thing. 
268|Q73|Stephen Mosley|Talking about skills in the UK, do we have the infrastructure in place to take advantage of the market? 
269|Q73|Professor Preston|We are trying an approach of concentrating on a few universities or providers to deliver those skills. Whether that approach will work in practice, I am not sure. 
270|Q74|Stephen Mosley|I didn’t mean the skills. Do we have the physical infrastructure—the data centres and the like? 
271|Q74|Professor Preston|I could not answer that, sorry. 
272|Q74|Professor Yates|Generally speaking, we are pretty good on that, although I would like higher-speed internet in my village. 
273|Q74|Stephen Mosley|Get your postcode on the record while you’re at it. 
274|Q74|Professor Yates|Sorry. That was a flippant comment. To be serious, generally speaking, we are pretty good at building decent infrastructure, and some of the initiatives that the Government have taken in this space have been quite good. Commercial interests demand that you do not just have British infrastructure, you have global infrastructure; systems like Hadoop and so on are cloud-based, so you do not need the physical infrastructure in a particular jurisdiction or country. 
275|Q75|Stephen Mosley|With the increase in regulation from the UK or Europe, do you think that this sector could be a flash in the pan that will evaporate when regulations choke the volume of data that is being collected? 
276|Q75|Professor Yates|No, very simply. It is an unstoppable train, given the amount of data that we are collecting on everything. Soon we will have an internet of things, where our fridge will talk to our car and remind us to go to the supermarket. It is an unstoppable train. 
277|Q75|Professor Preston|Companies like Google operate almost above the regulatory environment in Europe. They will say that if they cannot do it in Europe, they will take academics to the US and work with them there. 
278|Q76|Jim Dowd|What if Google runs the world? What will happen then? 
279|Q76|Professor Yates|Perhaps they have already taken over the world. 
280|Q77|Stephen Mosley|Do you see the threat from regulation to be for home-grown UK and European-based companies rather than global companies? Would you draw that distinction? 
281|Q77|Professor Preston|It could threaten what UK and European companies are doing if we are not careful, whereas the US has a looser regulatory environment for companies in this area. 
282|Q77|Professor Yates|That is generally true; it is a looser environment that is more focused on driving innovation than on protecting the rights of the individual. That is an obvious distinction. At the same time, we should be quite pleased with what the UK does in this field. We are good at analytics and social science, we have some really good universities and we are quite good at being interdisciplinary. As I said, a lot of these technologies are cloud-based, so they do not need physically to be in the next city. They are being used in different ways, and the more that we can encourage innovation to use those systems, the better. We are going to be fine. 
283|Q78|Chair|Do you agree with that, Dr McPherson? At least one Cambridge academic who speaks a lot on this sector expresses great concern that we will one day produce a less benign Government, and that all our data will be misused by the state. But you have academic freedom here. 
284|Q78|Dr McPherson|Personally, I am concerned with the ethical aspects of using this data, with a lot of topics that were brought up by the previous panel about the inability to be truly anonymous and the inability to future-proof. I know that there are a lot of cases where we are talking about using the data for innovation and so on, and for very positive reasons, but I am thinking of the more vulnerable people—I am thinking of my human rights work—those for whom exposing their identity has tremendous repercussions. That is the area that concerns me. 
285|Q79|Chair|You accept Professor Yates’s comment that it is an unstoppable train. 
286|Q79|Dr McPherson|Yes, for sure. 
287|Q79|Professor Yates|By the way, I agree with the ethical concerns. Don’t get me wrong; I was just addressing innovation issues, not the ethical concerns. 
288|Q79|Dr McPherson|I changed the subject. 
289|Q79|Chair|We’ll leave it there; it is a fascinating point to stop at. Thank you very much for your attendance this morning. 
290|Q80|Chair|Gentlemen, thank you for coming in this afternoon. First, let me apologise on behalf of some of the Committee members who are unable to be here. We have squeezed this in out of our normal cycle and we are clashing with N other things in this building, but we are grateful that you have been able to come. For the record, I would be grateful if you would start by introducing yourselves. 
291|Q80|Sir Nigel Shadbolt|I am Sir Nigel Shadbolt. I am professor of artificial intelligence and head of the web and internet science group at the University of Southampton. 
292|Q80|Professor McAuley|I am Professor Derek McAuley, professor of digital economy, and I run the Horizon Institute, a research institute, at the University of Nottingham. 
293|Q80|Professor De Roure|I am David De Roure, director of the Oxford e-Research Centre, which is a multi-disciplinary research centre at Oxford. I am a representative of ESRC in my role as strategic adviser for social media. 
294|Q81|Chair|First, I want to clarify the use of English. A lot of people use the word “infrastructure” in this discussion about social media and real time analysis. What do they mean by infrastructure? Are we talking about people, physical technology or software? What is the correct definition to use? 
295|Q81|Sir Nigel Shadbolt|It is all of the above. You have to believe that in this area the hardware process the content in anything like real time at sufficient scale and the software analytics are clearly an essential component, but without analysts capable of drawing pertinent and relevant conclusions to understand the context of the setting you have hardware and software that has little value to it. 
296|Q82|Chair|Is that an accepted definition? 
297|Q82|Professor McAuley|I would accept that definition. It is often easy to get confused about the infrastructure being purely the hardware, with perhaps too much emphasis on that, since a lot of this is available commercially, in terms of at scale, and we really want to think about the software tools, the technologies and the people. 
298|Q82|Professor De Roure|I would accept that broad definition. It is very good to hear software emphasised because very often it is something that is forgotten or taken for granted. Digital infrastructure is perhaps different from roads. One of the things about digital is that a lot of the infrastructure can go to the person rather than the person to the infrastructure. 
299|Q82|Sir Nigel Shadbolt|Data themselves are an infrastructure. Perhaps this sounds a little odd to some ears, but the structure of the stuff we are analysing has an intrinsic infrastructure, so working out what those standards and interoperability points could be will turn out to be quite important. 
300|Q83|Chair|Within the UK are there gaps in that infrastructure? 
301|Q83|Professor De Roure|The experience of consulting to prepare for this emphasises repeatedly the skills gap. I know that is the theme of today, so we will be discussing that. I also highlight the software issue I mentioned just now. It tends to be taken for granted and not seen as infrastructure, but it absolutely is. 
302|Q83|Professor McAuley|In interacting around social media especially, we might look to the sort of move the Library of Congress in the US has made to grab hold of this as a national resource. One of the things we are doing at the moment, which perhaps is not most effective, is that everyone is negotiating for access to these datasets independently, hence not having any negotiating power to get access. 
303|Q83|Sir Nigel Shadbolt|It is a very important point. I am sure we will talk about the gaps around capability. The other thing to note is that we are in a curious situation in which the private sector, which is driven by the interest and intent to understand everything from sentiment to buy and intent to purchase, has substantial holdings of data that hold really interesting social insights. Some of the companies themselves are the very social media companies. There is an interesting question about the balance between the public and private holding and collecting of those data, and whether we need to take a much more balanced view about how we can get the private sector to work in common cause with us, because it has some of the most valuable content. 
304|Q84|Chair|Presumably, from that you would be arguing that the Government should work with the private sector to develop that infrastructure, sticking to that one theme— 
305|Q84|Sir Nigel Shadbolt|Yes. 
306|Q85|Chair|—and also to help address some of the skills issues. 
307|Q85|Sir Nigel Shadbolt|Yes. If we look even generally at indicators, there was a survey just this year by Eurojobs.com that looked at the 6,000-odd jobs that mentioned the words “data” or “data science” in their title. Half of those—over 50%—came from Britain. The closest, nearest EU competitor was Germany with about 9%. There are lots of jobs out there, and the sense is that currently the skills in that area could provide about a third of the necessary jobs, so a very broad gap is opening up. The area itself is set to grow, by some accounts, by around 100% in three to four years' time. 
308|Q85|Professor De Roure|The kinds of analytics we do with social media data have different infrastructural requirements from other forms of data. It is probably worth highlighting that as well. I would like to introduce the words “real time” at this point. We do not talk so much about real time analytics with other data sources. That has very significant infrastructural implications. 
309|Q86|Chair|In terms of Government, we are in a rapidly moving field. I can name the first Minister I saw not all that long ago—I will not do so today—with a computer on their desk. Things are moving incredibly fast. Do Government really understand its requirements and what can be developed out of the technologies around? 
310|Q86|Sir Nigel Shadbolt|It is moving so fast that researchers are challenged too. The rates of change are so enormous. To give just one statistic, every 10 years the amount of information being held is roughly a thousand-fold greater than we currently have. These are extraordinary rates of change. Do we have the capacity? I think we begin to see the requirement. One of the promising things is the way in which the Government and previous ones have begun to talk about the power of information and understand that this is an asset they have to invest in, and the associated skills to bring it to the fore. As Professor De Roure says, the real challenge here is understanding this blend of skills. It is not just about having the ability to ingest the data and crawl over it. It is not just about big data in fact; it is about data of various stripes, and being able to apply a range of skills, from social science, behavioural sciences through to software science, to understand how to make sense of this torrent of data. 
311|Q86|Professor McAuley|For example, one might look at the internet of things as a new concept. I was at a workshop at Stanford 20 years ago on the internet of things. We talked about light bulbs on the internet. At one level, the technologists have been thinking about many of these things. What we are really seeing now is a convergence of the technology with the social and the human: technologists who understand the challenges in dealing with human data; likewise, on the social science side, social scientists who understand what is possible with computational techniques. It is in this space that we are really challenged. It is not that everyone has to be an expert on everything, but it is the dreaded t-shaped person who has experience and understanding across a number of disciplines, and there is an awareness of that, yet depth in one area. That is where we are seeing it is not purely technology-driven any more. I am a computer scientist. I will be the first to admit that it has been a learning experience for me to get to the point of understanding all of these social nuances about how we have to deal with human data. One of the key challenges is not just the purely technical skills but broader awareness of the challenges in dealing with these sorts of data. 
312|Q86|Professor De Roure|Reflecting on those comments, I think the agility of that capability requires us to be able to remove barriers, not repeatedly investing in existing silos of activity in research areas. Something like social media really is interdisciplinary, as we have heard, so we need to be more strategic in those investments. That is certainly the mood of the research councils to work across. 
313|Q87|Jim Dowd|Sir Nigel, if I may pursue a point you made a few moments ago, if I understood it, the amount of information and data around grows by a factor of 1,000 every 10 years. How does that correspond to the half-life of facts? 
314|Q87|Sir Nigel Shadbolt|One of the great challenges is the dictum: a rumour is halfway round the world before truth has got its boots on. The web and social media applications behind it are often seen as propagations of rumour mills. There is no end to the amount of opinions, rumours and gossip that might be exchanged in this milieu, but, in truth, the increase in our understanding of basic facts in this space is also exploding. So it is interesting to see whether real facts and opinion are keeping track of that, but because of things like the internet of things we are simply instrumenting so much of the environment that there are new kinds of facts being stored and laid out all the time. Some of these will be material to making judgments about social mobility, social attitudes and social interactions. 
315|Q88|Jim Dowd|Where does the dictum that the more you know, the more you know you don't know fit into all this? 
316|Q88|Sir Nigel Shadbolt|That is a really interesting point. One of the things we are all aware of is that there is no one discipline that has the essential insights into how to make sense of these data. Our written submission was from the Web Science Trust. A set of laboratories networked around the world tried to look at the web as a systems level object. It is not a piece of technology; it is not a set of software programs; it is humanity-connected. As such, you have to pay attention to understanding the methods you need to make sense of this, because we are literally seeing new forms of interaction the mathematics for which barely exist to do the analysis. The sociology behind it has been in the background for some time. It is now possible for sociologists even to test some of their theories and to put them to empirical test. We are seeing a new set of disciplines emerge in the face of this new data opportunity. 
317|Q89|Jim Dowd|I have a few questions on the amount of what is called social media data necessary for social media organisations to hold. Should they be allowed to require rather than just request information? I recognise that organisations of all kinds, whether in the private or public sector, can never have too much information about you. I was putting a flashlight app on my phone the other day, because the one I had before was not very good, and the phone told me that I had to switch on my locator before I would be allowed to download it. Other than simple acquisitiveness on the part of the company wanting to know who is out there, why on earth do they need to know where I am before they will let me have light? 
318|Q89|Professor McAuley|Of course they don't. We are now going through a period when many of the things being deployed are being, let us say, a bit duplicitous in their behaviour and they are asking for things. They are presenting one experience, yet asking for a lot more information. I know of a research project, which would not have gone through ethical approval at my university but did go through somewhere else, involving a simple psychometric fun program. What sort of person are you? Its purpose was to determine your social graph. It would have sent the heebie-jeebies up my ethics committees if they had ever seen something like that. A lot of this is going on. 
319|Q89|Professor McAuley|At the moment I am leading a working group looking at the principles of managing personal data for the Information Economy Council. We are reporting in two weeks' time on ethical guidelines for how companies should process this sort of information. In one sense, industries are crying out for this. Many small companies, even large ones, want to be seen to be behaving ethically and are getting somewhat annoyed at some of the unethical behaviours of others. I would put that flashlight program in that category. It does not need that information to do its job; it is obviously after it for some other reason. 
320|Q90|Jim Dowd|You never know whether that is for its own purposes or to sell it on, because this information has value. 
321|Q90|Professor McAuley|Indeed. 
322|Q91|Jim Dowd|Would it be practical to introduce a restriction on the amount of data these organisations are allowed to request up front? I understand the argument, “You have to accept our terms and conditions or you don't do business with us,” or, “If you want to do business with us and don't want to accept our terms and conditions, you don't do business with us.” Is there a practical role for imposing restrictions and limitations on the amount of data and information these organisations can either request or certainly hold permanently? 
323|Q91|Professor McAuley|My comment would be that we already have legislation in this area, and possibly forthcoming legislation under data protection regulation. That gets us to a position where, if the user is considered to have given consent, you can take what you want. There is a question, again, as to whether that is ethical. We might want to be thinking about some frameworks, even if they are voluntary, such as those related to organic food supply. There is a regulation about what food products can be on the shelves, but there is another branding associated with things that are organic. There may well be a branding associated with highly ethical personal information products in the future, rather than it being perhaps a requirement, because the underlying legal basis is one of consent. This would be some sort of critical kitemark to say this meets a higher standard, and perhaps then the population might be able to think about it and reflect on what they do and do not use. 
324|Q91|Professor De Roure|I think that contention is very important. There is definitely a case for increased awareness. How few people read the terms and conditions they are signing up to is documented. 
325|Q91|Sir Nigel Shadbolt|They are usually totally impenetrable of course. There is some very interesting research on this at the University of Nottingham, looking at the reading age and how complex these terms and conditions are. Some of it is more complex than Shakespeare and needs a reading age of 19.2 years to get through it. It is an area where a degree of practical simplification could help. 
326|Q92|Chair|How do you do that, because most of this is written for American corporates and not our systems? 
327|Q92|Sir Nigel Shadbolt|Yes, although I suggest that the interest those companies have in a UK or European audience is such that they would take it seriously if there was a real sense that without that they would not get access to those markets. I think that is beginning to shape this. 
328|Q92|Professor McAuley|I highlight the recent ruling of the European Court that has been publicised mostly as the right to forget, but the precursor judgment to that was that Google had to comply with Spanish data protection law. That was the more important judgment, because that led to the second part. The multinationals would be based not even on new incoming regulations but on the existing human rights legislation, and everything else would be required to operate under national laws. I think it is a landmark ruling. One of the things we might aim to do is make the UK a better place to do business by having a set of, say, template contracts—a bit like food labelling—where it is quite clear what you are getting and what is happening to your data, not necessarily as the final straw but as a voluntary code for people to sign up to. “We make our tools and services easy to understand” could be part and parcel of the development of that, and setting up the UK as, “We are an easy place to do business. Consumers can understand what is going on.” 
329|Q93|Jim Dowd|As highly experienced and trained practitioners in this field, are you as amazed as I am about the volume of personal information that people would give away for nothing? 
330|Q93|Sir Nigel Shadbolt|There are good studies on this, and apparently for a free cup of coffee you give away a surprising amount, except that when the consequences of that are played back to the individual it is clear that the notion we have given up on privacy, or that we will trade almost anything, has not been the experience in areas where we have gone the wrong side of the argument. You might give it away, but the presumption as to how you give it away and how it will be used turns out to be very important. Even in the case of the commercial situations, when people are presented with the consequences of that, they think about whether there should be a better balance. The problem with deciding that these data shall be collected and these data shall not is that there are always proxies for the information you decide not to give that can still reveal a huge amount. It is unlikely that a transaction between you and your supermarket would be something you would want to alter or change, but it is clear from the entire history of that, as we know in the famous example of the Target supermarket in the US, that 20 products can predict whether or not you are pregnant and pretty well your due date. That is the reality of understanding shopping basket compositions. While that is happening, the regrettable other side is that we cannot get into information-sharing situations with these corporations where we can understand that over-the-counter non-prescription cough mixtures and medicines might help us predict and see outbreaks of flu and the common cold in a population, because they will not share the data with the Government. There seems to be a degree of asymmetry here about how analytics are used and who gets to use it and who gets the insights. That would be one of the major correctors we could look at. 
331|Q94|Stephen Metcalfe|You said the Government cannot get this information shared. The Government undertake quite a lot of horizon scanning activities, looking at emerging technologies. In this particular field have the Government done enough to be ahead of this and understand the implications of what is happening, or is it another case of them napping while the world around them turns and develops? 
332|Q94|Professor De Roure|We really welcome the emphasis on data and data sharing and all the issues that go with that. I would suggest that looking at data sharing alone is not sufficient. It is essential but not sufficient. It is what you do with the data that counts. Sharing the tools, the results and practice, and building best practice, has to be part of sharing. Investment in data is worth while if it results in data that can be discovered and reused, and preferably accrues value through reuse by the community or the beneficiaries of that analysis. 
333|Q95|Stephen Metcalfe|But the question was: are Government ahead of the curve on this? 
334|Q95|Professor De Roure|No. I think social media data are special, which is a point I will continue to make, partly because it is social, which goes back to the previous point. It has to be treated as separate. It is easy to say it is a new form of data, like business data, supermarket loyalty cards and admin data. It is that, but it is something else as well. If you look at something like the summer riots, that was partly mediated by the use of social media. New social processes are being created—for example, on Twitter—which deserve analysis in their own right. That is a new and important phenomenon to the country. I would strongly argue that we need to treat social media at least with the attention we are giving to other new forms of data; and it has, as we said before, its own infrastructural requirements, especially in terms of analytics and real time analytics. 
335|Q96|Professor McAuley|It is seven years since the Research Councils UK launched the digital economy programme. I think that was foresight, given that the iPhone is only seven years old. If we can remember what the state of social media was seven years ago, it was a bit of a mess. Maybe people had heard of Twitter, but it was still viewed as a slightly eccentric thing to be engaging in. The rate of change in terms of uptake, especially promoted by the fact that the technology is suddenly available in everyone's hands, and the velocity of this is so high that we have all been slightly bamboozled by how much people have engaged with it. 
336|Q96|Professor McAuley|I put a caveat on that. Often, folks will say, “We'll take the current trends we have observed over the last few years and project them, like some hockey stick, into the future.” One of them is that many of the initial social media mechanisms were very open by default. You were publishing to the world. With something like Twitter, where that is its modus operandi, it is broadcast in full, so that is understandable. Many people got caught out by social media that was by default broadcast and did not really internalise that. That is why in the last few years we have seen the emergence of new social media which regard privacy and small group interaction as much more important. My comment would be that the speed at which this has moved has defied many of us and we are working hard to keep up with it. I certainly would not blame Government, or anyone else, for not having had the foresight seven years ago to see this one coming. 
337|Q96|Stephen Metcalfe|Is it now catching up? Has it caught up? Is it doing what it can to support this technology and the potential? We are told it is worth hundreds of billions over the next four years. Is it now getting it right? 
338|Q96|Professor McAuley|I am sure David can speak to this from the point of view of ESRC, but I think there is still a lot more to be done. In particular, we need to be careful that we do not focus on the social media of today, because in two years it could be gone. 
339|Q96|Sir Nigel Shadbolt|That is exactly right. The remarkable thing about this is that the research to tell us what we can infer from this social media is only now landing in front of us. Your sexual orientation, disposition to vote a particular way, your religion and ethnicity are predictable with a very high degree of certainty from your Facebook likes. This is new research. It will take a while to internalise just how we deal with that. What are the processes to put in place? We can imagine any number of people who would be interested in knowing and understanding everything from the last Obama campaign to what one can expect in the election campaigns here. This will become material information that is argued over, and the research will simply go into this area. 
340|Q96|Sir Nigel Shadbolt|Is the infrastructure there? Is the capability there? Are the Government doing enough? It is easy to confuse big data with insights in social media. We are making significant investments in this area. The Square Kilometre Array and the announcements about the eight great technologies that the Science Minister has made are good investments, but in this particular area of social analytics it is a different kind of content, skillset and blend, and it is moving so very fast that we have not had enough time to put in some of the infrastructural elements we need to support it. 
341|Q96|Professor De Roure|I agree with that and I should underline that the intent is there. It may not have been realised yet, but the degree of interest within the research community is there as well. The researchers are very enthusiastic to work with social media, both to study it but also to use it as a tool for their studies in social science. I would hope for investment in the coming year or so in social media which perhaps would mirror some of the investments in admin, retail and business data. 
342|Q97|Stephen Metcalfe|Bearing in mind the speed at which this is all developing and changing, if we want to maximise the financial benefits of this potentially, who should be leading the development of the products that will realise its potential? Is it the private sector, or, because it is moving so fast, does it need to be academia? 
343|Q97|Sir Nigel Shadbolt|The UK has led the way in a couple of areas, not in social data but in open data. It led the way by releasing it and thinking about the kinds of institutions and infrastructure that need to be set up to support its analysis, and how to stimulate the demand side as well as the supply side. We might think the market will take care of all of this because there is such a strong set of retail and commercial interest in social media, but their analytics will tend to be very much closed. The methods they use will generate insight for them and their clients. The reports are available typically for very large amounts of money. The challenge is to provide a public set of insights so that the public sector—the public good—can be as well served as the private good. 
344|Q97|Sir Nigel Shadbolt|I am not saying the commercial sector does not have an interest in collaborating on this— it absolutely does; but in some areas it will regard this as particularly valuable to its own positioning and customer insight, so we may well here have a situation where the provisioning of tools available for wider research for the kind of data analytics that Government have to do will need to be made available on different sorts of licensing conditions such as open licences. 
345|Q97|Professor McAuley|I talk to quite a number of companies that have had access to a lot of personal information for many years. They already are challenged ethically around what they do. They choose not to do certain analyses—for example, to determine who you might vote for, what your sexuality is or any of these personally invasive things. They choose not to do it. There may be a valid research purpose in asking some of those questions; it may be something that as a society we want to understand, but, quite sensibly, certainly established businesses with a respectable brand would not wish to ruin that by going down that path for a commercial reason. They would not want to be seen to be doing that analysis for a commercial reason, even though that sort of analysis done anonymously and correctly, as we might do with the census, statistically and at aggregate level can still provide an enormous social good. But they would not wish to do it because of the dangers of being seen that they were pursing this only for commercial gain. 
346|Q97|Professor De Roure|Social media are a great opportunity for businesses and academia to come together with common interests and methods. An additional role for academia is in the production of people with the skills and business needs. To come back to the “skills” point, we are told time and time again that we are not producing enough data scientists who can do this kind of work. 
347|Q98|Stephen Metcalfe|What do you think should be the role of small business in helping to develop some of these products that might analyse this? 
348|Q98|Professor McAuley|I also work with the connected digital economy catapult. One of the things we have been doing there is reaching out to business to ask them what their challenges are. I would bluntly categorise small companies into two types: those who are extremely sensitive to the ethical issues around the data, and those who have not even thought about it. It is not that the latter group is in any way evil; it is simply that it is driven by technology and a can-do attitude. On the one hand, the former group are appealing to us, “Please could you come in and certify that we handle these data in a certain way, such that you can evidence this and build it? We have no ground to rely on, so how can people trust us?” versus others who say, “We have this technology; it's great; we can do this stuff.” It leads to tension between innovation and regulation. Some of the most innovative things have come about by slightly stepping over the line, realising that and then stepping back. I see huge amounts of creativity in the SMEs, and one thing we could usefully do is make them more aware of some of the ethical challenges that this sort of processing causes. 
349|Q99|Stephen Metcalfe|That would be improved by better collaboration. 
350|Q99|Professor McAuley|For example, yes. 
351|Q100|Stephen Metcalfe|How would you go about it? What steps are needed to improve the interaction between small businesses and academia? 
352|Q100|Professor McAuley|I find that for small businesses, especially at the start-up end, keeping food on the table is the important thing. They need very practical advice that is directly related to the sort of thing they are doing. They would probably find most of the papers we publish in the academic journals impenetrable, given that they are written for a very particular audience. In a sense, we need a translation from what is often very generic, abstract work into very practical sector-specific, even context-specific, areas. In many ways, it is not necessarily a property of the data. Data by themselves have in a sense no value or ethics associated with them; it is what you do with them, and each of these companies needs to have a case study or something they can understand and relate to. That translational work between the very generic and abstract academic research into the very practical lessons for these SMEs is vital. 
353|Q100|Chair|Graham—sorry, Jim. 
354|Q101|Jim Dowd|Okay; thank you. You caught me out going out of order like that. It shows an unexpected degree of originality from you, Chair. [Laughter] 
355|Q101|Jim Dowd|If I may make a variation on the earlier line I was pursuing as to the tension between having good, sound analysis of data and the need for informed consent, to save you tiring yourself with the cliché that it is a question of balance, which option would be the primary concern, and why? 
356|Q101|Sir Nigel Shadbolt|A prior problem is that the presumption is that it is a one-way deal at the moment for most people who give up their data either to Governments or commercial organisations. One of the things that needs to be rectified—we are starting to see this happen, partly post-Snowden—is the rectification of this information asymmetry. People want access. They do not want to control it necessarily, but they want to know they can get their information back and out, and that they have some rights and entitlements over it. We will start to see a swing very much in the judgment, opinion or assumption that it is our data, whether it is health records or our social interaction record. This is something we are going to see come increasingly to the fore. 
357|Q101|Sir Nigel Shadbolt|Then the question is: what are the analytics that can and cannot be performed on that? We will then find people being asked much more to consent for all sorts of reasons, whether it is medical research or social analytics of a broader sort. There may be some mandated areas. The census is a good example where we can imagine using many of these as proxies for certain sorts of census data. 
358|Q101|Sir Nigel Shadbolt|A lot of the challenges here are trying to get a mindset where we can imagine that in this world the device formerly known as the mobile phone—this device—is your personal information device. You take your photographs on it; you record your music on it, and why should you not be carrying increasing amounts? It does not all have to disappear into the cloud. There is a very significant sense in which you can act as the custodian of this information. The question then is: do you get personal analytics on this? A very good example is well-being. There are any number of fitness monitors that you carry around to monitor how and where you jog. That data could become hugely important at the stage before primary care. The assumption will be that those are my data. Unfortunately, at the moment I upload my data through an application. That application goes to somewhere in Finland, and the small company that started this fabulous app called Moves gets acquired by Facebook. Now all my data, exquisitely detailed, have gone somewhere else. We have not really understood the food chain enough to realise that the analytics you might do could end up in a place you did not anticipate or did not expect, and did not think you had permissioned. 
359|Q101|Professor McAuley|It is increasingly the case that we can find a lot of these interesting applications by the fact we are sharing data. A lot of the analytics could be performed on my personal data in isolation. That is what I refer to as the 1990s Microsoft model of business, which is, “We'll ship you some software that you can use in a private context to edit whatever documents you want,” to be contrasted with the modern CloudWorld where I have no idea who is looking at my documents if I am online editing it on Google Docs. I have no auditability of that or visibility of what is going on. As for a lot of the existing models of, “Ship us your data and we'll process it and give you this value,” there is absolutely no reason these data have migrated into the cloud and the analytics on your own personal platform. 
360|Q101|Professor McAuley|Then we might turn it around and say, if someone gave me an application that was really valuable and said, “By the way, would you mind sharing these derived statistics from your information?”, I would say, “Yes, that's okay, because how many miles I walked today is not particularly sensitive. Of course you can have that.” Many of these companies would say that those are the data they want. They do not in a sense want your personal data; they want some statistics from your data. There is a question technologically about how we might implement that in the future. 
361|Q102|Jim Dowd|Could they not just anonymise it? 
362|Q102|Professor McAuley|They can anonymise it; that is one thing. 
363|Q103|Jim Dowd|But they won't. 
364|Q103|Professor McAuley|The key thing is that, if you are among the truly paranoid, would you believe they have anonymised it? What measure would you have to know they have done that, rather than remembering your IP address and unique identifier from your phone? They have asked for your contacts, and there are many other things. The truly paranoid would say, “Even if they say that, how do you know?” For the companies that are honest and true, one of the things they might welcome would be, “Come and audit us.” In fact that is one of the requests we have had. We did an online survey recently where 60% of the respondents said they would support third-party auditing of their privacy policy. They want someone to come and verify that it does what it says on the tin. They say, “This is our privacy policy, and, yes, by God, we do it.” That includes some very big companies. 
365|Q104|Jim Dowd|That would imply a regulator of some kind. Whether it is industry-funded or Government, there would have to be an interventionist body of some kind to do that. 
366|Q104|Professor McAuley|Indeed. I simply look at other aspects of human life. Whether it is organic food supply, green building regulations or financial audit, in order to have faith in the system as human beings we traditionally require a third-party expert to look over it and say, “Yes, actually, they are doing this.” 
367|Q105|Jim Dowd|Like Arthur Andersen. 
368|Q105|Professor McAuley|I would not like to jump to who might do it, but that might be one. Financial audit is a very good model to use, because it has to scale from the small company with three shareholders to the multinational. Arthur Andersen do not deal with a company with three shareholders, so one would need a mechanism to scale from small to large. 
369|Q106|Jim Dowd|The surveillance of social media by GCHQ has become an issue of late. How do you reconcile—if, indeed, you do—obtaining user consent with the demands of national security, given the fact that, as Professor McAuley says, to those who are truly paranoid “national security” is simply a cloak used by Government to do nasty things to their citizens? 
370|Q106|Professor De Roure|That is a very important conversation. I am concerned that by focusing on GCHQ and surveillance we are looking at only part of the picture. If we expand that to law enforcement and the use of social media to help the police in enforcing criminal legislation, we can see clear benefits. A word I would like to use here is “asymmetry,” which Nigel used in a different context earlier. We would not want through legislation to constrain our law enforcement, or our national security, to have less power through the use of social media than those who are threatening us in some way. I think the principle of symmetry is really important. 
371|Q106|Professor De Roure|The other way in which this discussion enlarges very importantly is that it is not just about the individuals, but the companies, the universities, the security of the data and the use of social media data in all those contexts to protect companies, IPR and ensure there is data integrity in our organisations. So it is a much bigger discussion beyond GCHQ and surveillance space. 
372|Q106|Sir Nigel Shadbolt|Also, it is important to understand that there are legitimate issues to be addressed, which I know are very much in the minds of politicians and the agencies themselves, around bulk collection. One of the challenges, because the technology exists, is to collect bulk and then decide how you pay attention to it. People imagine that that is essentially the world we are in, whereas in many aspects of our digital age the data are paid attention to only if there is some sense that it exceeds a threshold; otherwise, it simply boils away. When you go past speed cameras, typically they activate only if you are breaking the law and then your image is taken. That feels a much more proportionate response. 
373|Q106|Sir Nigel Shadbolt|In some sense, we are going to move to a situation where we will be living in this extraordinary digital panopticon where huge amounts of information are coming in all the time. To imagine that we have to find some safe place to store it where we can pore over it at leisure seems in a sense disproportionate, and possibly a poor use of financial resources and technical capability. It is much better to have a sense of what you think you are interested in so that you can pay attention to the important signals. That is one area where social media research is very important. It is not as if this stuff does not have a background theory. We have to have a sense of why we are looking at the information in the first place. Historically, completely open, large-scale fishing trips have not been extraordinarily successful. You need insight to direct your search in these contexts. 
374|Q106|Professor McAuley|Many of the protocols that have existed for years would have made the mass surveillance we have had not possible, but for commercial reasons, because it costs a few more CPU cycles, or whatever, they have not been deployed. We are now seeing the reaction to that, which is the deployment of, “We will encrypt all e-mail connections,” because this behaviour was not expected. 
375|Q106|Professor McAuley|I go back to asymmetry. It would be one thing to say that in the future we will find that many of these channels will be encrypted, so interception and flight will not be possible, but for it to be possible for some nations to access everything no matter where it is on the planet, by the issue of a court order in those countries, whereas it is not applicable the other way, does not seem equitable, and one may want to ask what is reasonable internationally with partners in this regard. 
376|Q106|Professor De Roure|Reflecting on the comments made about this and the previous question, we seem to be giving lots of examples that would cause citizens to have a reluctance to release the information. I am a little concerned about that, because we should also be explaining the benefits of the analysis of this information, which we have discussed less. I would like to balance that a little bit. The positive stories resulting from social media analysis need to be propagated as well. 
377|Q107|Chair|Professor McAuley, you mentioned in response to a question just now that 30% of users wanted a third-party audit. 
378|Q107|Professor McAuley|Sixty per cent. 
379|Q108|Chair|You referred to some research. Is that published research? 
380|Q108|Professor McAuley|It is a survey, and that was the data as of last Wednesday night. We are preparing to present this to the Information Economy Council on 1 July. We floated a document for consultation on practices around personal information which had, in my opinion, two substantive elements over and above what has been said so many times about personal data, access and control and consent. One point was simplification, which includes templated contracts instead of bespoke legal contracts for every website, and an iconic representation of them: “This is what we do with your data.” The final one was: what was the appetite for third-party compliance checking against that, including ethical process for approval of new products and services, and privacy by design; was the system designed to ensure your privacy? 
381|Q108|Professor McAuley|We had an open meeting last Thursday and had an online consultation the week before that. The statistic was that 70% agreed, or strongly agreed, that third-party regulation would be a good thing; 20% sat on the fence; and 10% said they disagreed. To me, that shows there is an appetite in the UK among companies for this. It means there would be resistance to legislation, but if 70% of them agree, and strongly agree, I think it would be good to respond to that request. 
382|Q109|Chair|This is all coming into the public domain formally on 1 July. 
383|Q109|Professor McAuley|Yes. 
384|Q110|Chair|Perhaps you would be good enough to let us have a copy of it. 
385|Q110|Professor McAuley|I will do. 
386|Q111|Graham Stringer|My apologies if you covered part of this earlier. I missed the first 10 minutes of this session. Sir Nigel, you are responsible for open data strategy across the UK Government. Can you explain what that is, how close we are to achieving standards for open data, and just what that means? I find it difficult to know what a standard for open data would be. 
387|Q111|Sir Nigel Shadbolt|Yes, indeed. We began this work in 2009, and it has been very successful. It was all about releasing primarily non-personal Government data that Governments collect, usually at taxpayers' expense, which is everything from infection rates in hospitals to where bus stops are located and transportation and education spend data. These have typically not been social media data; they have not been at the personal level. When we refer to open data, we are very keen that the debate respects and understands the varieties of data now in play on the web, from personal data, to anonymised data, to non-personal data, to big data and relatively small data, but nevertheless incredibly valuable data, that sit on spreadsheets in various parts of Government. We have released much of this data. 
388|Q111|Sir Nigel Shadbolt|When we talk about standards, we mean the ability not to stay locked within a particular piece of software and not be used by another piece of software. Famously, we do an awful lot of processing of spreadsheets and are familiar with that. There are ways to store the data in a way that another spreadsheet program can ingest the information, not a particular product issued by a particular software provider. There are interoperability standards. There are standards around how you refer to and describe the data, and how they relate to social media data. Often, you can argue about whether social media data are open or closed. Things like your Twitter stream are typically open; it is going out there into the open. 
389|Q111|Sir Nigel Shadbolt|A very important aspect of the work going forward in this area will be to agree standards as to how we can represent and allow that data to be analysed, because at the moment, frankly, people are dreaming up a particular format or way of representing this information and going ahead with it. One of the interesting research disciplines is to work out how we can, with a little engineering, allow for a much easier flow of information between our analytics. 
390|Q112|Graham Stringer|Are you telling this Committee that you have achieved the impossible and got different Government Departments to be able to access each other's data? 
391|Q112|Sir Nigel Shadbolt|We have made pretty good progress, actually. Technically, it will be no surprise to this Committee that the real challenge is often organisational or cultural. We know how to fix the technology, but it is a matter of understanding how we can allow that information to flow. This will be an interesting challenge. If Government are serious about trying to use the product and insights of social media for themselves and their own Government Office for Science and departmental analytics, this sharing will be essential. 
392|Q113|Graham Stringer|How important is access to Government data to organisations that are interested in analysing social media? 
393|Q113|Sir Nigel Shadbolt|Very much. 
394|Q114|Graham Stringer|Can you put figures on it at all? 
395|Q114|Sir Nigel Shadbolt|Certainly, particular outputs, like the index of multiple deprivation and a variety of ONS datasets, are hugely valuable, because they talk about social mobility, and I think it is intrinsically billions of pounds-worth of value. 
396|Q114|Sir Nigel Shadbolt|The first instinct is to say, “We must be charging these people for this.” In that case, the whole premise of open data is that by making them openly available you allow a whole range of companies to participate in and use those data to drive insight around business and the provisioning of services, but the Government-generated data that relate to everything from education to health and social welfare will be of highly material significance. The kind of work on which the ESRC—the Economic and Social Research Council—focuses much of its attention is precisely this sort of so-called administrative data. David, is there a value for this? 
397|Q114|Professor De Roure|We could go away and calculate that. 
398|Q114|Sir Nigel Shadbolt|It would be very large. 
399|Q114|Professor De Roure|Yes. 
400|Q115|Graham Stringer|You gave a definition of standards partly in answer to this question. I do not know if it is a meaningful question. What should confer standards on our open data? Are standards the doorway to making sure you are as open as it is possible to be? 
401|Q115|Sir Nigel Shadbolt|I think it is one of the underpinning foundational principles. It seems very obvious. The Government have been doing some quite good work in this area. The Government Digital Service has been looking to mandate open standards, so these are not standards that are proprietary or owned by a particular company or sector. These, along with licensing and a whole range of now quite well understood components, remove friction from the system. Standards have bedevilled everything from health care to welfare to credit payments over the years. The web is a great example—perhaps the best example, along with the internet—of a global fabric which has worked because its standards are open, understandable and freely available. 
402|Q115|Professor McAuley|I would add a comment on the importance of standards in releasing data. We want to compute with this data. It is no good releasing it in a text document or PDF. It was data in a spreadsheet, and it gets turned into a table in a printed document. That can classify as open data. The data are not open. This requires human beings to process all this data and probably type it back in. One of the key things about open standards is to get to the point where the data are released so they can be immediately reused computationally rather than with human intervention. A key tangent on this is that we have been working with cultural institutions to release their content as data, not as a website for people to experience, or for a human being to experience, but so that it can be repurposed and reused. The key thing is to get the data so that they can be reused, repurposed and used by many tools if they are in a standard form and accessible to a computer, whereas, “We have published this; it happens to be in this document” does not make it reusable and repurposable. 
403|Q116|Chair|Sir Nigel, you said in response to Graham Stringer that within Government, sharing is essential. You may be aware that I did some work with Government at the beginning of the 1990s when the issue was not about the technology but the people issues and creating a management structure that has fuzzy boundaries between Departments. Is it still the same in this era of dealing with social media data as well? 
404|Q116|Sir Nigel Shadbolt|We are starting to see an understanding that the value of information and data exchange is so high that silos are understood to be unfortunate and get in the way. 
405|Q116|Sir Nigel Shadbolt|The real issue is to incentivise officials at various levels to understand why this is beneficial, there are cost efficiencies and better information flow as a result. 
406|Q116|Sir Nigel Shadbolt|To come back to the whole issue about capabilities, unfortunately this is an area where effective and agile use of data is something the Government have to look at. Have they really got the mix of skills in the civil servants? It has them in a few specialist areas, but generally is there an awareness of what is required here? Even if you can incentivise and get the cultural and organisational pieces straight, do you have people who would actually know what it meant to say what Professor McAuley has just said about the whole idea of a PDF versus an open exchange format for a spreadsheet? 
407|Q116|Chair|Of course, all of that is much harder than the technology on many occasions. 
408|Q117|Stephen Mosley|That leads very nicely to what I was going to ask, which was about skills and the UK skill base. Professor De Roure, the ESRC have said that the UK data capability strategy was not sufficient in the area of training. Could you explain what you meant by that and say what you think should be included? 
409|Q117|Professor De Roure|It is very good as far as it goes, but what we are looking for is to drill down further in the implementation, very much along the lines we have been discussing here. This is one of the reasons we welcome this inquiry because it will emphasise the areas that need greater attention. 
410|Q117|Professor De Roure|“Data capability” is a good phrase. because it is not just about the data but the capability, which requires all the things we have been discussing from the human skills to the analytics skills, the core science and situating that in real examples of UK life, working with the software and the exchange of methods and practice that we have been discussing here. I like the PDF example, because even in our scholarly communication process we are still using techniques that are 350 years old—we should celebrate it—to exchange information. In the digital world and the world of social media there are many new ways of doing these things. There is an emerging social media methodology. New and best practice is beginning to form, and that really needs attention. 
411|Q118|Stephen Mosley|Expanding out a bit, do you see a lack of individuals with the right level of skills? If so, what effect is it having on the social media analysis sector? 
412|Q118|Professor McAuley|At the digital economy catapult we have been hiring a number of senior technical architects. We had to pay 20% more for the people who had the data science skills, so it is clear that there is a premium in the market for them right now, which would indicate to me that there is a shortage, never mind that they took a lot of finding. When it comes to social media, it is even worse. Those are pure data science skills. People who have the appreciation, when dealing with what I refer to as human data, that the consequences of the analysis could do harm to individuals and have a sensitivity to that is something we need to be training up. For example, if we look at something like the Turing Institute announced in the last Budget, I would like to make sure that they have an ethical strand to all the statistics and analytics they do, because that is where we have seen a lot of the impact happening. There is a shortage. 
413|Q118|Professor McAuley|The data capability strategy of the research council mentioned that they were bringing forward a proposal for a series of data analytic centres. Much of the data they were talking about was human data—it is not particle physics or the Square Kilometre Array—and that requires a sensitivity to the social sciences that we have a severe shortage of. 
414|Q118|Sir Nigel Shadbolt|We have not fixed this if we just throw tin and fat pipes at it. The big computing infrastructure is required, but it is also about human analysts, and it is not just retooled computer scientists. I speak as a computer scientist. We need to bring in people with the social science skills and skills in statistics and experimental design so that they will know how to take the data and turn it into information and put it into a wider context. These are not assemblies we have routinely been putting together in our universities. We are starting to see an awareness of that, but I would urge that, when we think about supplying capability from the higher education sector, we understand that we need these mixed methods. A broad set of disciplines is required from mathematics, statistics, behavioural and social sciences to computing. 
415|Q118|Sir Nigel Shadbolt|The requirement to get data analytic centres which have a range of perspectives and orientations could be really powerful here. I refer to a bunch of people who look at the data from the point of view of retail analysis, financial engineering or social exclusion. We have not talked much about that today. What about those sub-populations who essentially are not well represented in social media? Can we identify the missing footprints as well as the digital footprints at play here? 
416|Q119|Stephen Mosley|So far there has been very much focus—it is understandable, given your backgrounds—on the public sector: universities, research councils and the Turing Institute. Does the private sector—business and start-ups—have a similar problem, or does it find it easier to recruit? 
417|Q119|Professor McAuley|Start-ups present their own special case, but I would like to take a couple of large companies: a retailer and a telecommunications operator. I will not name them because it is under commercial confidence. They are both talking about a charter that they would publish concerning how they process data so that their customers would know what they are and what they will and will not do, and try to build up that relationship of trust about how they will process the data. It would be very easy for a large retailer to find you, given a customer loyalty card, on social media. They currently do not do this and do not wish to do it for fear of what the backlash would be. For those companies it has been a painful learning experience, including having the data analytics people saying, “We can do this,” the marketing people saying, “It's great to have more information,” and the people who own the brand saying, “Please don't mess with our brand by doing this bad thing to our customers.” In that sense, they are the ones who are representing the social science side. 
418|Q119|Professor McAuley|Increasingly, even large fast-moving consumer goods companies are concerned precisely about this issue and are engaging with social scientists, as well as technologists, on this. There is a real demand in industry. The problem with SMEs is getting together enough people who have that skillset when you are a five-person operation. You need a sociologist. You cannot afford a full-time sociologist; you are too busy. You have three developers, or whatever, and someone running the company. What you need is guidance and information about what to do. What is safe and secure and what would customers expect, rather than unnecessarily being able to bring together these multi-disciplinary teams? 
419|Q119|Sir Nigel Shadbolt|We have talked about the UK context here, but the Web Science Trust has fostered a global lab-based network of 14 where people are doing analytics in this space and are trying to put together the interoperability to allow us to share insights. There is an issue here about how we learn from and can inform the global social media analytics in this space. 
420|Q119|Sir Nigel Shadbolt|On your point, I do think these companies are well aware that at the moment there is an absolute race to secure the best of a very scarce talent—the so-called data scientist. 
421|Q119|Chair|Gentlemen, thank you very much. It has been an extremely interesting session. 
422|Q120|Chair|Good afternoon. Thank you for coming in this afternoon. All of you have been sitting here listening, so you understand the format. It would be helpful if you could introduce yourselves for the record. 
423|Q120|Professor van Zoonen|I am Professor Liesbet van Zoonen. I am professor of media and communication at Loughborough University. I lead a big research project about public taboos and desires around identity management and the sharing of personal data. It is very much focused on what people want and do not want. 
424|Q120|Dr d'Aquin|I am Dr Mathieu d'Aquin. I am a researcher in data technologies at the knowledge media institute of the Open University. I am currently focusing a lot on the data infrastructure for the Milton Keynes future cities project. 
425|Q120|Professor Robertson|I am Dave Robertson. I am head of the school of informatics at the University of Edinburgh, but I am really here representing the UK Computing Research Committee, which is an expert panel of the British Computer Society. 
426|Q120|Emma Carr|I am Emma Carr, the acting director of Big Brother Watch, which is a civil liberties and privacy campaign group based in the UK. 
427|Q121|Chair|Thank you very much. We touched on this directly and indirectly with the previous panel, but who in your opinion is most likely to misuse data—the Government or the private sector? Do the Government need to approach social media data usage differently from how a private company might? 
428|Q121|Professor van Zoonen|From our research, we can say that the UK citizens' approach to this is that they tend to believe that the Government are a bigger risk than private corporations, although that is changing very rapidly due to practices by Tesco, for instance, that are becoming more well known. If you look at what people think about this, they still think the Government are the biggest risk. 
429|Q122|Chair|That is Government per se. Does it break down into different Departments having a greater degree of trust? 
430|Q122|Professor van Zoonen|Yes. It also breaks down into local government having more trust than national Government. The further away people are from national Government, the bigger the distrust of national Government and the trust in local government is. Of course, those different levels of Government are not included very often in the discussions we have about big data. We tend to presume that it is a global, national discussion, rather than also a local one. 
431|Q123|Chair|A while ago I saw some data that suggested that one of the Government Departments fairly high up the list in trust—relatively—was the Treasury, which seemed to me to be an absurdity, but there are some odd human reactions to Government Departments. 
432|Q123|Professor van Zoonen|Yes. It also depends a bit on which people you ask and what their political views are. There are definitely groups of people who have a high degree of trust in the legal institutions, the police and the secret service, and groups of people who do not have that. In that sense, there is not an overall picture. 
433|Q123|Dr d'Aquin|Unlike Professor van Zoonen, I cannot talk about people's perception, but our research shows—besides what we might not know about Government capacity—that the organisations that will have the best ability to misuse personal data are certainly private companies, especially large-scale private companies not located in the UK, including the big social media platforms in the US, as well as companies that are not necessarily directly associated with social media but that collect personal data as a side effect of their activities. Of course, Google comes to mind. Some of our research has shown that, looking at the web activities—the web use—of average users, the biggest amount of disclosure of personal data will go to systems such as Google Analytics. That also includes mobile phone providers, internet providers and all the companies that have the capacity to collect very large amounts of personal data, which could, if they wanted, be largely misused. 
434|Q123|Professor Robertson|It is really difficult to identify where the threats will come, but there is a special responsibility for a Government in all of this. The one thing a Government can do that is really hard for others to do is set an example. Open data is a good example of that. Government can set an example by backing initiatives of that kind. That is the limit of it—you do that and see what follows and so on and so forth. To some extent, you can have regulation as well, but that kind of light-touch example setting has already been pretty effective in many ways. Maybe you could go further, but it has done a lot. 
435|Q123|Professor Robertson|The other way round is to apportion blame. I will leave that to people who are more closely involved, but I expect it is really hard. It is really brittle as well. It is very difficult to know at exactly what point you lose trust in some of these systems because they are so pervasive. It is difficult to know where the rubber hits the road with the system and where it will have an influence on people—or not, as the case may be. 
436|Q123|Emma Carr|Depending on what kind of data you are talking about and what the use of those data is going to be, the polling seems to indicate that the public have a very similar outlook on the public and the private sector in terms of how safe their data are with them. However, generally, people hold the Government to a much higher standard when it comes to data protection. That may be because people know that private companies are usually using their data to make money—for advertising purposes. When we see any indication that the Government are making money out of our personal information, especially when it is being sold to, say, insurance companies—Care.data comes to mind— people seem to get extremely upset about data being used within the public sector generally. 
437|Q124|Chair|I will come on to Care.data. Professor Robertson, the UKCRC said that the Care.data initiative was “out of step with public opinion.” Could you explain that? 
438|Q124|Professor Robertson|The reason for choosing that example was that it is a good example of what I was mentioning before—how brittle these systems can be. We had no particular reason to believe that there was any notion of malice or impropriety in that particular initiative. As far as I am aware, the people running it were doing the best job they could possibly do, but it got slightly out of step. By out of step, I mean that the people whose data it was were not fully aware of what was going on. Because they were not fully aware in the right sort of way—in their culture or their understanding of what is going on in the scientific community; you can frame it how you like—it was badly rolled out. Because of that, there is a scientific consequence, which is that research that could have gone on quite legitimately and successfully, had that been done just a little bit differently, will probably be held up. 
439|Q125|Chair|Are there particular examples you can draw our attention to in terms of that initiative? 
440|Q125|Professor Robertson|Emma Carr is nodding and may be able to give better feedback than I can. The simplest thing is that people simply did not know that this was going on until it leaked out in the press. In Scotland we have not had this kind of impact because we did not take that step, but when we talk to people about this sort of thing quite often their view is, “Oh, aren't researchers using my data for something useful that will help to make people better? Wouldn't that be good?” That is very different from suddenly finding out that people are going to do something you were not told about that may be partly commercial and partly about harvesting data and is now going to become institutionalised. It just plays badly, regardless of what the motives are. That is the problem—it is the public perception of what you do. It makes the problem very difficult. It is the reason you have Caldicott guardians for medical data. You have to have people whose job it is to understand how to reconcile those dangers. 
441|Q126|Chair|Isn't that a rather difficult area? There are circumstances where exactly the same practice could be used for a commercial benefit. Let's take the use of cameras as an example. There has just been an understandable hue and cry about terrible cases of abuse in a care setting. I heard one person advocating for the families of the victims say that there ought to be cameras in every care setting. That was for a perfectly good moral reason, but, equally, cameras can be used to understand customer behaviour and so on. You cannot generalise, can you? 
442|Q126|Professor Robertson|That is the problem—you cannot generalise. This is moving very fast. Some form of data analysis is embedding itself pretty deeply in domains; health care is one, but you can choose pretty much any other domain you like. If you look at what industry predicts, a big proportion of the data available to it will be social data—data derived from the living population. If that is true, it will embed itself very deeply indeed. It is really hard to reconcile some of these issues without understanding domains very closely. Care.data could not have been predicted by a computer scientist working alone. I suspect it probably could not have been predicted by a sociologist or a social anthropologist—or even a medic—working alone. Somehow the mix has to work. You can see signs of these kinds of interdisciplinary groupings building up, but it is an avalanche. It is probably impossible for us to move so fast that we could make it risk free. 
443|Q127|Chair|Do you want to add to that? 
444|Q127|Emma Carr|Big Brother Watch did some polling at the beginning of the year. We found that 69% of people had not been informed of the right to opt out of Care.data. This is entirely the point. Whether we are talking about Government use of data or private sector use of data, it is all about consent. You cannot just presume informed consent because, as in the case of Care.data, a leaflet has been sent out. Especially when it comes to something like medical data, where if people do not have trust that their data will be kept secure it may have hugely detrimental effects both on their own health and on the public sector as a whole, you have to ensure that there is a higher standard than for just tweeting or Facebooking about your day. If you stop doing that as a result of not trusting Facebook or Twitter, it does not really have the same consequences. 
445|Q128|Stephen Metcalfe|Talking about trust, where has this lack of trusting the Government with data of any sort come from? Where has it grown up from? It strikes me that inherently the Government are trusted less than almost anyone else. 
446|Q128|Professor van Zoonen|There are a couple of reasons you could think of. One is the particular context of the UK and the reason why data are collected here, which is very much set in a security framework. That has historical reasons and has to do with the alliance with the United States. If you compare the purposes of data collection for the UK Government with the way in which that discourse is framed in continental Europe, for instance, you find that in continental Europe the whole discourse about data collection from citizens is about providing service to citizens—making sure that a Government can offer better services to its citizens. The discourse in the UK is a safety discourse. That is a helpful discourse for citizens in the immediate aftermath of a crisis, when people buy into that and think it is really necessary, but after half a year people think, “Right, that is not that good an idea.” The transaction is a little bit abstract. You give your data and get security, but the longer that takes, the more abstract it becomes. In the Indian situation, for instance, and in Europe, you give your data but you get a better service. That is a really different way of presenting the policy. 
447|Q129|Stephen Metcalfe|So in the UK the citizen does not see the link between sharing data and better services. 
448|Q129|Professor van Zoonen|No, not yet, because the whole discussion here is always about security. Look at the surveillance cameras, the Patriot Act and its aftermath and data protection—it is all in the context of protecting your citizens, not of offering better services. That is there, but not as the first thing. 
449|Q129|Dr d'Aquin|I agree with that view. There are quite a number of different elements. I am not exactly sure we can say that citizens do not trust the Government, but what private companies—especially the big private companies—give back in exchange is more direct, sensible and visible. There is the notion that if you want to collect information from users in a commercial system, or even in an academic system, you have to provide incentives— you have to have something in return. From a commercial perspective it is much easier to make that something in return visible to the user. 
450|Q129|Dr d'Aquin|There is another aspect. Our research experience suggests that a lot of the lack of trust comes from fear of interpretation. If data are collected by Government, users need to have an understanding of what is going to be done with them. While it is still very obscure in most cases why personal data are being collected all round and what your social media platform will do with them, the obscurity is much bigger when it comes to Government. As has been mentioned, there is no clear indication of what the exact use and benefit globally of this particular data will be. 
451|Q129|Dr d'Aquin|That is where the fear of interpretation comes from. In some of our research, we have seen that, if you put users in front of the personal data their employers collect, reactions are often very pragmatic—“Of course,” “That is fine,” “That is normal,” “That is part of operational services”—but on certain very specific aspects the user will want to have a right to respond to their personal data. For example, a user spending a lot of time on the vacancy pages of their own organisation will feel that they need to provide context to that particular information so that it can be interpreted properly. The lack of trust also comes from this—the inability of the user or the citizen to provide the context for interpreting the data they make available. It is a lack of control, really. 
452|Q130|Chair|In these two answers there are some interesting contrasts, aren't there? On the one hand, I suspect that just about everyone in this room has a piece of plastic provided by some banking organisation or another where we have given a lot of data. The trust vehicle there is that, if they go wrong, they commit to making good their mistake financially, broadly speaking. On the other hand, I suspect we all have a Government piece of paper—an Oyster card—in our pocket. The payback there is the convenience of not having those wretched queues at the ticket office, isn't it? So there is a point where the public give in to some of their worries about the role of Government in exchange for a service—the point you made, Professor van Zoonen. 
453|Q130|Professor van Zoonen|Going back to the Care.data discussion, if you look at the way that is brought to the public—at least, in the website information—it is all about helping the NHS improve its services. That is interesting, because there is no direct link to how that helps the individual patient; it is all about helping the institution. The other side of that— what you get for the transaction—is underplayed, so to speak. Again, that is an example of an institutional interest—a Government interest—taking precedence over the individual citizen or patient. It is a matter of framing your data-sharing policy, in a way. 
454|Q131|Stephen Metcalfe|Do you want to comment on the original question of where this lack of trust comes from? 
455|Q131|Professor Robertson|This is a personal view, but I do not believe that Government is necessarily trusted less in all respects than some companies. I do not think there is a tremendous amount of trust in some of the large companies dealing with data—it is just the way that it is articulated. You have to choose where your pedigree examples are from. In Edinburgh, there is probably not a lot of trust in the local authority building tram systems because it did not go tremendously well for us, even though we now have a tram system—which is good, sort of. It is that kind of thing. 
456|Q131|Professor Robertson|There is still a monolithic feel to Government IT, which does not square well with the picture that was painted for you earlier of very lightweight, streamlined services, relevant to the user and so on; it just does not feel that way. I feel for people in Government, because that is quite a difficult one to shift. You do not have the luxury of being able to say, “Oh well. We'll start with a clean sheet of paper.” There is a whole lot of baggage to do with public service and Government that you would not have if you were a start-up company, so it is very difficult. On the other hand, that is the way the world appears to have gone. From apps and all the way through, people are much more accustomed to being able to chew things up in small bits and understand vicariously the notion of a service that is delivered over the internet. That was not true five years ago. I should think it is tough for Government; that is part of the reason. 
457|Q131|Emma Carr|There has been far more in the media about data loss in the public sector than about data loss in the private sector. Part of that is Big Brother Watch's fault, I am afraid, for putting that into the public domain. Quite often you hear about USB sticks with child protection information being left on buses or mobile phones going missing and the relevant security not being there to protect all of that information. 
458|Q132|Stephen Metcalfe|Because that never happens in the private sector. 
459|Q132|Emma Carr|Apart from one or two high-profile cyber-security attacks involving people's credit card details or whatever, it is on a much smaller scale. Obviously it happens, but— 
460|Q133|Chair|How do you know it is on a lower scale? You can't possibly know that. 
461|Q133|Emma Carr|How do I know what is on a smaller scale? 
462|Q134|Chair|That loss of data in the private sector is on a lower scale. 
463|Q134|Emma Carr|I think it is probably on less of a large scale than in the public sector. 
464|Q135|Chair|How do you know that? 
465|Q135|Emma Carr|That is entirely the point. We find out because it is usually to do with credit card details. People generally have to find out about that because there is a financial aspect. When it is in the public sector, we generally find out because we have put in a freedom of information request, which we cannot do with the private sector, unfortunately. Again, that is more to do with having a much higher standard for information relating to people's security or health, which people care about much more. Coming back to Care.data, when you have the public sector asking for larger datasets and wanting to do more with them, it raises the question whether the safeguards are there to ensure that those data will be kept to a higher standard than people would necessarily expect from the private sector. 
466|Q136|Stephen Metcalfe|So it is not necessarily the individual coming to the conclusion that they should not trust the Government when the data are passed over, but someone telling them they should be outraged that the Government want to use those data to provide a service. Do you think that is why the Government are now pulling away from sharing more data? Are they fearful of media and public reaction because people are being told through the television, the radio and the newspapers, “You need to be outraged”? 
467|Q136|Emma Carr|I disagree that the Government are pulling away. I am on several advisory boards that are helping the Cabinet Office and NHS England to try to go forward with data-sharing practices. We can all agree that it would be beneficial to the public sector to have that extra level of data and to be able to analyse it to help public services—it is just about going about that in the right way. Care.data highlighted exactly the wrong way to go about it—by not telling people what you are going to do with the data, who will have access to them and how they will be shared. 
468|Q137|Stephen Metcalfe|Do you not think that the damage has now been done—that now no one will ever want to share those data? 
469|Q137|Emma Carr|Exactly. That is why I am on the Care.data advisory board. We are working extremely hard to ensure that those mistakes are put right and the public can have confidence, when it does go ahead, that they have been taken away. We need to ensure that at all levels of data sharing, whether it is in the NHS or at local authority level, people can see from A to B exactly what is going to happen with their data. Unfortunately, there have been too many occurrences where that just has not been demonstrated. 
470|Q138|Stephen Metcalfe|On that one area of Care.data, were you proposing that people should positively sign up to allow their data to be used, rather than negatively pull out? 
471|Q138|Emma Carr|We would always advocate an opt-in rather than an opt-out as best practice, but we understand that that is not always practicable. However, we suggest that you do not tell people by means of a leaflet that you intend significantly to introduce different means of sharing medical data. 
472|Q139|Stephen Metcalfe|So somewhere in the middle there is a way to be found. Do you think that the Government Departments that are potentially in possession of large quantities of data and might have opportunities to share them are not skilled enough to know how to use them and how to prepare the public for sharing them? 
473|Q139|Emma Carr|We have been involved in workshops in the Cabinet Office about using big data to solve fraud, error and debt. Interestingly, when we ask what data they want to have and currently cannot have access to and what they want to do with it, often they do not have the answer to that question and take quite a long time to respond. Often in our experience at Big Brother Watch we find that they know big data is available—it is talked about and is seen as something of a new, modern silver bullet to aid public services—but there is something of a question mark against what they then want to do with it, perhaps because they do not have the necessary knowledge inside that Government Department. 
474|Q140|Stephen Metcalfe|Going back to the public's view on how all of these data are stored or used, is the concern about their collection and storage the fact that they might end up on a memory stick on a bus or a stolen laptop, or is it not about where they are stored but how they are then used? Where does the main concern lie? Has any research been done into that? 
475|Q140|Professor van Zoonen|It is also about how and where the data are stored. In general, if there is a central storage system, there is much greater suspicion about what is going on than if storage is decentralised. In Estonia, for instance, they have a national identity card that offers a lot of different commercial and Government services. The trick there is that all of the data that you hand in to those services are kept on different databases. They do not go into a central database. That makes quite a big difference to how much people trust such a system. The other thing that makes a difference is whether people know that their data are being collected or whether they are being remotely collected, either by remote biometrics or by commercial monitoring on the internet. Having a certain level of awareness and a decentralised storage system really makes a difference. 
476|Q141|Stephen Metcalfe|So identity assurance providers who collect data and assure you that it will then be protected are not the answer, because that would be one central database. 
477|Q141|Professor van Zoonen|There is a level of choice already. Lessons were learned, so people can choose to whom they want to give their data. That is an important difference already. They are aware that they are giving data and that presumably there is a purpose for giving those data as well that is not breached. 
478|Q141|Dr d'Aquin|It is interesting that you connect the two. The identity assurance framework explicitly states distribution of information as a core principle, for the reason that it helps to establish trust by ensuring that no one private organisation will have total control over the entire system. Care.data does exactly the contrary. As I understand it, the current proposal gives the entire provision of software services to support it to one private company. That is one private company that people may or may not trust, but the understanding of how that private company might gain benefit from having such total control over their data is certainly not helping with the trust issue. 
479|Q141|Dr d'Aquin|Going back to your original question, it is true that for a lot of the researchers and journalists who are looking at this aspect the core computing infrastructure—where the data are stored, how they are processed and how secure they are—is a very important issue. Based not on concrete research but simply on an anecdotal understanding of research in other areas, I would say that these technical aspects are far from the concerns of the majority of users. The one question is, “What are they going to do with it, and how can I understand what is going to be done with it in such a way that I can be reassured that the interpretation, understanding and use of the data will not go against my interest?” 
480|Q142|Stephen Metcalfe|How would you ever arrive at being able to reassure someone that the data would be used in a way that they could even begin to understand? We have heard how complex some of the links are between different pieces of data. How can you persuade someone that what is going to be done will be done ethically, sensibly and safely on their behalf? 
481|Q142|Dr d'Aquin|It is a good idea to start by saying what is going to be done. 
482|Q143|Stephen Metcalfe|But there are people out there who will instantly say, “Don't believe them. Don't believe them.” 
483|Q143|Dr d'Aquin|There are mechanisms that do not necessarily achieve that amount but allow a certain feedback mechanism to be included in the whole system. They include some of the elements that have been talked about in the mydata program, which give access not through a complex procedure of requesting it under data protection but by the simple click of a button. A single authentication into one system gives access to the full set of data somebody else might have access to, showing what kind of analytics can be achieved on those data. 
484|Q143|Dr d'Aquin|In our own research we have done that, if only on a small scale, for the relationship between employees and employer. Our research has shown that when employees are faced with the data that their employer collects about them, the majority of them react by saying, “That is reassuring. I knew data were collected and that some things can be done. Seeing them makes me confident that I can entrust my employer with this type of data.” That is a very simple mechanism that is reasonably obvious. Giving the data back to the citizen— making them accessible to the citizen and attaching to them information about organisations and individuals who might have access to every part of them—seems an obvious mechanism, in addition to distribution, of course, to try to improve trust in these sorts of systems. 
485|Q143|Professor Robertson|The issue is really, “What is the evidence base?” If somebody says, “Why should I trust this?” you should have some evidence. The important thing I want to add is that it is not completely a black art. There are things that you can apply that are reasonably well understood. You can have various mechanisms that are just to do with the data artefact that protect it. You can have various protocols. There are all sorts of ways you can try to make sure that that is secure in the narrow, technical sense. There are things to do with the process by which you move data around. You can have processes that are inspectable, that you could accredit and so on. Those are quite often used in health care when you are interested in doing that sort of thing. 
486|Q143|Professor Robertson|The third point is the authority argument, which is to do with professionalism. Just because you are using social data, it does not mean that everyone has to use it. You can have communities of people who have a very high level of trust, which is what an awful lot of this sort of thing runs on at the moment. All of these things are pretty well known. In my personal opinion, they tend to screw up where they are done without respecting the domain. People do them thinking that one size fits all and they can do the same thing as they move between different areas. That is where you get all sorts of sociological and cultural problems. 
487|Q143|Stephen Metcalfe|Thank you. 
488|Q144|Stephen Mosley|While the focus of the last question was very much on trust, it started to move on to things like security and safety of the data as well. Is it possible for the public ever to be sure that their data are secure? 
489|Q144|Professor Robertson|No. I suppose any of us could probably expand on that a little, but let me be the first to do so. I suppose the more detailed answer is “not on any scale that we would care about.” Pretty much as soon as the data start to contain significant content, it is very difficult to guard against that content being able to be used to breach various aspects of your privacy and security. That is it; that is the basic problem we are all fighting against. 
490|Q145|Stephen Mosley|I will assume the answer is pretty much the same for all of you, but could I expand it a bit? Have the Government done enough to make sure that individuals' data are secure? 
491|Q145|Professor van Zoonen|What we find is that people are very concerned about things like identity fraud and privacy breaches. They do not have a real clue about how that works, but it is a big concern. In addition, saying that their data will never be secure is a recipe for quite a lot of distrust. The issue is not making the data more secure but making sure that, once your data have been stolen or mistakes have been made with them, there are mechanisms to correct that. You bring your car to the garage for a yearly check-up to see whether it is still all right. You need to have something like that for your personal data as well, so that they are checked on a yearly basis to see whether they are still all right everywhere and have not been stolen. We hardly ever talk about that kind of mechanism and whether it is a way to repair identity loss, identity fraud and privacy breaches. 
492|Q146|Chair|That would have to be predicated on the citizen having the right of access to data. 
493|Q146|Professor van Zoonen|Exactly. 
494|Q147|Chair|And on having some sort of ombudsman role that presumes the citizen is right, rather than waits for— 
495|Q147|Professor van Zoonen|Yes, it would be the other way round—trusting the citizen to come up with the right personal data, instead of distrusting— 
496|Q147|Chair|I have been arguing that for years. 
497|Q147|Professor van Zoonen|Yes, but an ombudsman is much more on a collective level. There should be individual mechanisms as well. In that sense, we know very little about what kind of crime identity theft is, for instance—who are the most vulnerable people, who are the most likely perpetrators and so on. That would be part of bringing back confidence in Government doing stuff about this, because it is one thing that is very high on the agenda of the people we spoke to, at least. 
498|Q147|Dr d'Aquin|There is an element that relates to transparent traceability—putting in mechanisms that make citizens able almost to audit by themselves how their data are being handled. It is not about having unnecessary technical complexity, but simply about being able to demonstrate the level of security that is being given to the data. 
499|Q147|Dr d'Aquin|You must also respond directly to any possible threat or issues. We had a discussion before about whether or not Government were leaking more data than private companies. I disagree respectfully with the answer that was given. I think private companies leak personal data much more. Almost every month one of the very large companies is shown to have been hacked and to have had data stolen from its system. The difference is that those companies are starting to get better at putting on a direct response by locking out all the accounts that may have been affected and getting in contact directly with the users who may have been affected. 
500|Q147|Dr d'Aquin|It requires very complex and demanding mechanisms to be able to trace back any security issue and how it may have affected users directly. That is the sort of mechanism that could make trust in the security of Government systems with respect to personal data more effective. You can never achieve complete trust in the security of a system, but you can improve trust in the people who are trying to make it secure and the traceability and auditability of the system. 
501|Q147|Professor van Zoonen|It is interesting that in the last two years many of the big companies and consultative groups have issued reports about gaining online trust from their customers. Basically, they have the same discussion that we are now having, about how to assure trust and the secure handling of personal data. For them, it has become one of the key issues in maintaining a good business case. They recognise that if that trust is not gained from their customers they will lose business. It is a very simple economic argument. 
502|Q147|Emma Carr|Going back to your original question, not only can you never be sure that anyone will keep your data safe but it would be completely dangerous to try and allude to that. Sometimes both the public and the private sector can overpromise about how safely data can be kept, whether those are being stored in the UK or outside. 
503|Q147|Emma Carr|Going back to your question about the safeguards, the regularity framework around the Data Protection Act is pretty good, certainly for data in this country, despite its being fairly old. The one thing I would say about it is that there could be far harsher penalties available for people who breach section 55 of the Data Protection Act by knowingly disclosing information. That is something that could very easily be rectified. You could have custodial sentences available. Under section 77 of the Criminal Justice and Immigration Act, the Home Secretary has the ability to amend the Data Protection Act to include those. If people saw harsher penalties were available, rather than just very small fines—sometimes we see fines of less than £1 per piece of information that has been lost—that would give them more faith that the safeguards were there. 
504|Q147|Emma Carr|We also should not rely just on the Information Commissioner to enforce the Data Protection Act. Too often, they have had to prosecute under the Computer Misuse Act or for the offence of misconduct in public office, because harsh penalties are available and it is easier to prosecute. We could allow civil cases to be put if I know my data have been lost, whether it is by the Government or a private sector company, as is possible in the US. 
505|Q148|Stephen Mosley|You have mentioned the Information Commissioner. He has noted that individuals lose data rights once the data have become anonymised. Do you think that should be reconsidered? It depends on the situation, doesn't it, but is it getting easier to un­anonymise data? 
506|Q148|Professor Robertson|In narrow technical terms—to give you that kind of answer—this is a very difficult one. It is not as if data just sit there, you then do something with them, they go through and you can easily spot the routes by which they go through. Typically, very early on in the analysis of data they will be transformed into something else, with the same identifiers, different identifiers or a different structure. It is a bit like taking two numbers, multiplying them together and then trying to guess what the original two numbers were— it is not always easy. It is quite difficult to disentangle that. 
507|Q148|Professor Robertson|You can go the other way, of course, and take data where it would not have been obvious that somebody was identified, or maybe not obvious even that the structured data were there, because they were obtained from mining Twitter feeds or from unstructured text. All of those algorithms are getting really quite good now. All of that is generating data that in some sense maybe you never put in—or certainly that you never put in intentionally. That is being pushed in all sorts of different directions, because a lot of those data were already on the open web. That makes it quite a complicated topology. That is just technical. As far as I am aware, I never said anything that remotely verged on the sociological—it only gets worse. My point is that it would be very difficult to think of some gold standard or single route for doing it. Basically, it is about continuous vigilance and continuous work. 
508|Q148|Emma Carr|I would certainly like to see the ICO address further anonymisation, the potential of re-identification and pseudonymised and de-identified information. From my awareness, as time goes on and more datasets are created, it becomes easier to re-identify information that has been de-identified. That is something that I would like to see the ICO address before we come up against any potential problems in the future. 
509|Q148|Professor Robertson|I also do not want to give the impression that it is completely hopeless. One thing that you want is an appropriate level of de-identification. You want to reduce the probability of identification to some reasonable level, given the benefits involved. It is a bit like safety cases for aircraft. Occasionally an aircraft will indeed fall out of the sky, but not so often that typically it feels like we should ground every aircraft. 
510|Q149|Chair|We are practical as well. We have suggested in the context of some health data, where sharing for research is valuable, that the data could be held in a safe repository and released under controlled circumstances, case by case. Those sorts of mechanisms are feasible, aren't they? 
511|Q149|Professor Robertson|Yes—those sorts of proportionate mechanisms are. The property of these domains is that it always looks really bad in the general case, but it is possible to make progress just by shifting the parameters a little bit, if culture allows. That is the crucial point. 
512|Q149|Emma Carr|All too often getting the terminology right here is very important. When I have entered meetings, people have been talking about anonymised data when they mean pseudonymised, and pseudonymised data when they mean de-identified or statistical. Far too often they say “anonymised” when that is not what they mean, when we are talking about data sharing in practice. There needs to be a greater awareness within Government Departments, if they want to use data, of what the terminology actually is, so that when they try to inform people of what is going to happen they are informing them correctly. 
513|Q149|Dr d'Aquin|That is exactly the point I wanted to make, but formulated in a slightly different way. I agree with the Information Commissioner that truly anonymised data should not be subject to data protection, but I say that knowing that anonymisation can mean an awful lot of different things. There are other examples; the ones that have been mentioned are completely right. I have just read one about a city in the US releasing anonymised data about the taxi trips done during the year in that city. Those anonymised data were entirely and fully de-anonymised within two hours. It was not because the technology is better or because people are getting better at re-identifying data, but simply because the anonymisation mechanism that was used was provenly and very ignorantly weak. It was a big technical mistake. 
514|Q149|Dr d'Aquin|I like the idea of anonymised data; it can be extremely useful, if it is done properly. However, if you are talking about data that are personal or useful, I do not agree. What is needed is not only a proper definition but a proper framework—standardisation of what anonymisation means and what an anonymisation level is. There are mechanisms that exist in which single datasets can be assessed with respect to anonymity. Any discourse or release of anonymised data should come with a proper assessment of the level of anonymity and should be considered as having to follow data protection or not on that basis. That is a very important point. Basically, anonymisation can mean an awful lot of different things. 
515|Q150|Graham Stringer|Not everybody uses social media, and there are parts of the country that are not covered by these sorts of electronic communications. Is it sensible for the Government to use information from social media as a basis for forming policy, because those datasets will always be inadequate? 
516|Q150|Professor Robertson|While they are thinking, I will give you my academic's answer. There is a different weight. There are some demographics, for example, that use less social media, but there will be pretty strong drivers for some of those to do so soon. For example, when you look at the size of the problem that is emerging with the elderly, the frail and the infirm, it is very hard to imagine some notion of technical social networking not being used. That will have to happen, because otherwise it is not going to work. If that does happen, you will see it shift. It would be brilliant to be prepared for that, rather than to try to exclude people from that particular ethic. We should be approaching it the other way round and trying to push it in, with the aim of making the other problems to do with demographic shift rather less difficult. That would be a more positive way of putting it. I realise that, being an academic, I have not really answered your question. 
517|Q150|Graham Stringer|It was interesting. 
518|Q150|Dr d'Aquin|The most naive answer would be, “No, it is unreasonable.” At least, it is unreasonable to do it in a completely naive way. It is obvious that any data collection mechanism, including social media analysis, includes a bias, but the proper use of social science methodology includes assessing the bias and the effect it may have, and including any other complementary mechanism that can help to reduce that bias. While David's answer might be to try to reduce it by making sure that people join in, there is also an element of simply assessing what is the effect of the bias introduced by the data collection. 
519|Q150|Professor van Zoonen|In addition to what has been said about vulnerable groups not being on social media, it is important to realise that there is an increasing movement of people to getting off the grid altogether. That has nothing to do with vulnerability and everything to do with people not wanting to be traceable by energy companies, Governments or whatever and wanting to live off the grid. It is a serious social movement that would no longer be captured by social media analytics. 
520|Q151|Graham Stringer|That is right. Where do you think the data on social media could give us most benefit in extra information and as an extra base for policy making? 
521|Q151|Professor van Zoonen|There is a fantastic example in the health context, although it comes from the Netherlands, of failure of a policy because of social media. It relates to a disease for which girls have to get an inoculation when they are 13. I cannot remember what it is called, but when they are 13 years old girls need to get a vaccine against a certain type of cancer. In the Netherlands that policy failed because of a social media campaign by parents, who were very concerned about what was going to happen to their children. The year after that, the Dutch Government started their own social media campaign. Whenever there was a story about the vaccine being dangerous, they would put in their expert and explain what was going on. Since a lot of social media analytics is about marketing, advertising and campaigning, it is there that the Government could probably gain most—not by using the data but by being on there to explain their policy. 
522|Q152|Graham Stringer|Is social media best—or only useful—when it is used in relation to information from other sources, such as CCTV? 
523|Q152|Emma Carr|It depends on what you want to achieve. One suggestion is that social media data could potentially help the police with information that is usually gathered by the census or something like that. However, as has been said, the accuracy of social media data has been questioned in academic studies. I know that the ONS is looking at Twitter to see what it can ascertain from that that it could not necessarily ascertain from the census and the questions it has to ask every 10 years—or in addition to that. It depends on what you want to do with social media. If you want to inform people via social media, that is one thing; if you want to analyse people via social media, the safeguards around that are obviously different. 
524|Q152|Professor Robertson|It is starting to develop enough outside the public sector that there may be something to be learned from looking at applications that were not developed there. It would take too long to go through all of the examples, but there are canonical examples to do with emergency response, where you very quickly build up maps and so on from just the population, because there is nothing else. There are commercial examples to do with navigating roads and so on. You want to get really fast, up-to-the-minute information about where there are blockages on roads, so you do it through the social network rather than by trying to model the road network. In the commercial world and that kind of funny world of people just doing stuff, there are an awful lot of those kinds of examples. The bigger question for this kind of audience is, how many of those would translate and survive were they to be used in Government? Government is a big lever, because it could potentially use data that it has acquired to jump-start some of these things or to provide a bit of an incentive for people to be involved. However, as you may be aware, there is rather less expertise on how you do that. 
525|Q152|Dr d'Aquin|I cannot talk generally, but from conversations we have with local government, with the police about crime and with people working on disaster management and things of that sort, I can say that there is an increasing awareness that social media data have two extremely good qualities: first, there are a lot of them; and, secondly, they are fast. In many cases—I take the example of crime reporting—that is a double-edged sword. It comes with needing the ability to process the data in very large amounts and to make sense of them, to reduce noise and to enable early signals of something to look at in more detail to emerge. In many cases it cannot replace longer-term, richer and more sophisticated ways of data collection. 
526|Q152|Dr d'Aquin|What I see emerging as a pattern is the use of social media to detect in a very rapid way early signals of a phenomenon that then has to be validated through the use of other data. In crime reporting, especially, the example you give of CCTV is an absolutely obvious one. Looking at Twitter to detect that an issue may be happening somewhere at that moment means that someone can go and watch a real stream on a CCTV camera to validate that something is indeed happening and then take appropriate action. In many cases false reporting, noisy data or simply misinterpretation of what in the end is a very large amount of unstructured data will show that such validation mechanisms are absolutely necessary. 
527|Q152|Graham Stringer|Thank you. 
528|Q152|Chair|Stephen has a couple more quick questions. 
529|Q153|Stephen Metcalfe|I want to go back to the legislative framework that is currently in place to control the way our data are used. The EU is proposing some changes to the Data Protection Act. There seems to be a mixed reaction to that. TechUK said it would have a “negative impact” and Big Brother Watch said it would improve individuals' control over the amount of data. Briefly, what is the purpose of data protection legislatively? What is your view on these changes? Is there a balance to be struck somewhere that will mitigate against the negativity while allowing individuals some control over what is done with their data? 
530|Q153|Emma Carr|One of the things that Big Brother Watch quite liked about the new EU regulation was that it shifts the burden of evidence away from the individual to the researcher. No longer will the individual have to explain why those data should be kept by the researcher—the researcher will have to justify why they should be kept. That is one of the safeguards. It gives individuals more control over their information, which is always a good thing. 
531|Q153|Emma Carr|EU data protection is incredibly important because of the online world we now live in. I would like to see some kind of global principle for how our data are used and shared, because the internet has completely changed the way in which those data transfer across borders. This new regulation is also about additional safeguards for when data are moved outside the EU. I believe there is a process where the national data regulator has to get involved and to sign up to some safeguards saying, “If these data enter our country, we will be responsible for them.” That higher threshold is important and is reflected in the individual nations, which tend to adopt the same principles. Anything that can be done to give individuals more control and to have a higher level of safeguards is a good thing. 
532|Q153|Professor van Zoonen|In this respect it is interesting that, when we asked our respondents what they feared most in the future about data sharing, their biggest fear was that they would have to pay for privacy and would always lose out to big business interests. If you contrast the EU policy and citizen protection with what techUK is saying about the economy suffering if we do not allow this data sharing, that is exactly where this public fear is located—that the citizen interest will lose out to big business interests. It is necessary to take on board that kind of sensitivity and what people are thinking about these issues. 
533|Q153|Dr d'Aquin|I am not profoundly familiar or at least as familiar as my colleagues may be with the changes that are proposed, but one of the key arguments is that, while, in principle, giving more control to users, these changes will introduce a bigger need for companies to invest in data infrastructure—in mechanisms such as responding to requests for the right to be forgotten. These mechanisms of this investment might hamper the economic growth of Europe in this particular area and might simply introduce additional obstacles to the business and economic use of social media analysis. That is a valid concern, from a purely economic perspective. In response to that, the important aspect is to provide support for businesses to make this investment and, especially, to factorise, understand and show good practices and how to make this investment adequately so that the economic benefit of social media analysis is not reduced by the need to comply with the regulation. 
534|Q154|Chair|There are other examples beyond the US, but my final question relates specifically to the US Patriot Act. You will be glad to know that the notes we have on you on these iPads are not out in the iCloud. The House took that decision consciously, because it is not held within the framework of legislation the UK has control over. Clearly, legislation like that is going to impact on ordinary citizens. Do you think the Government should be doing more to help people understand how their data are held in other countries and what rights they have in respect of those? 
535|Q154|Professor Robertson|Yes. 
536|Q154|Emma Carr|Yes. 
537|Q155|Chair|I do not think I have caused any controversy there—I am just curious. I might have if the American ambassador were here. Looking at it from the British Government's perspective, should we adopt a Patriot Act kind of approach to gain access to social media data? 
538|Q155|Professor Robertson|The things that are important are the evidence base and transparency. That is the difficulty with the Patriot Act. You can understand how it was rolled in at a very emotional time, why it was felt to be necessary and so on—that would be a very long conversation—but the way that it has played out has been very murky. The effects of that are pretty wide ranging. It is not just the Patriot Act but everything that went along with it. Even if you look at the research community in pure science, you will find that quite a lot of people working in security in that community feel personally undermined in their work by some of the things that are believed to have been going on. A lot of these things are beliefs—you do not know exactly what happened—but it has certainly demolished a huge amount of confidence. If you had to think of how to demolish confidence with public bodies in that area, that would be a good way to do it. I could not have made it up. 
539|Q155|Professor Robertson|On the other hand, we have just talked about the EU directive and so on. In my personal opinion, that is another example of something that is quite broad-brush, so it is very difficult—in the other direction, but still a bit unwieldy. Both of those things feel slightly uncomfortable to me. Somewhere there must be a pragmatic middle route, because we have to do something. As you say, part of it has to involve simply explaining, “These are the things that we believe we do, to the best of our ability and our ability to tell you. Here's how they are laid out.” That would be a tremendously positive thing to do. 
540|Q155|Emma Carr|If the question is, “Do we need a Patriot Act to get access to communications?” the response is no. We already have things in place in this country to allow people to have access to them, such as the Regulation of Investigatory Powers Act, the Telecommunications Act and the mutual legal assistance treaty, for access to communications from other countries. We have to be very careful when we think about the Patriot Act and its repercussions for the United Kingdom. As has been said, it is not just about communications. We must remember that in this country we have a different legal framework from the US. 
541|Q155|Dr d'Aquin|One thing that was quite misguided about the US Patriot Act was that it was realised in a slightly naive way, possibly because it was rolled out very quickly, at a time when it was felt to be necessary. Under the Act, the only approach to data collection to fight terrorism is the bulk collection of all information about every citizen and filtering that out a posteriori—after or when it has been collected—which sounds really naive. 
542|Q155|Dr d'Aquin|The argument about the need to collect data for security is not one that I would feel confident to have myself, but it requires complex and sophisticated mechanisms to ensure that data are not misguidedly and naively collected, in a way that might have bad repercussions, that data are collected at the time when they are needed and that the conditions under which data are collected about specific individuals are made extremely clear to the public. 
543|Q155|Chair|This is a debate that will go on. I was going to come back to Professor van Zoonen to point out that we pay for privacy already, in the sense that if you do not want a Clubcard you do not get the discounts and so on. There are plenty of examples like that. Thank you very much for a very good evidence session.
544|Q156|Chair|Good morning, gentlemen. Thank you for your patience. We have been trying to finalise another report on an entirely different subject, which we hope will become clear in a few days. For the record, I would be grateful if you would introduce yourselves. 
545|Q156|Dr Macnish|I am Kevin Macnish from the Inter-Disciplinary Applied Ethics Centre at the University of Leeds. 
546|Q156|Steve Wood|I am Steve Wood. I am head of policy delivery at the Information Commissioner’s Office. 
547|Q156|Dr Elliot|I am Mark Elliot from the School of Social Sciences at the University of Manchester. 
548|Q157|Chair|Some of the witnesses we have heard from and the evidence that has come in have suggested that the use of social media data produces a minefield for ethicists and should be limited until we have very core defined ethical standards in place. Do you agree with that, or do you see that there are problems? 
549|Q157|Dr Macnish|Yes; there are certainly problems with it. The amount of information people are putting out about themselves and the amount of information that can be gained and potentially abused is quite revolutionary. We simply do not have in place the regulations, or even the ethical understanding in many cases, to know how to deal with this. 
550|Q157|Steve Wood|From the perspective of the Information Commissioner’s Office, we are focused on the regulation of the Data Protection Act and the interaction between this area and personal data. There are certain rules and pieces of legislation in place which interact with this area, but we certainly see a need to modernise the data protection framework. That work is currently taking place in the negotiations in Europe over the new data protection regulations to see how they can be modernised. Equally, we see a welcome interaction between the world of data protection and the wider development of ethics committees, in particular the use of ethical frameworks in the commercial sector, which may be a new approach. We certainly see a welcome interaction between those areas. 
551|Q157|Dr Elliot|We do not yet understand the psychology of being in these public/private spaces where there is a fusion of understandings of what is private and what is public. It is clear that something being placed on social media is not a consent to do whatever you want with it now. People’s understanding of what they are doing when entering information into a social media site or Twitter is not the same as broadcasting something to be used subsequently for whatever purpose anybody wants to use it for. 
552|Q158|Chair|Dr Elliot, in your evidence you said that, in comparison with other types of data, the ethical guidelines for social media data are underdeveloped. Is that simply because it is also new, or are there barriers that we have not considered in other similar debates? 
553|Q158|Dr Elliot|The newness of it is really important. We are also facing issues where social media data are not used on their own. There is increasingly interest in linking the data to other data, which throws up a whole set of different issues. You cannot take this out of the big data context. Social media data are one type of the new data that are often called big data. How those data fit in with all the other data available for use in various different ways by different groups of people with overlapping interests is something we need to take into account, and that framework is just not there. 
554|Q159|Chair|More generally on this point, we have to try to synthesise a sensible report out of an incredibly complicated set of information that has come to us. Clearly, there are concerns about ethics in this space. If you were assisting us to draft that report, give us one ethical guideline that you think ought to be firmly implanted in our considerations. 
555|Q159|Steve Wood|In terms of the interaction between privacy and data protection issues, one area we are keen to promote is the concept of a privacy impact assessment. I think that can interact quite well with wider ethical considerations, particularly considering the effects and potential use of the data and different range of scenarios, from research to looking at trends and sentiment issues relating to social media, compared with other areas where the data might be used more to create a profile that might be applied, and may relate to decision making, to an individual, where it may have different types of impact. The privacy impact assessment that we have developed at the Information Commissioner’s Office can be a useful tool which can link and work well in the wider context of ethical considerations. So that might be one of my opening points. 
556|Q159|Dr Macnish|Speaking as an ethicist, I would say much more broadly than that even, but simply just do no harm as much as possible. It may sound facetious, but a lot of good can come out of social media and big data in general, but there is also tremendous scope for abuse. What we should be looking to do as a community, both in law and in ethics, is to limit that harm to the greatest extent possible while also freeing up the benefits that can come out of it. 
557|Q159|Dr Elliot|I think it is defining the principles of what is and is not fair use of the information, and also the relationship between the provider of the social media and the users. The recent report to hit the news headlines about experiments being conducted by Facebook is a clear example of misuse. This goes beyond the data, and that is why it gets so complicated. This is not just about the data; it is about the relationship between Facebook and its users who are being manipulated in the experiment. Clearly, experimental use of information, which is using your data for research, goes beyond that. It is the use of Facebook users for research, and a boundary there has been crossed. 
558|Q160|Stephen Mosley|There is a boundary there, but do you think data protection legislation hinders the legitimate use of data for research? 
559|Q160|Steve Wood|I do not think data protection legislation necessarily hinders the use of data for research. It contains a set of principles. As Mark has already mentioned, the first principle relating to fairness is a really useful tool which can guide people to the right considerations, thinking about the reasonable expectations of the data subject and other impacts on them. A lot of the debate has been around the future data protection regulations and the balance between the need to have consent for research and whether other conditions can be used in data protection legislation to legitimise the research, if you like. There has been widespread debate in relation to the proposed data protection regulations being negotiated in Brussels about what that balance should be. At the Information Commissioner's Office we accept that in some circumstances consent will not always be the right route for research for a number of reasons, but there are other conditions and tools which should be available in the legislation to consider whether the research can go ahead. For example, considering the concept of legitimate interest still requires a data controller to take into account the impact on the data subject and to think about the benefits and legitimate reasons why they are doing that research. It is about a balance of the legitimate conditions to focus on the research. Consent has its place, but it is about that balance. 
560|Q160|Steve Wood|I do not think the current data protection law as it stands is necessarily a barrier to research. Sometimes it can be misunderstood, but, equally, there are issues about getting the balance right to make sure we have the right protections, but, equally, to make sure there is a reasonable understanding and reflecting how research can work in the current data protection legislation. 
561|Q161|Stephen Mosley|Surely, if something has been legitimately published—let’s say they are court records, for instance, or an individual has posted it publicly themselves—and it is publicly available, it should be available for research purposes. 
562|Q161|Steve Wood|Yes, and often in those scenarios the research can take place on a legitimate basis. It is thinking through the different implications and scenarios with some of that information, particularly if it is held for a longer period or how the research progresses. It very much depends on the scenario. I think the key piece of information to get to users is to make sure they can understand in clear and transparent terms what the research means for them and how their data is being used. Equally, sometimes there is a misconception that once the data is public it ceases to be personal data. It is still personal data under the legislation; it is just that it has to work through the conditions for the research to be able to take place. The fact that it is public is a factor which often can link in to legitimise the research in the first place. 
563|Q161|Dr Macnish|On the back of what Mark said earlier, there is not the clear public/private divide any more that there might have been 20 years ago. When you publish something on Facebook, your reasonable expectations may be that it just goes out to a very limited number of friends; it may be only 10 people. That might be seen in the sense of almost a personal letter, but in fact you can have personal communications between two people on Facebook. You can make a statement public and then it goes out to everybody, or, when you are using a social media platform like Twitter, everything is public by default, although you can also ban certain people from seeing what you post on Twitter. It is not a straightforward public/private divide. With social media you are talking about a quasi-public arena, which I think muddies the waters quite a bit. 
564|Q161|Dr Elliot|There is a distinction here between “published” and “public.” If you have deliberately self-published something—for example, if you post your CV online—you have the obvious intent that people should read it and that is its intention. The same goes for certain sorts of web activity such as blogging. You desire people to come and look at the website. Social media is not quite in that category. It may be public or semi-public, but that is not the same as publishing, which is the deliberate intent to put it out to as many people as possible. There is a grey area here. 
565|Q162|Stephen Mosley|In May, the European court made a judgment on Google and demanded that it removed links. I think these were newspaper articles referring to a court case about 15 years ago. Do you think that sort of thing could be considered as a censorship of data? 
566|Q162|Steve Wood|The first thing I would say about the judgment is that it is not, as some have characterised it, rewriting or deleting history; it is about the removal of the links when they are returned from a search result against an individual’s name. The other thing to mention about the court judgment is that it is not an absolute right to be able to go to a search engine and ask for those links to be removed. Essentially, it still has to be an infringement of data protection law, and then a consideration will come into play as well about the status of the information and the relationship of the individual in terms of their public profile in considering freedom of expression issues. 
567|Q162|Steve Wood|One of the challenges of the judgment, and the issue we are still mulling over, is that it does not make very much reference to freedom of expression. Picking up your point about censorship, it is quite a challenging judgment for us to interpret. The court did not make that much reference to the importance of freedom of expression, but we are still working through the implications to come up with a sensible approach to how we apply that judgment in our work. As the information commissioner responsible for both data protection and freedom of information, we are aware of the importance of both rights. 
568|Q162|Dr Macnish|There is a lot of detail to be worked out in the whole concept of the right to be forgotten that the Spanish judgment was drawing on. The principle, at least as stated by the European Parliament at the moment, is that it will not apply to newspaper archives, for instance, but are Huffington Post or Salon.com—solely online publishers—newspapers? What about an individual person’s blog? Some people blog and the information they share is treated extremely seriously, and sometimes even taken more seriously than what might be in the newspapers. For other people, it might just be a blog about their family background. What counts as being a newspaper in that sense is not entirely clear. 
569|Q162|Dr Macnish|Another issue which comes up is the idea that, if it is in the public interest, it should not be deleted. But, again, how do you know whether or not something is in the public interest, especially after a gap of five, 10 or 15 years? It may turn out that something which five years ago is no longer in the public interest in another 10 years’ time suddenly does become in the public interest. Let’s say a person has a particular political viewpoint which is expressed and gets in the public record. Five years later they say, “I have not been engaging in politics recently. I wish to have that struck off the record,” and 10 years later they do get into politics and follow up certain views. For the rest of us, we might think it would be helpful to know what they once expressed in public. 
570|Q163|Stephen Mosley|We keep hearing about the right to be forgotten. An alternative point of view is that there should be a right to be forgiven. Have you heard that term used at all, and, if so, do you think a right to be forgiven might be better than a right to be forgotten? 
571|Q163|Steve Wood|We have indicated that the term “right to be forgotten” is quite difficult. It also raises expectations in the public about what might be able to happen. Whether “right to be forgotten” is the right term, it is not one we are wedded to or necessarily promoting as the data protection regulator. There is currently a right to erasure, which is more explicitly in the current data protection regulations. It may be that sticking to those terms is more helpful. 
572|Q163|Steve Wood|I think the term “right to be forgiven” has been advanced by some US commentators as an alternative concept in US society, but, again, it only takes us so far; it still leads us into some of the difficult issues that Kevin was outlining. I think it is the importance of the term. It is quite a loaded term. It has been advanced by the European Commission under their current proposals for a draft data protection regulation. It is clearly part of setting out a concept, but it may be an unhelpful one in what it gives to users but having some important ideas behind it. The idea behind it is a good one, which is giving users more control over their data. We are supportive of that. 
573|Q164|Mr Heath|Can I explore the concept of informed consent? I accept that you can probably achieve consent, but by the time you have got to the 106th page of the terms and conditions and clicked “I agree” you probably have not been informed a great deal. Is informed consent a conceit? Is it a concept that we can actually make work? 
574|Q164|Mr Heath|Dr Macnish: With informed consent, a lot of the question depends on what you are being informed about. I do not think you have to be informed about the exact process your data will go through, or all the legal aspects surrounding it, but it is reasonable to be informed about the risks and benefits that will occur to you as a result of your data having been used. For instance, Facebook has been in the press recently over the use of its wall to manipulate emotions, or at least that is the way it has been presented. One word of research in its 9,400-word terms and conditions seems not to be informed consent by anybody’s remote stretch of the imagination. It seems reasonable to suggest that, if you are going to go into some sort of experiment like this, you tell the users, “We are going to engage in an experiment. These are the harms and the benefits that may occur. Do you consent to doing this?” 
575|Q165|Chair|It is a bit like the health warning on a pack of cigarettes. 
576|Q165|Dr Macnish|It is not far off. Universities have been doing this with ethics research boards for quite some time, and it seems quite reasonable to expect that companies should obey the same standards and requirements as universities. 
577|Q166|Mr Heath|Each and every time a piece of information is used for research purposes. 
578|Q166|Dr Macnish|I believe so, yes; yes, I would say so. 
579|Q166|Dr Elliot|We—being collectively our society, the science community, business and so on—are not exploring how we could use this technology to obtain consent. Obtaining real time consent is a technical possibility now. We could be asking people explicitly each time we want to use their data for a new purpose, using the very media we are talking about now, using technology that is already existing. There has to be a policy will and investment in infrastructure to do that. One of the logistic barriers for consent has always been that it is too difficult to get in touch with people to ask them whether you can now use their data for an entirely new purpose. That is no longer the case. At the moment there is quite a lot of fabrication about why we are not going forward with this technology. There is a lot of vested interest in the existing way of doing things about holding on to data and doing work on the data that you have got, rather than accessing data when you need it. 
580|Q167|Mr Heath|Dr Elliot, you are suggesting that the technology can provide that explicit case-by-case consent. You would not necessarily need to move, for instance, to identity assurance providers as a way of coping with it. 
581|Q167|Dr Elliot|I said “could”—not “can.” I think work still needs to be done to provide the infrastructure for that, but, yes, absolutely it is possible to do that. You could do it in a variety of different ways. Identity assurance providers would be one mechanism by which you could deliver that; the use of brokers and personal data stores is another approach. We would not necessarily need to do just one thing. 
582|Q168|Mr Heath|As a very basic question, do we know whether people actually want this paraphernalia and this approach? Is there any research that says, yes, people do want to give their informed consent rather than simply have it— 
583|Q168|Dr Macnish|Research carried out by Eurobarometer 2011 suggested that 80% of UK citizens were concerned about their data being used by companies without user consent. Ireland also returned an 80% concern. The two countries were the highest in Europe in that regard. 
584|Q169|Mr Heath|Do you have any thoughts as an academic on why the Anglo-Saxons or Celts should be particularly exercised by this? 
585|Q169|Dr Macnish|I am not sure. I can hazard a guess on that one. 
586|Q170|Mr Heath|Mr Wood, is there anything you want to add? 
587|Q170|Steve Wood|I would support the comments made about the importance of consent and considering different ways we can achieve it. It is also thinking about the level of information that is needed for different types of scenarios. In terms of data protection, we always talk about the level of information increasing, or that the detail or explanation may need to increase. The more intrusive the processing of the data and the greater the risks or implications for the individual, the more important it is that they have very clear information and it is very clearly provided to them, so it works on that scale. 
588|Q170|Steve Wood|The other thing with regard to consent is that you should use consent only when it is true consent—an individual has a choice and it is freely informed—and there is not an imbalance. That is why we say that sometimes consent is perhaps not always the right option. There may be other ways you need to think about it. I very much echo and support getting away from the idea of having just very long privacy notices which people are struggling to read. They can be 10,000 words long. The idea is sort of just-in-time technology and real time information, and there are some areas developing in mobile apps where we can see that starting to work. There needs to be innovation in both the public and private sectors in getting this information to people, so there are possibilities there which can be explored. 
589|Q171|Mr Heath|Do you expect the regulator to be setting this out or industry to be offering it? 
590|Q171|Steve Wood|We have set out some initial guidance in a code of practice on privacy notices which we published in 2010. We are in the process of updating that and consulting industry on it in light of some of these developments such as just-in-time technology. We will provide some guidance. It will not necessarily all be specifically on research; it obviously covers a wide range of circumstances. 
591|Q172|Stephen Metcalfe|Struggling to read 10,000 words is probably the understatement of the century. You just click the box “I agree” and then get to the really interesting stuff. Do you think notices containing tens of thousands of words—I think one has 176,000 words, which is absurd—are deliberately designed to be totally impenetrable so that you do just click “I agree,” and all sorts of stuff could be hidden inside it? 
592|Q172|Steve Wood|I would not say they are necessarily written in that way deliberately. Often, they will come from a culture within an organisation where lawyers are heavily involved. It may also be about writing terms and conditions that cover other aspects like terms of sale and so on. It comes from the point of view that you need to cover everything. In part, it comes from that perspective rather than being deliberately long, but there may be some organisations that sometimes are able to exploit the opacity of the notice. There are lots of different techniques to get round it. There is also the concept of a layered notice—I do not know whether you have heard of that before—where you have the basic information at the first point in a privacy notice, perhaps even some symbols and other things to explain it, and there is still more information in the notice for people to drill down. That is the other concept we have been promoting. 
593|Q173|Chair|It is not helped by documents written for American courtrooms and intended to be applied globally. 
594|Q173|Steve Wood|Yes. We recognise there is more to be done, and it is a priority area for us in continuing to explain that. It is also a source of concern in other areas. We receive complaints about nuisance telephone calls where people have not realised what was in the privacy notice and it is argued that they have consented, so it is an important issue to us in a number of different areas. 
595|Q174|Stephen Metcalfe|It is entirely right that it is an important issue. It is that box you just click to get through, and it has huge implications. You said you were putting pressure on to improve it and perhaps adopt a layered approach to terms and conditions. On whom are you putting pressure? 
596|Q174|Steve Wood|In terms of the guidance and the messages we are putting out, saying we have this code of practice on privacy notices. We also promote the concept of what we call privacy by design. One of the improvements in the proposed data protection regulation being negotiated at the moment is the concept of data protection by design and default, which is actually in the legislation. We think it will be helpful in giving us a slightly stronger statutory hook to promote that concept as well. It is a mixture of us providing guidance and working with the industry. We want industry to come up with solutions and ideas about how to do this. 
597|Q175|Stephen Metcalfe|What about getting the public to have a greater understanding that when they click the box “I agree” there are implications to that? How do we go about that? 
598|Q175|Steve Wood|It is an area on which we are seeking to do work to make sure that people are aware of their rights and the importance of interaction with the information they receive. I think there needs to be a mix of people involved in it; we cannot do it all ourselves. We are increasingly dealing in partnerships and working with other organisations—for example, citizens advice bureaux and organisations like that. We have also started a programme of teaching materials for schools on data protection. It is not just about being safe online; it is more about interactions and young people learning about transactions and about their information. We have had quite a good success rate. Those have been rolled out in primary and secondary education as well, but it is a long process. 
599|Q175|Dr Macnish|I would back up what Steve said about schools in particular. I talk to undergraduates about this. We are now getting undergraduates who have been with Facebook since they were 13. I would estimate that about one in 50 has read the terms and conditions on Facebook. 
600|Q176|Stephen Metcalfe|That many. 
601|Q176|Dr Macnish|Well, they might just be trying to show off in front of their classmates. Some of them do have concern. However, there is clearly a generation growing up that does not take this seriously and trusts Facebook—I am not picking on them—and other social media with their data. It is a real concern. As Steve said, getting them at school is the place we need to be focusing on, but, if we are going to make the terms and conditions understandable to schoolchildren, that gives us a level of English and understanding that I think is sensible to be aiming at. 
602|Q177|Stephen Metcalfe|So there is still more work to be done in that area. 
603|Q177|Dr Macnish|Very much so. 
604|Q178|Stephen Metcalfe|Google’s motto, allegedly—there is some issue around it—is “Don’t be evil.” Can any of the companies that are collecting data live up to that kind of ethos, or, because of the sheer scale of the organisations involved in the data, when they think they are being good, the potential is that they can be doing great harm? 
605|Q178|Dr Macnish|“Evil” is a very strong word to use. 
606|Q179|Stephen Metcalfe|It is in inverted commas. 
607|Q179|Dr Macnish|Indeed, yes. Rather as I said earlier, the potential for harm is there and is significant. Just because a company’s intentions are good it does not follow, therefore, that what it does is right. That information can be abused by others. Function creep can occur, whereby the initial intention is morphed slowly and slowly until eventually you end up in a totally different position that was not envisaged at the beginning. So those initial good intentions suddenly find themselves having some very negative consequences and outcomes. 
608|Q180|Mr Heath|Coming back to the earlier point about the terms and conditions and the American angle to this, it does occur to me that there are 51 jurisdictions in the United States, each one of them asserting extraterritorial jurisdiction as well. So, whatever we do within Europe, companies will still feel the need to protect themselves under US and state law and have these rigmaroles despite our best intentions. Mr Wood, do you know if there are any discussions with the American authorities, and do they take the same view? 
609|Q180|Steve Wood|It is a good point about the global dimension to these issues that we have to seek global solutions and standards ultimately. We work and co-operate a lot in Europe with other data protection authorities under the data protection directive, but increasingly we are working internationally. We have just signed a memorandum of understanding with the Federal Trade Commission—the FTC. There are a lot of discussions now and there is some convergence internationally about the issues and techniques needed to address issues around privacy and information. They are universally international issues. There is a movement in that direction, but it is taking time to get that up and running. 
610|Q180|Dr Elliot|Can I pick up the point on terms and conditions? There is an issue here. Even if you made your terms and conditions only 500 words, I still do not think people are going to read them, partly because of the language they are written in and partly because nobody has the time to do that sort of stuff. They want to get to the good stuff, as you said. I do think we need to look at technical solutions to this. There is existing technology with text mining and so forth by which you could have an app that distilled some of these terms and conditions and mapped them on to your own preferences. That is another issue here. Each user will have their own preferences about what they are and are not willing to do, and what they are and are not willing to allow a user of their data to do, and so forth. We also need to look at technical solutions to this. 
611|Q181|Stephen Metcalfe|What about graphic solutions and icons you become familiar with that say, “Your data will be used in this way”? They can often speak thousands of words. Is there anyone doing that? 
612|Q181|Dr Elliot|Companies? 
613|Q182|Stephen Metcalfe|No, not necessarily companies at this point. I am referring to someone coming up with the concept of using icons or graphics. 
614|Q182|Dr Elliot|We are now putting together a research project looking at exactly this. What would work for users in terms of representations of privacy content within terms and conditions? We are looking at traffic light-type systems and different ways of representing visually a particular pathway for your data and where it is going to end up, who is going to be using it and what the risks are. 
615|Q182|Dr Macnish|At a more localised level, I believe Facebook is doing something along those lines with every status that is now posted. Whenever a status update on Facebook is posted, a question comes up as to whether you wish it to be public, to go out to friends or be private. I think that is icon-related as well, so work is being done at a very localised level rather than on terms and conditions. 
616|Q182|Steve Wood|There is a need for standardisation to make sure we do not have the proliferation of too many different icons. A number of people have used the analogy of nutrition labels, or labels showing the fat content of foods, but this area is a little more complex than that. It is not to say it is impossible, but we need to work collaboratively across a number of different areas to get those standards agreed. 
617|Q182|Steve Wood|The other area we are exploring at the Information Commissioner's Office at the moment is the concept of a privacy seal scheme. That would be a standard scheme we might be able to endorse, but we are still exploring that at the moment. 
618|Q183|Graham Stringer|Mr Wood, you said you were in favour of privacy impact assessments. What would one look like? 
619|Q183|Steve Wood|Essentially, a privacy impact assessment is a process that an organisation would work through, thinking about the information and data they have, making sure they understand it and how they may want to use it, or data they may want to combine in or add to that data, and specifically focusing on the usage of that data, the information flows and the impact on individuals and the various different scenarios that can unfurl from the use of that data. It is very much thinking through different options and ways to mitigate the privacy risks which are identified. There could be a number of different issues. Do we need to provide more information to users? What about security? It also allows an organisation to think about the issues before they start the process, which we think is very important. 
620|Q183|Steve Wood|We also hope that it introduces the idea of proportionality. There can be different routes that perhaps use fewer data to get to a result that still helps the organisation. Sometimes people see the prize, or think, “We can get to this result only by using this amount of data,” without thinking about whether there are different ways to do it. Can we use different forms of data? Would anonymised data, rather than fully identifiable data, help us in certain situations in terms of working through all those different risks and issues? The end product of a privacy impact assessment is ultimately a report which can propose different ways forward and different options, but the key point is that the issues are mitigated at an early stage. It is a process we have been promoting for about eight years at the ICO. 
621|Q184|Graham Stringer|Should users be made aware of who owns the sites? These sites change hands, as you have pointed out. There can be fairly innocuous ownership and it can then end up in the hands of credit rating agencies. Do you think people should be automatically made aware of who owns those sites? 
622|Q184|Steve Wood|Transparency is a key component of data protection legislation. It is very important that it is transparent to the user who is processing their personal data. Whether it is the ownership of the site, who is ultimately the data controller is a really important point. That has to be transparent to the user. 
623|Q185|Graham Stringer|You say that as though it is at the moment, but it is not at the moment, is it? 
624|Q185|Steve Wood|We can still find instances where transparency can be better and clearer. In particular, people’s understanding of how credit reference agencies work is an area we recognise, and maybe we will be doing more work on that in the coming year. 
625|Q186|Pamela Nash|Gentlemen, in what way can data from social media be used by Governments, first, in disaster response? 
626|Q186|Dr Macnish|I think in locating and hearing about disasters much faster than the media can get hold of them, and hearing updates of what is going on. People are regularly tweeting about them. When the Egyptian revolution kicked off in Tahrir square the hashtag “
627|Q187|Pamela Nash|That is a good example. With information coming so quickly, do you think it can be utilised well by Government? 
628|Q187|Dr Macnish|Absolutely. I think you can run algorithms against it even when it is coming through quickly. Obviously one person sitting down at a screen is going to struggle, but you can run it through an algorithm that would help to pull out defining trends that could then balance claims against counterclaims to see whether or not something is really happening. A fair amount of analysis needs to happen, depending on how fine-grained you want to get with the information you are receiving, but certainly there are benefits to be had from it. 
629|Q188|Pamela Nash|Do we have the capability at the moment to be able to analyse that information very quickly and utilise it? 
630|Q188|Dr Macnish|I could not say for certain. I am not a computer scientist. My understanding is that we probably do, but I do not know quite the volumes that we would be talking about as to whether or not we could deal with it. Each algorithm will have a certain parameter within which it can cope. 
631|Q189|Dr Elliot|If the question is whether it would be possible, then, yes. This is just technology. For the disasters we are talking about, it is something instant like Twitter rather than more reflective social media. You are then just sticking data science on to the fire hose that Twitter produces. There is a whole issue about getting access to that. If you want to be able to respond in real time using that, some data science needs to be done; it is not just on tap. Work would need to be done if that is what you wanted. Infrastructure and probably some research would be needed in order to fit it to what purpose you had in mind. The first question would be: what would you want to do with it? 
632|Q189|Dr Macnish|There would also be the follow-up. It could also be used as a communications channel from the emergency services to the people in that particular area, saying, “This is the hashtag, Facebook site, or whatever, that you should be following.” This has been used to an extent in the States with the amber alert system, which seems to be quite effective. If there is a missing person, it goes out on Facebook. People get SMSs. It is a very simple form of communication that people sign up to, and then they can hear directly from the emergency services. 
633|Q189|Pamela Nash|I want to look at national interests and how we use social media and the data from it to prevent terrorism and terrorist attacks. How can we use data to prevent these attacks, and how effective do you think we are at using those data at the moment? 
634|Q189|Dr Macnish|I could not comment on how effective we are in using the data at the moment. There is potential for the data to be used. My understanding is that social media platforms are being used to recruit terrorists. There is going to be an increasing scale of involvement in terrorism, which might well be reflected in social media platforms. Communities and who you are friends with, who you connect with and who you follow might start to give indications. My concern is that we may end up in a dragnet scenario whereby all social media is collected and trawled through in a fishing trip expedition just to find the interesting information and to find the terrorists out of that. Going back to an earlier comment, just because the intention is good does not necessarily mean that, therefore, the consequences will also be good. 
635|Q190|Pamela Nash|What would be the negative consequence of that? 
636|Q190|Dr Macnish|I think Government having unrestricted access to citizens’ social media would not be a healthy thing. You can find people’s private opinions; people would feel extremely vulnerable. Privacy is a core element of a liberal democracy, and it would be unhealthy for the Government to have that level of access to people’s information as a regular thing. If you find somebody whom you have good reason to suspect is involved or engaged in terrorism in some way, by all means with a warrant go after their information and take it, but the idea of having everybody’s information collected just so it can be trawled through looking for trends is a worrying one. 
637|Q191|Pamela Nash|Dr Macnish, can I take it that you are not a fan of the USA Patriot Act in that case? 
638|Q191|Dr Macnish|No. I have two problems with the Patriot Act, both revolving around section 215, which is the most controversial aspect. One is that there appears to have been, from my limited understanding, a secret interpretation of that particular section, which I see as being wholly undemocratic. When Government take a secret interpretation of a law, it becomes very problematic. There is no sense of accountability of the Executive. The second thing is precisely what I said. It allows for dragnet collection. In the case of the States, that led to communications data from Verizon and other mobile phone companies going straight to US intelligence and being stored there. My understanding is that that has now changed in the light of the Snowden revelations, and those data are now held by the telephone companies and they can be accessed by the intelligence services when they have reason to suspect a particular individual. My understanding is that this latter approach is how the UK currently operates. That seems to be a much safer approach. The intelligence services require grounds to approach the telephone companies, internet service providers, or whoever it may be, to get the information they need on particular individuals and not on groups in general. 
639|Q192|Pamela Nash|Can I ask your colleagues whether they have any comments? 
640|Q192|Dr Elliot|I think you are only ever going to catch a stupid terrorist using social media. Any sensible terrorist is going to be using the dark web to communicate and network. It is the bad terrorists or the not very clever terrorists that you are going to get in this way. As to whether that is worth any significant use of resources, never mind the ethical issues my colleague has raised, I am very dubious. 
641|Q193|Pamela Nash|I am just playing devil’s advocate here. I take your point about a stupid terrorist, but the information that we are looking for is not necessarily someone putting details of an attack on social media. It might be a very nuanced analysis of trends that people are looking at, who they are communicating with and where they are travelling. That might mean a more extended look; it might be a wider range of people whose information is being looked at. Is that not something that you think— 
642|Q193|Dr Elliot|I am sorry. I missed the nuance. 
643|Q194|Pamela Nash|Dr Macnish made the point that it should relate only to people who are already suspects. If you are looking at information, it might be more difficult to ascertain, and a wider pattern is being looked at. It might be a wider range of people. 
644|Q194|Dr Elliot|Is this like the “crimes about to be committed” type of analysis, which I have heard about? 
645|Q194|Pamela Nash|Yes. 
646|Q194|Dr Elliot|Perhaps you are saying, “Hang on. There might be something about to happen here.” I think we are again in very murky water ethically. I understand there is some value in this technology, having spoken just yesterday to somebody from Europol. They are achieving some wins with that. Whether that should be done routinely and the resource required justifies the benefits is less clear to me. 
647|Q194|Dr Macnish|To follow that up, the concern I have there is that the sort of pattern recognition you are talking about, looking for patterns that indicate somebody may well be involved in terrorism or may be about to engage in a terrorist act, is based wholly on statistical correlations. There is an 80% chance that somebody might be involved in terrorism, or something along those lines. Does that 80% chance count as grounds to intrude and monitor their telephone and communications? I don’t know, but it just feels very uncomfortable to me that a statistical correlation would be sufficient. In a way, we almost deal with that already with profiling, saying that because there is a statistical correlation you should not just stop and search somebody. You need to have grounds for suspicion in that particular case. I think the same would be true here as well. 
648|Q195|Pamela Nash|You have both touched on public perception and what the British public might think of different levels of Government use of social media data to protect national security. Mr Wood, what do you say is the general public view—not necessarily your own view—about how comfortable they are with the Government using their social media private data for national security purposes? 
649|Q195|Steve Wood|A mix of views comes forward from the public. I think they have perhaps some understanding that their data, which may be old, may be used in certain ways, sometimes linked to national security or law enforcement areas. They do not have a full understanding of what happens. Sometimes they think more is done with their data in certain circumstances when it is not; in other scenarios, it is the opposite. We probably lack the public debate and true understanding and transparency about the extent to which their social media data could be used. Post-Snowden, what we probably have lacked in the UK is a full debate about these issues. The debate has been much more rigorous in the US. A good starting point for the debate is what further steps we can take to improve transparency and get people to understand the different ways in which particularly social media data can be used. That ranges from the things you have just discussed to perhaps more general uses relating to trends, and correlating and understanding issues. This might be in a very broad geographic area, which may have fewer privacy issues, compared with where you start to target an individual, or you probably need to consider issues about proportionality and what the effect on the individuals may be as well. I think we lack that debate at the moment. 
650|Q195|Pamela Nash|To me, it is not a big jump from Tesco analysing whether or not a woman is pregnant by her shopping, and what vouchers to send her, to looking at national security issues, but that is a matter for public debate. 
651|Q195|Chair|Gentlemen, thank you very much for helpful evidence and your written information as well. We may follow up some of these questions in a little more detail in writing, if we may. You have raised some challenging issues to which we would not do justice if we touched on them now. Thank you very much indeed for your time. 
652|Q196|Chair|Minister, thank you very much for coming in. We know that in all of your responsibilities you take a keen interest both in the Internet Governance Forum and, specifically here, the social media space. In your role as the responsible Minister, how much of your work is to do with supporting UK-based companies versus managing issues around US companies operating in the UK? 
653|Q196|Mr Vaizey|It would be hard to divide that up. As Minister for the creative industries, I am a big supporter of UK businesses, and we help them in terms of their export strategy. If you are talking about the internet, it is pretty clear that, in terms of some of the issues that cross my desk, companies like Google, Facebook and Twitter are relevant. On the other side, the main internet service providers—BT, a British company, Virgin Media, which is now effectively an American company, Sky and TalkTalk—would play a big role as well. We work with the main ISPs very much on issues to do with child protection and child abuse imagery, but we work on that as well with the big American companies Twitter, Facebook and Google. 
654|Q197|Chair|But you have very little power to regulate the activities of those big American companies that have played a significant part in some of the evidence we have heard in this inquiry. How do you go about addressing that challenge? 
655|Q197|Mr Vaizey|You have put your finger on this, Mr Miller, in one sense. In a very wide sense, that is the challenge for policymakers, not just in the UK but in almost any country, because a lot of the organisations one deals with now have a global reach but are based outside one’s jurisdiction. On almost any policy issue, because of technology, you face that challenge. Nuisance calls would be another example. Companies from abroad make nuisance calls. How do you deal with that? 
656|Q197|Mr Vaizey|Without wishing to put a hostage to fortune on the table, I have found dealing with them reasonably straightforward. It is a challenge for Government at what point it wants to lay down the law, if I can use the vernacular. For example, on the removal of child abuse images, the Prime Minister was very clear that it was his intention to do everything he could to eradicate those from the internet. In that respect Google came to the table and made some very far-reaching changes. That was because the Government were emphatic in their position. I am sure we will cover a range of matters in this evidence session, such as issues to do with the right to be forgotten and data protection. These are issues where the UK Government have a say. Funnily enough, potentially, we have a stronger say because we can play our part in influencing European policy, which obviously has a big impact on companies outside Europe. 
657|Q198|Chair|Within the UK data capability strategy, where does social media data fit into that discussion, rather than big data in its generality? Is there a specific piece of work going on in terms of how social media data is handled? 
658|Q198|Mr Vaizey|I have read the evidence this Committee has received. I know that some of the people giving evidence indicated that social media should be a separate element of Government policy, if you like—that big data is one of the eight great technologies, and perhaps social media should be a ninth great technology. A wry smile crossed my face. If you are giving evidence and you come from the world of research where you are looking for grants to look at social media, it would be very useful if it was the ninth great technology. I think that for practical reasons social media fits within the Government’s approach to big data. It is obviously an important element of it. 
659|Q198|Mr Vaizey|Reading the evidence, I think we are justified in saying that we are at a very early stage both in how we use social media and understand it. The Government are certainly aware of its importance and keen to work with academics and researchers to explore the implications, but in my view clearly social media sits within big data. 
660|Q199|Stephen Metcalfe|Some very large numbers are thrown around about the economic benefits of looking at this. Someone suggested £216 billion by 2017—whether that is per annum or cumulative I am not quite clear—supporting 58,000 jobs. Are those numbers ones you recognise? Have the Government made their own estimates of what this technology— this field—could be worth, in terms of both social media and just big data? 
661|Q199|Mr Vaizey|I am not aware of any internal Government research on this. These are the CEBR figures, which is a respectable institute. We all know that estimates of this kind are estimates by definition. Whether it is £216 billion, £150 billion or £250 billion, I think we can all agree it is probably a big number and it will create potentially thousands of jobs. Big data is one of the eight great technologies. Some people describe data as the currency of the 21st century. It has been described as the oil of the 21st century. It is clearly going to be extremely important. It is important that Government are ahead of the game in terms of their research and engagement with industry and academia on it. It is important that we are seen as a country that is looking at big data and lead by example. 
662|Q199|Mr Vaizey|In terms of Government making data available, I think our open data policy is very important as well. When we came into office we made the very conscious decision that we would do our best to make Government data available, because that can drive business creation and innovation. 
663|Q200|Stephen Metcalfe|You said we need to be ahead of the game. Do you believe we are and we are not playing catch-up with countries like the US or Japan? 
664|Q200|Mr Vaizey|I think we are ahead of the game. There are some stats which are not estimates. One statistic I have seen is that we are the fourth largest country in terms of high-performance computing. If you look at the kind of investment we are making, whether it is the £40 million to the Alan Turing Institute—I gather that flesh has been put on the bones of that this month by the Engineering and Physical Sciences Research Council, which is responsible for it—the £189 million we have put into high-performance computing, or the £50 million we have put into the connected digital economy catapult, a lot of money is going into this. I have seen comparisons with other countries. The United States will clearly be a world leader; Japan is another one; and some people say India is good on this as well. I think we stand good comparison with other European countries, and certainly with others around the world. 
665|Q201|Stephen Metcalfe|You talked about the great investment that has been put into areas that would support this field. It is good that the Government have invested, but how do you measure the return on that investment? What are the tangible results from that? It is great that you have done the investment. What do we get back for it? 
666|Q201|Mr Vaizey|That is a really good question. I don’t have an answer to it. As an MP who has a huge amount of science in his constituency, I am very happy to receive that investment. There was £500 million in the Large Hadron Collider. I have never asked for any return on that investment. It creates a base layer of both physical capital, in terms of kit that is being built and used, and also human capital. You attract from all over the world the brightest minds who want to work. I am sure there are statistics out there that we can read out to show the return on investment in scientific research in the widest sense that would give good, strong figures. David Willetts has been very successful in protecting the science budget. I think the reason he has been successful is that the Government recognise that effectively this is investing in the skills, businesses and applications of the future. 
667|Q202|Stephen Metcalfe|What I am saying is that, if we are going to invest in big data and social media data, we need to know whether we are getting our fair share of the alleged £216 billion, and whether it is worth investing more. One of the economic challenges we face as a country is that we do not have a big enough medium-size business sector. Medium-size businesses normally start from small businesses. How are we going to make sure that small and really medium-size enterprises get access to this and are involved in what I think will be quite an innovative space so that they will be able to maximise the economic potential? 
668|Q202|Mr Vaizey|We are doing quite a lot of work on that. David Willetts is leading a lot of this. He has set up a high-performance computing council, as it were. That is a way of taking the very big businesses and research institutes, which put a lot of investment into high-performance computing—it can include companies like Jaguar Land Rover, which put millions and millions of pounds into high-performance computing to do their very sophisticated design work—and looking at ways to make it available to small businesses. Clearly, that is incumbent on big scientific institutions. I mentioned the Large Hadron Collider because it happens to be in my constituency. They are very keen to make sure that small businesses have access. We have a lot of small high-tech companies, often spun out of universities, which are working on very high-end scientific research effectively but clearly do not have the resources to spend £50 million on the kind of kit they would need. They need access. That is the kind of work going on. 
669|Q203|Chair|I think you have Diamond in your constituency; I don’t think you have the LHC. Your boundaries do not stretch to Geneva, do they, but we know what you mean? 
670|Q203|Mr Vaizey|I am sorry—it is the Diamond synchrotron. I do not know why I talked about LHC. It was a senior moment. Perhaps I have a yearning to have the Large Hadron Collider in my constituency. Perhaps I can start my bid for the next Large Hadron Collider. 
671|Q204|David Tredinnick|It is reported that there is a shortage of people who have the right combination of skills for media and real time analytics. Do you think that is right? 
672|Q204|Mr Vaizey|I am sure there is a shortage. With any emerging field, particularly one where the skill set is particularly niche, there would be a skill shortage. That would apply to Government and business. We are looking at skills across the board, from schools through to colleges, universities and, indeed, apprenticeships. Skills also affect our approach to immigration, so we want to ensure that the highest quality graduates are able to come and work for companies where they are needed. 
673|Q205|David Tredinnick|To what extent do you differentiate the skills required for social media analysis and those required for other types of data? 
674|Q205|Mr Vaizey|To answer that question intelligently would be beyond my level of expertise. I can write you a fuller answer to it. 
675|Q206|David Tredinnick|Do you take account of those differences—I assume you must do—and to what extent? 
676|Q206|Mr Vaizey|The Government will have their own programmes on social media analytics in wanting to understand how to use social media, in particular, as Ms Nash referred earlier, in terms of disaster and crisis situations. A lot of what we will be doing at the moment is working with private business as well. A lot of the call-outs from Government will be to work with the private sector, simply because at this stage, without being pejorative, it would be difficult to find people who join the civil service with a specific career path to do data analytics and social media analytics. We are in the early stages. We will use public private partnerships, like the connected digital economy catapult, to look at opportunities to do more work in social media analytics, and we will use the research councils, the Alan Turing Institute and so on. Working with universities, academia and the private sector would be the main way forward. 
677|Q207|David Tredinnick|You touched on immigration. How do the Government plan to make sure that immigration policies do not adversely affect the ability to attract talent in social media analysis from abroad? 
678|Q207|Mr Vaizey|It is important that we have a strong immigration policy, in the sense of wanting to ensure that there is control of immigration. At the same time, we are keen to ensure that we get people with the right skills into the country. We have a points system to ensure that we can get people with skills. There are two routes. Tier 2 (general) is for skilled workers who have a job offer and a degree. There are inter-company transfers as well. We also have a shortage occupation list so we can recruit people where we think there is a shortage of skilled workers. We also have special visas for academics. We have a fairly open market for international students as well. There is a range of different ways that we can attract the right kind of people to come to the country to help, in terms of both pure research and growing businesses based in the UK. 
679|Q208|David Tredinnick|That is very helpful. I think we accept that we have an engineering shortage in the UK. What are you doing to try to help produce home-grown talent in the engineering sector? 
680|Q208|Mr Vaizey|The Government have, first, a strong focus on engineering in schools. With my Minister for Culture hat on, I am often criticised that the Government are perhaps focusing too much on STEM subjects—science, technology, engineering and mathematics—but I think that is because of the recognition of the shortage. I was delighted when the Secretary of State for Education said that computer science should be part of the national curriculum. For many years people have complained to me that kids at school were learning how to use applications but not how to write them. That is a very ambitious move and it puts us ahead of the game. The challenge will be in the implementation and making sure we can get the right teachers in to teach computer science, but it is a big signal that we take it seriously. 
681|Q208|Mr Vaizey|Apprenticeships also play a valuable role in this. As you know, the Government now have a big focus on apprenticeships. I am hoping to get certain things in my constituency correct this time. For example, in Harwell the UKAEA has a very good apprenticeship programme. I think there are now lots of people who can get the engineering skills they need through the apprenticeship programme as well as through straightforward university degrees. To get students studying these important subjects is a perennial problem, but the Government are very aware of it and are focused on providing solutions. 
682|Q209|Graham Stringer|The terms and conditions of online companies are often pretty impenetrable. What are you doing to monitor that situation? Do you think Government have a role to make those terms and conditions more comprehensible? 
683|Q209|Mr Vaizey|I think you heard evidence in another session from Nigel Shadbolt and another member of the Information Economy Council, which is chaired by David Willetts and which I attend. We had a meeting yesterday to talk about the approach to transparency on data that you discussed with them in your evidence session, and a first stab was put forward. That led to an interesting discussion about the role of Government. Some people feel, funnily enough, that it is better—“wrong” is not the appropriate word—that the initiative comes from business and industry rather than Government. Being a politician, I find that quite hard to get my head round. 
684|Q209|Mr Vaizey|I think we have an opportunity; I want to move forward on this and I think we should move forward on this. My understanding is that the Information Commissioner’s Office is going to be the conduit for this kind of work, with the industry coming forward with proposals to simplify terms and conditions online. 
685|Q209|Mr Vaizey|I think—the Committee probably shares this view—that the idea that people read 150 pages of terms and conditions is simply laughable; it is a complete nonsense. We all know what lawyers are like—every t is crossed and every i is dotted. But the consumer needs something that is easy to understand and straightforward. 
686|Q210|Graham Stringer|I certainly think we are all agreed on that. What I am trying to get at—I am not sure from what you have said—is whether you have asked the Information Commissioner to carry out that work or the Government themselves are monitoring the situation. I think the problem is universally recognised, and I want to find out where the Government are on it. 
687|Q210|Mr Vaizey|My understanding is that the work of the Information Economy Council, at which the initial draft was discussed yesterday, is going to be taking it forward, with the Information Commissioner standing behind that work and engaging industry to come up with proposals for simplified terms and conditions and a kitemark, which I think industry wants as well. 
688|Q211|Graham Stringer|Will part of that review, assessment, whatever you would call it, be questioning the justification online companies have for asking for the information they seek, or will that be a step too far? 
689|Q211|Mr Vaizey|I would have to give you my personal view, in the sense that the relationship is between the company and consumer. For me, I think Government’s role is to ensure that the consumer understands that the company is asking permission, which is the right word to use, from the consumer to use their data in a certain way. We should not necessarily restrict what they want to ask the consumer about how they use their data. I think that ends up being too top down and potentially restricts innovation. Government’s role should be to ensure that the consumer understands what the company is asking for and gives consent to that. 
690|Q212|Graham Stringer|The Information Commissioner has alerted this Committee—I guess he has alerted the Government as well—to the fact that a credit reference agency has been buying social media sites. Are the Government concerned about that? Do they see a privacy issue there, or do they believe action should be taken when ownership changes so that the users of those sites know who the owner is and that it might be used for different purposes from those they originally envisaged? 
691|Q212|Mr Vaizey|I am not the Minister responsible for the Information Commissioner. The Information Commissioner sits within the Ministry of Justice. My instinct is that the Government would want advice from the Information Commissioner about whether this was an appropriate thing for credit agencies to be doing. There has been debate in the Committee and elsewhere about people posting online in a public forum like Twitter. I think that technically it is still their data, but they have made it public. My understanding—I will correct it if I have got it wrong—is that that is now public data and, therefore, it is not a breach of the Data Protection Act to use it. Clearly, there are big issues involved here. There is the issue of what one does with data that are public, as in you have stated something in public, and what one does with aggregated data, which I think it is important should be kept anonymous. 
692|Q213|Stephen Mosley|You will be aware that under the Data Protection Act a breach of section 55, which is unlawfully obtaining disclosure of personal information, is currently an offence but is backed up only by a fine. It is not a criminal offence and there is no prison sentence attached to that. Do you think it should be? 
693|Q213|Mr Vaizey|I don’t want to dodge your question, Mr Mosley, but I think that, emphatically, has to be a matter for the Ministry of Justice. If a Minister in the Department for Culture, Media and Sport decided to change the Data Protection Act— 
694|Q214|Stephen Mosley|What would be your advice to the Ministry of Justice? 
695|Q214|Mr Vaizey|It is not something I have turned my mind to. 
696|Q215|Stephen Mosley|The Information Commissioner has told us that once data have been anonymised they lose protection rights, but there is a potential for those data to be reconstructed and re-identified. Should re-identified data have the same rights as unanonymised data? 
697|Q215|Mr Vaizey|My understanding is that there is a difference between somebody in a position of public trust being able to take data that have been anonymised and reconstituted—that would be a breach of the Data Protection Act—and somebody sitting at home taking reams of data and trying to reconstitute it. My understanding is that that is not an offence. I can see the difference between that case and somebody in a position of trust who is using tools perhaps not available to the general public to try to identify an individual from anonymised data. I think that should be an offence, but going further than that would be to stretch beyond my own personal ministerial responsibilities. 
698|Q216|Stephen Mosley|It is a very wide topic and we are aware that it covers a huge range of ministerial responsibilities, but I do want to press you on this a bit. Do you think that the re-identification of anonymised data by someone not connected to a public body should be a criminal act? 
699|Q216|Mr Vaizey|I am not aware that the Government take that view, and it is not my view at present. 
700|Q217|Mr Heath|Minister, do you deal with the European Union data protection regulations and the proposed new ones? 
701|Q217|Mr Vaizey|Not at all, but I am happy to answer questions. 
702|Q218|Mr Heath|You are familiar with the Government’s response. 
703|Q218|Mr Vaizey|Yes. Funnily enough, I always bump into Chris Grayling at the airport when he has had a discussion with the commissioner in Brussels, Viviane Reding. 
704|Q219|Mr Heath|On that basis, the Government’s position, as I understand it, is that they are not particularly keen on the proposals coming forward. One of the areas where they are not keen is the issue of explicit consent. We heard earlier that 80% of the British public are concerned about the way their data are potentially open to misuse. What is wrong with explicit consent in your view as a mechanism? 
705|Q219|Mr Vaizey|The issue is this. What we want to achieve in Government is a balance with the rights of the consumer. Perhaps I should not say “a balance.” The rights of the consumer are paramount, but one has to be pragmatic as well and not inadvertently stifle innovation. One issue that I did work on very closely, because it fell within my remit, was the e-privacy directive, which was a similar piece of legislation coming from Europe. It was about how you inform users of websites that cookies can effectively track their browsing history. Some would say that can be of benefit to consumers because they are served up with adverts that are relevant to their interests. 
706|Q219|Mr Vaizey|We worked closely with business to ensure that its implementation did not introduce too heavy burdens. If you go on a website, you will now see in a pretty straightforward fashion a banner saying, “We use cookies. Click here to find out more about them.” Similarly, the advertising industry, of its own volition, has come up with AdSense. You can click on an advert and they will tell you why you are seeing it and show you some background as to how it works. I think it has been successful. 
707|Q219|Mr Vaizey|We also work very closely with the Information Commissioner. He made it very clear that he would not prosecute people in the first year. He would allow them to try things out and come to him and explain why they were doing it, and he would provide feedback to them and say, “Well, you’re doing it slightly wrong in our view.” 
708|Q219|Mr Vaizey|Explicit consent can lead to excessive bureaucracy. It can also damage the consumer’s experience, which was the debate we had about e-privacy, if they have to keep giving consent at every stage of their interaction with a business. 
709|Q219|Mr Vaizey|Our other concern about explicit consent is that it ends up trivialising consent. Explicit consent sounds and is a pretty important decision made by the consumer. If for every single transaction with a business that involves giving them data you have to give specific consent, in a sense, if everything is explicit consent, nothing is explicit consent. Consumers will then start giving explicit consent as a matter of course, because they want to get on with the transaction they want to have. That is why we are concerned. 
710|Q219|Mr Vaizey|Consent is important to the consumer. It is their data; they have the ultimate right, but it is also important to be pragmatic, funnily enough, on behalf of the consumer, who also wants a relatively seamless transactional relationship with the business they are interacting with. 
711|Q220|Mr Heath|I understand that, so what is the alternative? How do you give uninformed consent without being asked regularly to do so? 
712|Q220|Mr Vaizey|You can provide informed consent by giving it, as it were, at the beginning of a transaction and your relationship with a business, whether it is a supermarket loyalty card or a website where you regularly shop. You can give specific or implied consent by getting a clear explanation, perhaps with reference to the discussion we had earlier, of the broad terms and conditions to which you are signing up, or the broad ways in which your data are going to be used, so that from then on your relationship can continue. 
713|Q221|Mr Heath|You would favour a generic consent: for example, “I give my consent to this sort of use of my information.” 
714|Q221|Mr Vaizey|Yes. 
715|Q222|Mr Heath|How about Government use of that information? Should that be one of the boxes you tick or do not tick? 
716|Q222|Mr Vaizey|I think Government have to be beyond reproach when it comes to their relationship with consumers. They have to ensure that, when you are transacting with Government, particularly as we are moving into a digital relationship with a lot of citizens, that is included. With reference to my earlier answer, if a company wants to say to you, “Mr Heath, please give us your consent, and we may give your data to the Government,” it is for the company to say that to the consumer, so long as the consumer knows— 
717|Q223|Mr Heath|Would that include national security? 
718|Q223|Mr Vaizey|Potentially. I am not an expert on national security, but clearly it could include a reference to the fact that the Government may be able to access your data for national security reasons. 
719|Q224|Chair|You may have heard an earlier witness argue that there ought to be a process of, almost, applying for a warrant to access my data. Do you think there is merit in thinking about that more deeply? 
720|Q224|Mr Vaizey|A warrant from Government? 
721|Q225|Chair|In the same way that a police officer seeking to search your house would require a magistrate’s warrant. Do you think there is a parallel in the virtual world that could strengthen public confidence in relation to Government potentially abusing their datasets? 
722|Q225|Mr Vaizey|The Government set out clear policies on how they will use their national security powers to access data. Those powers are subject to judicial oversight and are clear, but I would not wish to second-guess my colleagues in the Home Office about the right way to protect people. 
723|Q226|Chair|I come back to your point about explicit consent being a difficulty because it is intrusive. If it is intrusive, you have to ask yourself why companies are asking for so much information. Shouldn’t companies be encouraged to seek less information? We had an example the other day where a colleague was downloading an app and the system wanted to know his location. It was totally irrelevant and it was an unnecessarily intrusive request for information. Shouldn’t that kind of thing be actively discouraged by Government? 
724|Q226|Mr Vaizey|I do not know whether it should be actively discouraged by Government. I certainly think there should be a debate about the amount of information a company may wish to get from you. If it is asking for a location service for a music app, where you are listening to the music may well be irrelevant. 
725|Q226|Mr Vaizey|What I want to say, Mr Chair, is this. It is easy to forget, perhaps not for those of us who are approaching or are past middle age, like me, that this industry to a certain extent is in its infancy. It is a bizarre position to be in that the two largest companies in the world are effectively younger than all of us. 
726|Q226|Mr Vaizey|My hunch is that, in terms of the reams of terms and conditions that apply to a lot of these sites, that is the lawyers at work—presumably, they are getting hefty fees for covering every eventuality—plus the start-ups and innovators with their new applications, who are thinking, “We want lots of information because that might drive the next iteration of the business and the business model.” Presumably, your colleague who found the location data intrusive was given the option to provide it or not provide it. The people behind that app might think that in a year or two having that location data could take them to the next stage of how the app is used. 
727|Q227|Chair|I return finally to Government, and I appreciate this is a question that goes well beyond your own remit. So just answer in terms of your own remit, which spills over. You have relationships in DCMS with health in relation to sport, for example, business, criminal justice and so on. A very complex crossover brief exists in your Department, so you must have some inkling as to whether or not the current approach to data sharing within Government remains—as one witness said—a challenge. Do you think we have cracked it yet? 
728|Q227|Mr Vaizey|No, I don’t think we have cracked it; it is a challenge. Government need to do much more about data sharing. Across the piece in Government, single Departments make it very hard to do cross-departmental working. We have made great strides with the Government Digital Service. The work they have done has, in my view, been truly ground-breaking in crunching together thousands of websites into one site. What that is going to do in terms of data sharing is allow Government to have an overview of how the citizen transacts with Government. From that will emerge information that will help different Departments link up in terms of how they provide services for citizens, and hopefully we will see more sharing, more effective services and so on. That can link up health data, pensions data and so on. 
729|Q227|Mr Vaizey|Individual Government Departments are forging ahead in how they are using social media and also data. Some are better than others. The Department for Environment is lauded as one of the most effective in terms of using social media both to anticipate potential issues coming up but also to deal with them. Other Government Departments, such as the Department for Transport, in sharing open data are very innovative in how they have made it available. But, yes, we are also at an early stage. I would encourage the Committee to look at the work of the Government Digital Service. I think that is the pioneer. It is part of Government, but it has the air of something that sits slightly outside it, which allows it to be a relatively rare thing in Government—to be truly quite innovative and act almost as a start-up, which I happen to think is a positive thing; others might think it is a negative thing. 
730|Q227|Chair|Minister, thank you very much for your time this morning. 
